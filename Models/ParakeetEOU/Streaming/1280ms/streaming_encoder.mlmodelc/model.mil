program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "3500.14.1"}, {"coremlc-version", "3500.32.1"}, {"coremltools-component-torch", "2.4.0"}, {"coremltools-source-dialect", "TorchScript"}, {"coremltools-version", "8.3.0"}})]
{
    func main<ios17>(tensor<int32, [1]> audio_length, tensor<fp32, [1, 128, 129]> audio_signal, tensor<fp32, [17, 1, 70, 512]> cache_last_channel, tensor<int32, [1]> cache_last_channel_len, tensor<fp32, [17, 1, 512, 8]> cache_last_time, tensor<fp32, [1, 128, 16]> pre_cache) {
            tensor<int32, []> var_9 = const()[name = tensor<string, []>("op_9"), val = tensor<int32, []>(2)];
            tensor<bool, []> full_input_interleave_0 = const()[name = tensor<string, []>("full_input_interleave_0"), val = tensor<bool, []>(false)];
            tensor<string, []> pre_cache_to_fp16_dtype_0 = const()[name = tensor<string, []>("pre_cache_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<string, []> audio_signal_to_fp16_dtype_0 = const()[name = tensor<string, []>("audio_signal_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, [1, 128, 129]> audio_signal_to_fp16 = cast(dtype = audio_signal_to_fp16_dtype_0, x = audio_signal)[name = tensor<string, []>("cast_193")];
            tensor<fp16, [1, 128, 16]> pre_cache_to_fp16 = cast(dtype = pre_cache_to_fp16_dtype_0, x = pre_cache)[name = tensor<string, []>("cast_194")];
            tensor<fp16, [1, 128, 145]> full_input_cast_fp16 = concat(axis = var_9, interleave = full_input_interleave_0, values = (pre_cache_to_fp16, audio_signal_to_fp16))[name = tensor<string, []>("full_input_cast_fp16")];
            tensor<int32, []> var_12 = const()[name = tensor<string, []>("op_12"), val = tensor<int32, []>(16)];
            tensor<int32, [1]> value_1 = add(x = audio_length, y = var_12)[name = tensor<string, []>("value_1")];
            tensor<int32, [3]> var_28_begin_0 = const()[name = tensor<string, []>("op_28_begin_0"), val = tensor<int32, [3]>([0, 0, 129])];
            tensor<int32, [3]> var_28_end_0 = const()[name = tensor<string, []>("op_28_end_0"), val = tensor<int32, [3]>([1, 128, 145])];
            tensor<bool, [3]> var_28_end_mask_0 = const()[name = tensor<string, []>("op_28_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 128, 16]> var_28_cast_fp16 = slice_by_index(begin = var_28_begin_0, end = var_28_end_0, end_mask = var_28_end_mask_0, x = full_input_cast_fp16)[name = tensor<string, []>("op_28_cast_fp16")];
            tensor<string, []> var_28_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("op_28_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<int32, []> var_62 = const()[name = tensor<string, []>("op_62"), val = tensor<int32, []>(-1)];
            tensor<int32, []> var_64 = const()[name = tensor<string, []>("op_64"), val = tensor<int32, []>(1)];
            tensor<int32, [3]> x_1_perm_0 = const()[name = tensor<string, []>("x_1_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> cast_0_to_fp16_dtype_0 = const()[name = tensor<string, []>("cast_0_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, []> _inversed_108_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_108_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1]> value_1_to_fp16 = cast(dtype = cast_0_to_fp16_dtype_0, x = value_1)[name = tensor<string, []>("cast_191")];
            tensor<fp16, [1]> _inversed_108_cast_fp16 = mul(x = value_1_to_fp16, y = _inversed_108_y_0_to_fp16)[name = tensor<string, []>("_inversed_108_cast_fp16")];
            tensor<fp16, []> var_109_to_fp16 = const()[name = tensor<string, []>("op_109_to_fp16"), val = tensor<fp16, []>(0x1p+0)];
            tensor<fp16, [1]> lengths_1_cast_fp16 = add(x = _inversed_108_cast_fp16, y = var_109_to_fp16)[name = tensor<string, []>("lengths_1_cast_fp16")];
            tensor<fp16, [1]> lengths_3_cast_fp16 = floor(x = lengths_1_cast_fp16)[name = tensor<string, []>("lengths_3_cast_fp16")];
            tensor<fp16, []> _inversed_116_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_116_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1]> _inversed_116_cast_fp16 = mul(x = lengths_3_cast_fp16, y = _inversed_116_y_0_to_fp16)[name = tensor<string, []>("_inversed_116_cast_fp16")];
            tensor<fp16, []> var_117_to_fp16 = const()[name = tensor<string, []>("op_117_to_fp16"), val = tensor<fp16, []>(0x1p+0)];
            tensor<fp16, [1]> lengths_7_cast_fp16 = add(x = _inversed_116_cast_fp16, y = var_117_to_fp16)[name = tensor<string, []>("lengths_7_cast_fp16")];
            tensor<fp16, [1]> lengths_9_cast_fp16 = floor(x = lengths_7_cast_fp16)[name = tensor<string, []>("lengths_9_cast_fp16")];
            tensor<fp16, []> _inversed_124_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_124_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1]> _inversed_124_cast_fp16 = mul(x = lengths_9_cast_fp16, y = _inversed_124_y_0_to_fp16)[name = tensor<string, []>("_inversed_124_cast_fp16")];
            tensor<fp16, []> var_125_to_fp16 = const()[name = tensor<string, []>("op_125_to_fp16"), val = tensor<fp16, []>(0x1p+0)];
            tensor<fp16, [1]> lengths_13_cast_fp16 = add(x = _inversed_124_cast_fp16, y = var_125_to_fp16)[name = tensor<string, []>("lengths_13_cast_fp16")];
            tensor<fp16, [1]> lengths_cast_fp16 = floor(x = lengths_13_cast_fp16)[name = tensor<string, []>("lengths_cast_fp16")];
            tensor<string, []> cast_9_dtype_0 = const()[name = tensor<string, []>("cast_9_dtype_0"), val = tensor<string, []>("int32")];
            tensor<int32, [1]> input_1_axes_0 = const()[name = tensor<string, []>("input_1_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 145, 128]> x_1_cast_fp16 = transpose(perm = x_1_perm_0, x = full_input_cast_fp16)[name = tensor<string, []>("transpose_241")];
            tensor<fp16, [1, 1, 145, 128]> input_1_cast_fp16 = expand_dims(axes = input_1_axes_0, x = x_1_cast_fp16)[name = tensor<string, []>("input_1_cast_fp16")];
            tensor<int32, [8]> input_3_pad_0 = const()[name = tensor<string, []>("input_3_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 2, 1, 2, 1])];
            tensor<string, []> input_3_mode_0 = const()[name = tensor<string, []>("input_3_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_0_to_fp16 = const()[name = tensor<string, []>("const_0_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 1, 148, 131]> input_3_cast_fp16 = pad(constant_val = const_0_to_fp16, mode = input_3_mode_0, pad = input_3_pad_0, x = input_1_cast_fp16)[name = tensor<string, []>("input_3_cast_fp16")];
            tensor<string, []> input_5_pad_type_0 = const()[name = tensor<string, []>("input_5_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> input_5_strides_0 = const()[name = tensor<string, []>("input_5_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [4]> input_5_pad_0 = const()[name = tensor<string, []>("input_5_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> input_5_dilations_0 = const()[name = tensor<string, []>("input_5_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> input_5_groups_0 = const()[name = tensor<string, []>("input_5_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [256, 1, 3, 3]> encoder_pre_encode_conv_0_weight_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_0_weight_to_fp16"), val = tensor<fp16, [256, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64)))];
            tensor<fp16, [256]> encoder_pre_encode_conv_0_bias_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_0_bias_to_fp16"), val = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4736)))];
            tensor<fp16, [1, 256, 73, 65]> input_5_cast_fp16 = conv(bias = encoder_pre_encode_conv_0_bias_to_fp16, dilations = input_5_dilations_0, groups = input_5_groups_0, pad = input_5_pad_0, pad_type = input_5_pad_type_0, strides = input_5_strides_0, weight = encoder_pre_encode_conv_0_weight_to_fp16, x = input_3_cast_fp16)[name = tensor<string, []>("input_5_cast_fp16")];
            tensor<fp16, [1, 256, 73, 65]> input_7_cast_fp16 = relu(x = input_5_cast_fp16)[name = tensor<string, []>("input_7_cast_fp16")];
            tensor<int32, [8]> input_9_pad_0 = const()[name = tensor<string, []>("input_9_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 2, 1, 2, 1])];
            tensor<string, []> input_9_mode_0 = const()[name = tensor<string, []>("input_9_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_1_to_fp16 = const()[name = tensor<string, []>("const_1_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 256, 76, 68]> input_9_cast_fp16 = pad(constant_val = const_1_to_fp16, mode = input_9_mode_0, pad = input_9_pad_0, x = input_7_cast_fp16)[name = tensor<string, []>("input_9_cast_fp16")];
            tensor<string, []> input_11_pad_type_0 = const()[name = tensor<string, []>("input_11_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> input_11_strides_0 = const()[name = tensor<string, []>("input_11_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, []> input_11_groups_0 = const()[name = tensor<string, []>("input_11_groups_0"), val = tensor<int32, []>(256)];
            tensor<int32, [4]> input_11_pad_0 = const()[name = tensor<string, []>("input_11_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> input_11_dilations_0 = const()[name = tensor<string, []>("input_11_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<fp16, [256, 1, 3, 3]> encoder_pre_encode_conv_2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_2_weight_to_fp16"), val = tensor<fp16, [256, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(5312)))];
            tensor<fp16, [256]> encoder_pre_encode_conv_2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_2_bias_to_fp16"), val = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(9984)))];
            tensor<fp16, [1, 256, 37, 33]> input_11_cast_fp16 = conv(bias = encoder_pre_encode_conv_2_bias_to_fp16, dilations = input_11_dilations_0, groups = input_11_groups_0, pad = input_11_pad_0, pad_type = input_11_pad_type_0, strides = input_11_strides_0, weight = encoder_pre_encode_conv_2_weight_to_fp16, x = input_9_cast_fp16)[name = tensor<string, []>("input_11_cast_fp16")];
            tensor<string, []> input_13_pad_type_0 = const()[name = tensor<string, []>("input_13_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> input_13_strides_0 = const()[name = tensor<string, []>("input_13_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [4]> input_13_pad_0 = const()[name = tensor<string, []>("input_13_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> input_13_dilations_0 = const()[name = tensor<string, []>("input_13_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> input_13_groups_0 = const()[name = tensor<string, []>("input_13_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [256, 256, 1, 1]> encoder_pre_encode_conv_3_weight_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_3_weight_to_fp16"), val = tensor<fp16, [256, 256, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(10560)))];
            tensor<fp16, [256]> encoder_pre_encode_conv_3_bias_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_3_bias_to_fp16"), val = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(141696)))];
            tensor<fp16, [1, 256, 37, 33]> input_13_cast_fp16 = conv(bias = encoder_pre_encode_conv_3_bias_to_fp16, dilations = input_13_dilations_0, groups = input_13_groups_0, pad = input_13_pad_0, pad_type = input_13_pad_type_0, strides = input_13_strides_0, weight = encoder_pre_encode_conv_3_weight_to_fp16, x = input_11_cast_fp16)[name = tensor<string, []>("input_13_cast_fp16")];
            tensor<fp16, [1, 256, 37, 33]> input_15_cast_fp16 = relu(x = input_13_cast_fp16)[name = tensor<string, []>("input_15_cast_fp16")];
            tensor<int32, [8]> input_17_pad_0 = const()[name = tensor<string, []>("input_17_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 2, 1, 2, 1])];
            tensor<string, []> input_17_mode_0 = const()[name = tensor<string, []>("input_17_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_2_to_fp16 = const()[name = tensor<string, []>("const_2_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 256, 40, 36]> input_17_cast_fp16 = pad(constant_val = const_2_to_fp16, mode = input_17_mode_0, pad = input_17_pad_0, x = input_15_cast_fp16)[name = tensor<string, []>("input_17_cast_fp16")];
            tensor<string, []> input_19_pad_type_0 = const()[name = tensor<string, []>("input_19_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> input_19_strides_0 = const()[name = tensor<string, []>("input_19_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, []> input_19_groups_0 = const()[name = tensor<string, []>("input_19_groups_0"), val = tensor<int32, []>(256)];
            tensor<int32, [4]> input_19_pad_0 = const()[name = tensor<string, []>("input_19_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> input_19_dilations_0 = const()[name = tensor<string, []>("input_19_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<fp16, [256, 1, 3, 3]> encoder_pre_encode_conv_5_weight_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_5_weight_to_fp16"), val = tensor<fp16, [256, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(142272)))];
            tensor<fp16, [256]> encoder_pre_encode_conv_5_bias_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_5_bias_to_fp16"), val = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(146944)))];
            tensor<fp16, [1, 256, 19, 17]> input_19_cast_fp16 = conv(bias = encoder_pre_encode_conv_5_bias_to_fp16, dilations = input_19_dilations_0, groups = input_19_groups_0, pad = input_19_pad_0, pad_type = input_19_pad_type_0, strides = input_19_strides_0, weight = encoder_pre_encode_conv_5_weight_to_fp16, x = input_17_cast_fp16)[name = tensor<string, []>("input_19_cast_fp16")];
            tensor<string, []> input_21_pad_type_0 = const()[name = tensor<string, []>("input_21_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> input_21_strides_0 = const()[name = tensor<string, []>("input_21_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [4]> input_21_pad_0 = const()[name = tensor<string, []>("input_21_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> input_21_dilations_0 = const()[name = tensor<string, []>("input_21_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> input_21_groups_0 = const()[name = tensor<string, []>("input_21_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [256, 256, 1, 1]> encoder_pre_encode_conv_6_weight_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_6_weight_to_fp16"), val = tensor<fp16, [256, 256, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147520)))];
            tensor<fp16, [256]> encoder_pre_encode_conv_6_bias_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_conv_6_bias_to_fp16"), val = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(278656)))];
            tensor<fp16, [1, 256, 19, 17]> input_21_cast_fp16 = conv(bias = encoder_pre_encode_conv_6_bias_to_fp16, dilations = input_21_dilations_0, groups = input_21_groups_0, pad = input_21_pad_0, pad_type = input_21_pad_type_0, strides = input_21_strides_0, weight = encoder_pre_encode_conv_6_weight_to_fp16, x = input_19_cast_fp16)[name = tensor<string, []>("input_21_cast_fp16")];
            tensor<fp16, [1, 256, 19, 17]> x_3_cast_fp16 = relu(x = input_21_cast_fp16)[name = tensor<string, []>("x_3_cast_fp16")];
            tensor<int32, [4]> var_181_perm_0 = const()[name = tensor<string, []>("op_181_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_182 = const()[name = tensor<string, []>("op_182"), val = tensor<int32, [3]>([1, 19, -1])];
            tensor<fp16, [1, 19, 256, 17]> var_181_cast_fp16 = transpose(perm = var_181_perm_0, x = x_3_cast_fp16)[name = tensor<string, []>("transpose_240")];
            tensor<fp16, [1, 19, 4352]> input_23_cast_fp16 = reshape(shape = var_182, x = var_181_cast_fp16)[name = tensor<string, []>("input_23_cast_fp16")];
            tensor<fp16, [512, 4352]> encoder_pre_encode_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_out_weight_to_fp16"), val = tensor<fp16, [512, 4352]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279232)))];
            tensor<fp16, [512]> encoder_pre_encode_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_pre_encode_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4735744)))];
            tensor<fp16, [1, 19, 512]> linear_0_cast_fp16 = linear(bias = encoder_pre_encode_out_bias_to_fp16, weight = encoder_pre_encode_out_weight_to_fp16, x = input_23_cast_fp16)[name = tensor<string, []>("linear_0_cast_fp16")];
            tensor<int32, [3]> var_192_begin_0 = const()[name = tensor<string, []>("op_192_begin_0"), val = tensor<int32, [3]>([0, 2, 0])];
            tensor<int32, [3]> var_192_end_0 = const()[name = tensor<string, []>("op_192_end_0"), val = tensor<int32, [3]>([1, 19, 512])];
            tensor<bool, [3]> var_192_end_mask_0 = const()[name = tensor<string, []>("op_192_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 17, 512]> var_192_cast_fp16 = slice_by_index(begin = var_192_begin_0, end = var_192_end_0, end_mask = var_192_end_mask_0, x = linear_0_cast_fp16)[name = tensor<string, []>("op_192_cast_fp16")];
            tensor<int32, []> var_194 = const()[name = tensor<string, []>("op_194"), val = tensor<int32, []>(2)];
            tensor<int32, [1]> lengths_cast_fp16_to_int32 = cast(dtype = cast_9_dtype_0, x = lengths_cast_fp16)[name = tensor<string, []>("cast_190")];
            tensor<int32, [1]> var_195 = sub(x = lengths_cast_fp16_to_int32, y = var_194)[name = tensor<string, []>("op_195")];
            tensor<string, []> var_195_promoted_to_fp16_dtype_0 = const()[name = tensor<string, []>("op_195_promoted_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, []> var_60_promoted_to_fp16 = const()[name = tensor<string, []>("op_60_promoted_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, []> const_5_to_fp16 = const()[name = tensor<string, []>("const_5_to_fp16"), val = tensor<fp16, []>(inf)];
            tensor<fp16, [1]> var_195_to_fp16 = cast(dtype = var_195_promoted_to_fp16_dtype_0, x = var_195)[name = tensor<string, []>("cast_189")];
            tensor<fp16, [1]> clip_0_cast_fp16 = clip(alpha = var_60_promoted_to_fp16, beta = const_5_to_fp16, x = var_195_to_fp16)[name = tensor<string, []>("clip_0_cast_fp16")];
            tensor<int32, [1]> max_audio_length_1 = const()[name = tensor<string, []>("max_audio_length_1"), val = tensor<int32, [1]>([17])];
            tensor<fp16, []> var_211_promoted_to_fp16 = const()[name = tensor<string, []>("op_211_promoted_to_fp16"), val = tensor<fp16, []>(0x1.18p+6)];
            tensor<fp16, [1]> padding_length_cast_fp16 = add(x = clip_0_cast_fp16, y = var_211_promoted_to_fp16)[name = tensor<string, []>("padding_length_cast_fp16")];
            tensor<int32, []> const_7 = const()[name = tensor<string, []>("const_7"), val = tensor<int32, []>(-1)];
            tensor<int32, [1]> var_213 = mul(x = cache_last_channel_len, y = const_7)[name = tensor<string, []>("op_213")];
            tensor<int32, []> var_214 = const()[name = tensor<string, []>("op_214"), val = tensor<int32, []>(70)];
            tensor<int32, [1]> offset = add(x = var_213, y = var_214)[name = tensor<string, []>("offset")];
            tensor<int32, [1]> var_254_axes_0 = const()[name = tensor<string, []>("op_254_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1, 1]> var_254_cast_fp16 = expand_dims(axes = var_254_axes_0, x = padding_length_cast_fp16)[name = tensor<string, []>("op_254_cast_fp16")];
            tensor<fp16, [1, 87]> var_253_promoted_to_fp16 = const()[name = tensor<string, []>("op_253_promoted_to_fp16"), val = tensor<fp16, [1, 87]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4736832)))];
            tensor<bool, [1, 87]> pad_mask_1_cast_fp16 = less(x = var_253_promoted_to_fp16, y = var_254_cast_fp16)[name = tensor<string, []>("pad_mask_1_cast_fp16")];
            tensor<int32, [1, 87]> expand_dims_1 = const()[name = tensor<string, []>("expand_dims_1"), val = tensor<int32, [1, 87]>([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86]])];
            tensor<int32, [1]> var_260_axes_0 = const()[name = tensor<string, []>("op_260_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<int32, [1, 1]> var_260 = expand_dims(axes = var_260_axes_0, x = offset)[name = tensor<string, []>("op_260")];
            tensor<bool, [1, 87]> pad_mask_off = greater_equal(x = expand_dims_1, y = var_260)[name = tensor<string, []>("pad_mask_off")];
            tensor<bool, [1, 87]> pad_mask_3 = logical_and(x = pad_mask_off, y = pad_mask_1_cast_fp16)[name = tensor<string, []>("pad_mask_3")];
            tensor<int32, [1]> var_263_axes_0 = const()[name = tensor<string, []>("op_263_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<bool, [1, 1, 87]> var_263 = expand_dims(axes = var_263_axes_0, x = pad_mask_3)[name = tensor<string, []>("op_263")];
            tensor<int32, [3]> var_264 = const()[name = tensor<string, []>("op_264"), val = tensor<int32, [3]>([1, 87, 1])];
            tensor<bool, [1, 87, 87]> pad_mask_for_att_mask_1 = tile(reps = var_264, x = var_263)[name = tensor<string, []>("pad_mask_for_att_mask_1")];
            tensor<int32, [3]> var_266_perm_0 = const()[name = tensor<string, []>("op_266_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, [1, 87, 87]> var_266 = transpose(perm = var_266_perm_0, x = pad_mask_for_att_mask_1)[name = tensor<string, []>("transpose_239")];
            tensor<bool, [1, 87, 87]> pad_mask_for_att_mask = logical_and(x = pad_mask_for_att_mask_1, y = var_266)[name = tensor<string, []>("pad_mask_for_att_mask")];
            tensor<bool, [1, 87, 87]> const_15 = const()[name = tensor<string, []>("const_15"), val = tensor<bool, [1, 87, 87]>([[[true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], [false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false], [false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false], [false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false], [false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false], [false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false], [false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false], [false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false], [false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false], [false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false], [false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false], [false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false], [false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true]]])];
            tensor<bool, [1, 87, 87]> att_mask_9 = logical_and(x = pad_mask_for_att_mask, y = const_15)[name = tensor<string, []>("att_mask_9")];
            tensor<bool, [1, 87, 87]> att_mask = logical_not(x = att_mask_9)[name = tensor<string, []>("att_mask")];
            tensor<bool, [1, 87]> pad_mask_5 = logical_not(x = pad_mask_3)[name = tensor<string, []>("pad_mask_5")];
            tensor<int32, [2]> pad_mask_begin_0 = const()[name = tensor<string, []>("pad_mask_begin_0"), val = tensor<int32, [2]>([0, 70])];
            tensor<int32, [2]> pad_mask_end_0 = const()[name = tensor<string, []>("pad_mask_end_0"), val = tensor<int32, [2]>([1, 87])];
            tensor<bool, [2]> pad_mask_end_mask_0 = const()[name = tensor<string, []>("pad_mask_end_mask_0"), val = tensor<bool, [2]>([true, true])];
            tensor<bool, [1, 17]> pad_mask = slice_by_index(begin = pad_mask_begin_0, end = pad_mask_end_0, end_mask = pad_mask_end_mask_0, x = pad_mask_5)[name = tensor<string, []>("pad_mask")];
            tensor<int32, [3]> mask_1_begin_0 = const()[name = tensor<string, []>("mask_1_begin_0"), val = tensor<int32, [3]>([0, 70, 0])];
            tensor<int32, [3]> mask_1_end_0 = const()[name = tensor<string, []>("mask_1_end_0"), val = tensor<int32, [3]>([1, 87, 87])];
            tensor<bool, [3]> mask_1_end_mask_0 = const()[name = tensor<string, []>("mask_1_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<bool, [1, 17, 87]> mask_1 = slice_by_index(begin = mask_1_begin_0, end = mask_1_end_0, end_mask = mask_1_end_mask_0, x = att_mask)[name = tensor<string, []>("mask_1")];
            tensor<int32, [4]> cache_1_begin_0 = const()[name = tensor<string, []>("cache_1_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> cache_1_end_0 = const()[name = tensor<string, []>("cache_1_end_0"), val = tensor<int32, [4]>([1, 1, 70, 512])];
            tensor<bool, [4]> cache_1_end_mask_0 = const()[name = tensor<string, []>("cache_1_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_1_squeeze_mask_0 = const()[name = tensor<string, []>("cache_1_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<string, []> cache_last_channel_to_fp16_dtype_0 = const()[name = tensor<string, []>("cache_last_channel_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, [17, 1, 70, 512]> cache_last_channel_to_fp16 = cast(dtype = cache_last_channel_to_fp16_dtype_0, x = cache_last_channel)[name = tensor<string, []>("cast_188")];
            tensor<fp16, [1, 70, 512]> cache_1_cast_fp16 = slice_by_index(begin = cache_1_begin_0, end = cache_1_end_0, end_mask = cache_1_end_mask_0, squeeze_mask = cache_1_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_1_cast_fp16")];
            tensor<int32, [4]> cache_3_begin_0 = const()[name = tensor<string, []>("cache_3_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> cache_3_end_0 = const()[name = tensor<string, []>("cache_3_end_0"), val = tensor<int32, [4]>([1, 1, 512, 8])];
            tensor<bool, [4]> cache_3_end_mask_0 = const()[name = tensor<string, []>("cache_3_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_3_squeeze_mask_0 = const()[name = tensor<string, []>("cache_3_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<string, []> cache_last_time_to_fp16_dtype_0 = const()[name = tensor<string, []>("cache_last_time_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, [17, 1, 512, 8]> cache_last_time_to_fp16 = cast(dtype = cache_last_time_to_fp16_dtype_0, x = cache_last_time)[name = tensor<string, []>("cast_187")];
            tensor<fp16, [1, 512, 8]> cache_3_cast_fp16 = slice_by_index(begin = cache_3_begin_0, end = cache_3_end_0, end_mask = cache_3_end_mask_0, squeeze_mask = cache_3_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_3_cast_fp16")];
            tensor<int32, [1]> input_27_axes_0 = const()[name = tensor<string, []>("input_27_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_0_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4737088)))];
            tensor<fp16, [512]> encoder_layers_0_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4738176)))];
            tensor<fp16, []> var_38_to_fp16 = const()[name = tensor<string, []>("op_38_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 17, 512]> input_27_cast_fp16 = layer_norm(axes = input_27_axes_0, beta = encoder_layers_0_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_0_norm_feed_forward1_weight_to_fp16, x = var_192_cast_fp16)[name = tensor<string, []>("input_27_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_0_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(4739264)))];
            tensor<fp16, [2048]> linear_1_bias_0_to_fp16 = const()[name = tensor<string, []>("linear_1_bias_0_to_fp16"), val = tensor<fp16, [2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(6836480)))];
            tensor<fp16, [1, 17, 2048]> linear_1_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_0_feed_forward1_linear1_weight_to_fp16, x = input_27_cast_fp16)[name = tensor<string, []>("linear_1_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_31_cast_fp16 = silu(x = linear_1_cast_fp16)[name = tensor<string, []>("input_31_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_0_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(6840640)))];
            tensor<fp16, [512]> linear_2_bias_0_to_fp16 = const()[name = tensor<string, []>("linear_2_bias_0_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(8937856)))];
            tensor<fp16, [1, 17, 512]> linear_2_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_0_feed_forward1_linear2_weight_to_fp16, x = input_31_cast_fp16)[name = tensor<string, []>("linear_2_cast_fp16")];
            tensor<fp16, []> var_303_to_fp16 = const()[name = tensor<string, []>("op_303_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_304_cast_fp16 = mul(x = linear_2_cast_fp16, y = var_303_to_fp16)[name = tensor<string, []>("op_304_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_37_cast_fp16 = add(x = var_192_cast_fp16, y = var_304_cast_fp16)[name = tensor<string, []>("input_37_cast_fp16")];
            tensor<int32, [1]> key_1_axes_0 = const()[name = tensor<string, []>("key_1_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_0_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(8938944)))];
            tensor<fp16, [512]> encoder_layers_0_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(8940032)))];
            tensor<fp16, [1, 17, 512]> key_1_cast_fp16 = layer_norm(axes = key_1_axes_0, beta = encoder_layers_0_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_0_norm_self_att_weight_to_fp16, x = input_37_cast_fp16)[name = tensor<string, []>("key_1_cast_fp16")];
            tensor<bool, []> input_39_interleave_0 = const()[name = tensor<string, []>("input_39_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_39_cast_fp16 = concat(axis = var_64, interleave = input_39_interleave_0, values = (cache_1_cast_fp16, key_1_cast_fp16))[name = tensor<string, []>("input_39_cast_fp16")];
            tensor<int32, [3]> var_326_begin_0 = const()[name = tensor<string, []>("op_326_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_326_end_0 = const()[name = tensor<string, []>("op_326_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_326_end_mask_0 = const()[name = tensor<string, []>("op_326_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_326_cast_fp16 = slice_by_index(begin = var_326_begin_0, end = var_326_end_0, end_mask = var_326_end_mask_0, x = cache_1_cast_fp16)[name = tensor<string, []>("op_326_cast_fp16")];
            tensor<bool, []> var_332_interleave_0 = const()[name = tensor<string, []>("op_332_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_332_cast_fp16 = concat(axis = var_64, interleave = var_332_interleave_0, values = (var_326_cast_fp16, key_1_cast_fp16))[name = tensor<string, []>("op_332_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_0_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(8941120)))];
            tensor<fp16, [1, 17, 512]> linear_3_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_0_self_attn_linear_q_weight_to_fp16, x = key_1_cast_fp16)[name = tensor<string, []>("linear_3_cast_fp16")];
            tensor<int32, [4]> var_336 = const()[name = tensor<string, []>("op_336"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_1_cast_fp16 = reshape(shape = var_336, x = linear_3_cast_fp16)[name = tensor<string, []>("q_1_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_0_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(9465472)))];
            tensor<fp16, [1, 87, 512]> linear_4_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_0_self_attn_linear_k_weight_to_fp16, x = input_39_cast_fp16)[name = tensor<string, []>("linear_4_cast_fp16")];
            tensor<int32, [4]> var_340 = const()[name = tensor<string, []>("op_340"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_1_cast_fp16 = reshape(shape = var_340, x = linear_4_cast_fp16)[name = tensor<string, []>("k_1_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_0_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(9989824)))];
            tensor<fp16, [1, 87, 512]> linear_5_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_0_self_attn_linear_v_weight_to_fp16, x = input_39_cast_fp16)[name = tensor<string, []>("linear_5_cast_fp16")];
            tensor<int32, [4]> var_344 = const()[name = tensor<string, []>("op_344"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_1_cast_fp16 = reshape(shape = var_344, x = linear_5_cast_fp16)[name = tensor<string, []>("v_1_cast_fp16")];
            tensor<int32, [4]> value_3_perm_0 = const()[name = tensor<string, []>("value_3_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_0_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(10514176)))];
            tensor<fp16, [1, 17, 8, 64]> var_356_cast_fp16 = add(x = q_1_cast_fp16, y = encoder_layers_0_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_356_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_0_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(10515264)))];
            tensor<fp16, [1, 17, 8, 64]> var_358_cast_fp16 = add(x = q_1_cast_fp16, y = encoder_layers_0_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_358_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_1_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_1_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_7_transpose_x_0 = const()[name = tensor<string, []>("x_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_7_transpose_y_0 = const()[name = tensor<string, []>("x_7_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_360_to_fp16 = const()[name = tensor<string, []>("op_360_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(10516352)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_1_cast_fp16 = transpose(perm = q_with_bias_v_1_perm_0, x = var_358_cast_fp16)[name = tensor<string, []>("transpose_237")];
            tensor<fp16, [1, 8, 17, 173]> x_7_cast_fp16 = matmul(transpose_x = x_7_transpose_x_0, transpose_y = x_7_transpose_y_0, x = q_with_bias_v_1_cast_fp16, y = var_360_to_fp16)[name = tensor<string, []>("x_7_cast_fp16")];
            tensor<int32, [8]> x_9_pad_0 = const()[name = tensor<string, []>("x_9_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_9_mode_0 = const()[name = tensor<string, []>("x_9_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_23_to_fp16 = const()[name = tensor<string, []>("const_23_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_9_cast_fp16 = pad(constant_val = const_23_to_fp16, mode = x_9_mode_0, pad = x_9_pad_0, x = x_7_cast_fp16)[name = tensor<string, []>("x_9_cast_fp16")];
            tensor<int32, [4]> var_368 = const()[name = tensor<string, []>("op_368"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_11_cast_fp16 = reshape(shape = var_368, x = x_9_cast_fp16)[name = tensor<string, []>("x_11_cast_fp16")];
            tensor<int32, [4]> var_372_begin_0 = const()[name = tensor<string, []>("op_372_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_372_end_0 = const()[name = tensor<string, []>("op_372_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_372_end_mask_0 = const()[name = tensor<string, []>("op_372_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_372_cast_fp16 = slice_by_index(begin = var_372_begin_0, end = var_372_end_0, end_mask = var_372_end_mask_0, x = x_11_cast_fp16)[name = tensor<string, []>("op_372_cast_fp16")];
            tensor<int32, [4]> var_373 = const()[name = tensor<string, []>("op_373"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_1_cast_fp16 = reshape(shape = var_373, x = var_372_cast_fp16)[name = tensor<string, []>("matrix_bd_1_cast_fp16")];
            tensor<bool, []> matrix_ac_1_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_1_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_51_perm_0 = const()[name = tensor<string, []>("transpose_51_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_52_perm_0 = const()[name = tensor<string, []>("transpose_52_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_52 = transpose(perm = transpose_52_perm_0, x = k_1_cast_fp16)[name = tensor<string, []>("transpose_235")];
            tensor<fp16, [1, 8, 17, 64]> transpose_51 = transpose(perm = transpose_51_perm_0, x = var_356_cast_fp16)[name = tensor<string, []>("transpose_236")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_1_cast_fp16 = matmul(transpose_x = matrix_ac_1_transpose_x_0, transpose_y = matrix_ac_1_transpose_y_0, x = transpose_51, y = transpose_52)[name = tensor<string, []>("matrix_ac_1_cast_fp16")];
            tensor<int32, [4]> matrix_bd_3_begin_0 = const()[name = tensor<string, []>("matrix_bd_3_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_3_end_0 = const()[name = tensor<string, []>("matrix_bd_3_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_3_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_3_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_3_cast_fp16 = slice_by_index(begin = matrix_bd_3_begin_0, end = matrix_bd_3_end_0, end_mask = matrix_bd_3_end_mask_0, x = matrix_bd_1_cast_fp16)[name = tensor<string, []>("matrix_bd_3_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_382_cast_fp16 = add(x = matrix_ac_1_cast_fp16, y = matrix_bd_3_cast_fp16)[name = tensor<string, []>("op_382_cast_fp16")];
            tensor<fp16, []> _inversed_scores_1_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_1_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_1_cast_fp16 = mul(x = var_382_cast_fp16, y = _inversed_scores_1_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_1_cast_fp16")];
            tensor<int32, [1]> mask_3_axes_0 = const()[name = tensor<string, []>("mask_3_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<bool, [1, 1, 17, 87]> mask_3 = expand_dims(axes = mask_3_axes_0, x = mask_1)[name = tensor<string, []>("mask_3")];
            tensor<fp16, []> var_41_to_fp16 = const()[name = tensor<string, []>("op_41_to_fp16"), val = tensor<fp16, []>(-0x1.388p+13)];
            tensor<fp16, [1, 8, 17, 87]> scores_3_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_1_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_3_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_388_cast_fp16 = softmax(axis = var_62, x = scores_3_cast_fp16)[name = tensor<string, []>("op_388_cast_fp16")];
            tensor<fp16, []> var_40_to_fp16 = const()[name = tensor<string, []>("op_40_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 87]> input_41_cast_fp16 = select(a = var_40_to_fp16, b = var_388_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_41_cast_fp16")];
            tensor<bool, []> x_13_transpose_x_0 = const()[name = tensor<string, []>("x_13_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_13_transpose_y_0 = const()[name = tensor<string, []>("x_13_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_3_cast_fp16 = transpose(perm = value_3_perm_0, x = v_1_cast_fp16)[name = tensor<string, []>("transpose_238")];
            tensor<fp16, [1, 8, 17, 64]> x_13_cast_fp16 = matmul(transpose_x = x_13_transpose_x_0, transpose_y = x_13_transpose_y_0, x = input_41_cast_fp16, y = value_3_cast_fp16)[name = tensor<string, []>("x_13_cast_fp16")];
            tensor<int32, [4]> var_392_perm_0 = const()[name = tensor<string, []>("op_392_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_393 = const()[name = tensor<string, []>("op_393"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_392_cast_fp16 = transpose(perm = var_392_perm_0, x = x_13_cast_fp16)[name = tensor<string, []>("transpose_234")];
            tensor<fp16, [1, 17, 512]> input_43_cast_fp16 = reshape(shape = var_393, x = var_392_cast_fp16)[name = tensor<string, []>("input_43_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_0_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(10693568)))];
            tensor<fp16, [1, 17, 512]> linear_7_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_0_self_attn_linear_out_weight_to_fp16, x = input_43_cast_fp16)[name = tensor<string, []>("linear_7_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_47_cast_fp16 = add(x = input_37_cast_fp16, y = linear_7_cast_fp16)[name = tensor<string, []>("input_47_cast_fp16")];
            tensor<int32, [1]> x_17_axes_0 = const()[name = tensor<string, []>("x_17_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_0_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(11217920)))];
            tensor<fp16, [512]> encoder_layers_0_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(11219008)))];
            tensor<fp16, [1, 17, 512]> x_17_cast_fp16 = layer_norm(axes = x_17_axes_0, beta = encoder_layers_0_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_0_norm_conv_weight_to_fp16, x = input_47_cast_fp16)[name = tensor<string, []>("x_17_cast_fp16")];
            tensor<int32, [3]> input_49_perm_0 = const()[name = tensor<string, []>("input_49_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_51_pad_type_0 = const()[name = tensor<string, []>("input_51_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_51_strides_0 = const()[name = tensor<string, []>("input_51_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_51_pad_0 = const()[name = tensor<string, []>("input_51_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_51_dilations_0 = const()[name = tensor<string, []>("input_51_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_51_groups_0 = const()[name = tensor<string, []>("input_51_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_0_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(11220096)))];
            tensor<fp16, [1, 512, 17]> input_49_cast_fp16 = transpose(perm = input_49_perm_0, x = x_17_cast_fp16)[name = tensor<string, []>("transpose_233")];
            tensor<fp16, [1, 1024, 17]> input_51_cast_fp16 = conv(dilations = input_51_dilations_0, groups = input_51_groups_0, pad = input_51_pad_0, pad_type = input_51_pad_type_0, strides = input_51_strides_0, weight = encoder_layers_0_conv_pointwise_conv1_weight_to_fp16, x = input_49_cast_fp16)[name = tensor<string, []>("input_51_cast_fp16")];
            tensor<int32, []> x_19_split_num_splits_0 = const()[name = tensor<string, []>("x_19_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_19_split_axis_0 = const()[name = tensor<string, []>("x_19_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_19_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_19_split_cast_fp16_1 = split(axis = x_19_split_axis_0, num_splits = x_19_split_num_splits_0, x = input_51_cast_fp16)[name = tensor<string, []>("x_19_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_19_split_1_sigmoid_cast_fp16 = sigmoid(x = x_19_split_cast_fp16_1)[name = tensor<string, []>("x_19_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_19_cast_fp16 = mul(x = x_19_split_cast_fp16_0, y = x_19_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_19_cast_fp16")];
            tensor<int32, [1]> var_418_axes_0 = const()[name = tensor<string, []>("op_418_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<bool, [1, 1, 17]> var_418 = expand_dims(axes = var_418_axes_0, x = pad_mask)[name = tensor<string, []>("op_418")];
            tensor<fp16, [1, 512, 17]> input_53_cast_fp16 = select(a = var_40_to_fp16, b = x_19_cast_fp16, cond = var_418)[name = tensor<string, []>("input_53_cast_fp16")];
            tensor<bool, []> new_x_3_interleave_0 = const()[name = tensor<string, []>("new_x_3_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_3_cast_fp16 = concat(axis = var_62, interleave = new_x_3_interleave_0, values = (cache_3_cast_fp16, input_53_cast_fp16))[name = tensor<string, []>("new_x_3_cast_fp16")];
            tensor<int32, [3]> var_431_begin_0 = const()[name = tensor<string, []>("op_431_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_431_end_0 = const()[name = tensor<string, []>("op_431_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_431_end_mask_0 = const()[name = tensor<string, []>("op_431_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_431_cast_fp16 = slice_by_index(begin = var_431_begin_0, end = var_431_end_0, end_mask = var_431_end_mask_0, x = new_x_3_cast_fp16)[name = tensor<string, []>("op_431_cast_fp16")];
            tensor<string, []> x_21_pad_type_0 = const()[name = tensor<string, []>("x_21_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_21_groups_0 = const()[name = tensor<string, []>("x_21_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_21_strides_0 = const()[name = tensor<string, []>("x_21_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_21_pad_0 = const()[name = tensor<string, []>("x_21_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_21_dilations_0 = const()[name = tensor<string, []>("x_21_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_0_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(12268736)))];
            tensor<fp16, [1, 512, 17]> x_21_cast_fp16 = conv(dilations = x_21_dilations_0, groups = x_21_groups_0, pad = x_21_pad_0, pad_type = x_21_pad_type_0, strides = x_21_strides_0, weight = encoder_layers_0_conv_depthwise_conv_weight_to_fp16, x = new_x_3_cast_fp16)[name = tensor<string, []>("x_21_cast_fp16")];
            tensor<int32, [3]> input_55_perm_0 = const()[name = tensor<string, []>("input_55_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_23_axes_0 = const()[name = tensor<string, []>("x_23_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_0_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(12278016)))];
            tensor<fp16, [512]> encoder_layers_0_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(12279104)))];
            tensor<fp16, [1, 17, 512]> input_55_cast_fp16 = transpose(perm = input_55_perm_0, x = x_21_cast_fp16)[name = tensor<string, []>("transpose_232")];
            tensor<fp16, [1, 17, 512]> x_23_cast_fp16 = layer_norm(axes = x_23_axes_0, beta = encoder_layers_0_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_0_conv_batch_norm_weight_to_fp16, x = input_55_cast_fp16)[name = tensor<string, []>("x_23_cast_fp16")];
            tensor<int32, [3]> input_57_perm_0 = const()[name = tensor<string, []>("input_57_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_57_cast_fp16 = transpose(perm = input_57_perm_0, x = x_23_cast_fp16)[name = tensor<string, []>("transpose_231")];
            tensor<fp16, [1, 512, 17]> input_59_cast_fp16 = silu(x = input_57_cast_fp16)[name = tensor<string, []>("input_59_cast_fp16")];
            tensor<string, []> x_25_pad_type_0 = const()[name = tensor<string, []>("x_25_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_25_strides_0 = const()[name = tensor<string, []>("x_25_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_25_pad_0 = const()[name = tensor<string, []>("x_25_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_25_dilations_0 = const()[name = tensor<string, []>("x_25_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_25_groups_0 = const()[name = tensor<string, []>("x_25_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_0_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(12280192)))];
            tensor<fp16, [1, 512, 17]> x_25_cast_fp16 = conv(dilations = x_25_dilations_0, groups = x_25_groups_0, pad = x_25_pad_0, pad_type = x_25_pad_type_0, strides = x_25_strides_0, weight = encoder_layers_0_conv_pointwise_conv2_weight_to_fp16, x = input_59_cast_fp16)[name = tensor<string, []>("x_25_cast_fp16")];
            tensor<int32, [3]> input_61_perm_0 = const()[name = tensor<string, []>("input_61_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_61_cast_fp16 = transpose(perm = input_61_perm_0, x = x_25_cast_fp16)[name = tensor<string, []>("transpose_230")];
            tensor<fp16, [1, 17, 512]> input_63_cast_fp16 = add(x = input_47_cast_fp16, y = input_61_cast_fp16)[name = tensor<string, []>("input_63_cast_fp16")];
            tensor<int32, [1]> input_65_axes_0 = const()[name = tensor<string, []>("input_65_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_0_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(12804544)))];
            tensor<fp16, [512]> encoder_layers_0_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(12805632)))];
            tensor<fp16, [1, 17, 512]> input_65_cast_fp16 = layer_norm(axes = input_65_axes_0, beta = encoder_layers_0_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_0_norm_feed_forward2_weight_to_fp16, x = input_63_cast_fp16)[name = tensor<string, []>("input_65_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_0_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(12806720)))];
            tensor<fp16, [1, 17, 2048]> linear_8_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_0_feed_forward2_linear1_weight_to_fp16, x = input_65_cast_fp16)[name = tensor<string, []>("linear_8_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_69_cast_fp16 = silu(x = linear_8_cast_fp16)[name = tensor<string, []>("input_69_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_0_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(14903936)))];
            tensor<fp16, [1, 17, 512]> linear_9_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_0_feed_forward2_linear2_weight_to_fp16, x = input_69_cast_fp16)[name = tensor<string, []>("linear_9_cast_fp16")];
            tensor<fp16, []> var_472_to_fp16 = const()[name = tensor<string, []>("op_472_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_473_cast_fp16 = mul(x = linear_9_cast_fp16, y = var_472_to_fp16)[name = tensor<string, []>("op_473_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_75_cast_fp16 = add(x = input_63_cast_fp16, y = var_473_cast_fp16)[name = tensor<string, []>("input_75_cast_fp16")];
            tensor<int32, [1]> input_77_axes_0 = const()[name = tensor<string, []>("input_77_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_0_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(17001152)))];
            tensor<fp16, [512]> encoder_layers_0_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_0_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(17002240)))];
            tensor<fp16, [1, 17, 512]> input_77_cast_fp16 = layer_norm(axes = input_77_axes_0, beta = encoder_layers_0_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_0_norm_out_weight_to_fp16, x = input_75_cast_fp16)[name = tensor<string, []>("input_77_cast_fp16")];
            tensor<int32, [4]> cache_5_begin_0 = const()[name = tensor<string, []>("cache_5_begin_0"), val = tensor<int32, [4]>([1, 0, 0, 0])];
            tensor<int32, [4]> cache_5_end_0 = const()[name = tensor<string, []>("cache_5_end_0"), val = tensor<int32, [4]>([2, 1, 70, 512])];
            tensor<bool, [4]> cache_5_end_mask_0 = const()[name = tensor<string, []>("cache_5_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_5_squeeze_mask_0 = const()[name = tensor<string, []>("cache_5_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_5_cast_fp16 = slice_by_index(begin = cache_5_begin_0, end = cache_5_end_0, end_mask = cache_5_end_mask_0, squeeze_mask = cache_5_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_5_cast_fp16")];
            tensor<int32, [4]> cache_7_begin_0 = const()[name = tensor<string, []>("cache_7_begin_0"), val = tensor<int32, [4]>([1, 0, 0, 0])];
            tensor<int32, [4]> cache_7_end_0 = const()[name = tensor<string, []>("cache_7_end_0"), val = tensor<int32, [4]>([2, 1, 512, 8])];
            tensor<bool, [4]> cache_7_end_mask_0 = const()[name = tensor<string, []>("cache_7_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_7_squeeze_mask_0 = const()[name = tensor<string, []>("cache_7_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_7_cast_fp16 = slice_by_index(begin = cache_7_begin_0, end = cache_7_end_0, end_mask = cache_7_end_mask_0, squeeze_mask = cache_7_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_7_cast_fp16")];
            tensor<int32, [1]> input_79_axes_0 = const()[name = tensor<string, []>("input_79_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_1_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(17003328)))];
            tensor<fp16, [512]> encoder_layers_1_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(17004416)))];
            tensor<fp16, [1, 17, 512]> input_79_cast_fp16 = layer_norm(axes = input_79_axes_0, beta = encoder_layers_1_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_1_norm_feed_forward1_weight_to_fp16, x = input_77_cast_fp16)[name = tensor<string, []>("input_79_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_1_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(17005504)))];
            tensor<fp16, [1, 17, 2048]> linear_10_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_1_feed_forward1_linear1_weight_to_fp16, x = input_79_cast_fp16)[name = tensor<string, []>("linear_10_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_83_cast_fp16 = silu(x = linear_10_cast_fp16)[name = tensor<string, []>("input_83_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_1_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19102720)))];
            tensor<fp16, [1, 17, 512]> linear_11_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_1_feed_forward1_linear2_weight_to_fp16, x = input_83_cast_fp16)[name = tensor<string, []>("linear_11_cast_fp16")];
            tensor<fp16, []> var_507_to_fp16 = const()[name = tensor<string, []>("op_507_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_508_cast_fp16 = mul(x = linear_11_cast_fp16, y = var_507_to_fp16)[name = tensor<string, []>("op_508_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_89_cast_fp16 = add(x = input_77_cast_fp16, y = var_508_cast_fp16)[name = tensor<string, []>("input_89_cast_fp16")];
            tensor<int32, [1]> key_3_axes_0 = const()[name = tensor<string, []>("key_3_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_1_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(21199936)))];
            tensor<fp16, [512]> encoder_layers_1_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(21201024)))];
            tensor<fp16, [1, 17, 512]> key_3_cast_fp16 = layer_norm(axes = key_3_axes_0, beta = encoder_layers_1_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_1_norm_self_att_weight_to_fp16, x = input_89_cast_fp16)[name = tensor<string, []>("key_3_cast_fp16")];
            tensor<bool, []> input_91_interleave_0 = const()[name = tensor<string, []>("input_91_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_91_cast_fp16 = concat(axis = var_64, interleave = input_91_interleave_0, values = (cache_5_cast_fp16, key_3_cast_fp16))[name = tensor<string, []>("input_91_cast_fp16")];
            tensor<int32, [3]> var_530_begin_0 = const()[name = tensor<string, []>("op_530_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_530_end_0 = const()[name = tensor<string, []>("op_530_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_530_end_mask_0 = const()[name = tensor<string, []>("op_530_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_530_cast_fp16 = slice_by_index(begin = var_530_begin_0, end = var_530_end_0, end_mask = var_530_end_mask_0, x = cache_5_cast_fp16)[name = tensor<string, []>("op_530_cast_fp16")];
            tensor<bool, []> var_536_interleave_0 = const()[name = tensor<string, []>("op_536_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_536_cast_fp16 = concat(axis = var_64, interleave = var_536_interleave_0, values = (var_530_cast_fp16, key_3_cast_fp16))[name = tensor<string, []>("op_536_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_1_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(21202112)))];
            tensor<fp16, [1, 17, 512]> linear_12_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_1_self_attn_linear_q_weight_to_fp16, x = key_3_cast_fp16)[name = tensor<string, []>("linear_12_cast_fp16")];
            tensor<int32, [4]> var_540 = const()[name = tensor<string, []>("op_540"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_7_cast_fp16 = reshape(shape = var_540, x = linear_12_cast_fp16)[name = tensor<string, []>("q_7_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_1_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(21726464)))];
            tensor<fp16, [1, 87, 512]> linear_13_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_1_self_attn_linear_k_weight_to_fp16, x = input_91_cast_fp16)[name = tensor<string, []>("linear_13_cast_fp16")];
            tensor<int32, [4]> var_544 = const()[name = tensor<string, []>("op_544"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_5_cast_fp16 = reshape(shape = var_544, x = linear_13_cast_fp16)[name = tensor<string, []>("k_5_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_1_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(22250816)))];
            tensor<fp16, [1, 87, 512]> linear_14_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_1_self_attn_linear_v_weight_to_fp16, x = input_91_cast_fp16)[name = tensor<string, []>("linear_14_cast_fp16")];
            tensor<int32, [4]> var_548 = const()[name = tensor<string, []>("op_548"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_3_cast_fp16 = reshape(shape = var_548, x = linear_14_cast_fp16)[name = tensor<string, []>("v_3_cast_fp16")];
            tensor<int32, [4]> value_5_perm_0 = const()[name = tensor<string, []>("value_5_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_1_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(22775168)))];
            tensor<fp16, [1, 17, 8, 64]> var_560_cast_fp16 = add(x = q_7_cast_fp16, y = encoder_layers_1_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_560_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_1_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(22776256)))];
            tensor<fp16, [1, 17, 8, 64]> var_562_cast_fp16 = add(x = q_7_cast_fp16, y = encoder_layers_1_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_562_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_3_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_3_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_33_transpose_x_0 = const()[name = tensor<string, []>("x_33_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_33_transpose_y_0 = const()[name = tensor<string, []>("x_33_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_564_to_fp16 = const()[name = tensor<string, []>("op_564_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(22777344)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_3_cast_fp16 = transpose(perm = q_with_bias_v_3_perm_0, x = var_562_cast_fp16)[name = tensor<string, []>("transpose_228")];
            tensor<fp16, [1, 8, 17, 173]> x_33_cast_fp16 = matmul(transpose_x = x_33_transpose_x_0, transpose_y = x_33_transpose_y_0, x = q_with_bias_v_3_cast_fp16, y = var_564_to_fp16)[name = tensor<string, []>("x_33_cast_fp16")];
            tensor<int32, [8]> x_35_pad_0 = const()[name = tensor<string, []>("x_35_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_35_mode_0 = const()[name = tensor<string, []>("x_35_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_36_to_fp16 = const()[name = tensor<string, []>("const_36_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_35_cast_fp16 = pad(constant_val = const_36_to_fp16, mode = x_35_mode_0, pad = x_35_pad_0, x = x_33_cast_fp16)[name = tensor<string, []>("x_35_cast_fp16")];
            tensor<int32, [4]> var_572 = const()[name = tensor<string, []>("op_572"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_37_cast_fp16 = reshape(shape = var_572, x = x_35_cast_fp16)[name = tensor<string, []>("x_37_cast_fp16")];
            tensor<int32, [4]> var_576_begin_0 = const()[name = tensor<string, []>("op_576_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_576_end_0 = const()[name = tensor<string, []>("op_576_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_576_end_mask_0 = const()[name = tensor<string, []>("op_576_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_576_cast_fp16 = slice_by_index(begin = var_576_begin_0, end = var_576_end_0, end_mask = var_576_end_mask_0, x = x_37_cast_fp16)[name = tensor<string, []>("op_576_cast_fp16")];
            tensor<int32, [4]> var_577 = const()[name = tensor<string, []>("op_577"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_5_cast_fp16 = reshape(shape = var_577, x = var_576_cast_fp16)[name = tensor<string, []>("matrix_bd_5_cast_fp16")];
            tensor<bool, []> matrix_ac_3_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_3_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_3_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_3_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_53_perm_0 = const()[name = tensor<string, []>("transpose_53_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_54_perm_0 = const()[name = tensor<string, []>("transpose_54_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_54 = transpose(perm = transpose_54_perm_0, x = k_5_cast_fp16)[name = tensor<string, []>("transpose_226")];
            tensor<fp16, [1, 8, 17, 64]> transpose_53 = transpose(perm = transpose_53_perm_0, x = var_560_cast_fp16)[name = tensor<string, []>("transpose_227")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_3_cast_fp16 = matmul(transpose_x = matrix_ac_3_transpose_x_0, transpose_y = matrix_ac_3_transpose_y_0, x = transpose_53, y = transpose_54)[name = tensor<string, []>("matrix_ac_3_cast_fp16")];
            tensor<int32, [4]> matrix_bd_7_begin_0 = const()[name = tensor<string, []>("matrix_bd_7_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_7_end_0 = const()[name = tensor<string, []>("matrix_bd_7_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_7_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_7_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_7_cast_fp16 = slice_by_index(begin = matrix_bd_7_begin_0, end = matrix_bd_7_end_0, end_mask = matrix_bd_7_end_mask_0, x = matrix_bd_5_cast_fp16)[name = tensor<string, []>("matrix_bd_7_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_586_cast_fp16 = add(x = matrix_ac_3_cast_fp16, y = matrix_bd_7_cast_fp16)[name = tensor<string, []>("op_586_cast_fp16")];
            tensor<fp16, []> _inversed_scores_5_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_5_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_5_cast_fp16 = mul(x = var_586_cast_fp16, y = _inversed_scores_5_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_5_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_7_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_5_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_7_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_592_cast_fp16 = softmax(axis = var_62, x = scores_7_cast_fp16)[name = tensor<string, []>("op_592_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_93_cast_fp16 = select(a = var_40_to_fp16, b = var_592_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_93_cast_fp16")];
            tensor<bool, []> x_39_transpose_x_0 = const()[name = tensor<string, []>("x_39_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_39_transpose_y_0 = const()[name = tensor<string, []>("x_39_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_5_cast_fp16 = transpose(perm = value_5_perm_0, x = v_3_cast_fp16)[name = tensor<string, []>("transpose_229")];
            tensor<fp16, [1, 8, 17, 64]> x_39_cast_fp16 = matmul(transpose_x = x_39_transpose_x_0, transpose_y = x_39_transpose_y_0, x = input_93_cast_fp16, y = value_5_cast_fp16)[name = tensor<string, []>("x_39_cast_fp16")];
            tensor<int32, [4]> var_596_perm_0 = const()[name = tensor<string, []>("op_596_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_597 = const()[name = tensor<string, []>("op_597"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_596_cast_fp16 = transpose(perm = var_596_perm_0, x = x_39_cast_fp16)[name = tensor<string, []>("transpose_225")];
            tensor<fp16, [1, 17, 512]> input_95_cast_fp16 = reshape(shape = var_597, x = var_596_cast_fp16)[name = tensor<string, []>("input_95_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_1_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(22954560)))];
            tensor<fp16, [1, 17, 512]> linear_16_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_1_self_attn_linear_out_weight_to_fp16, x = input_95_cast_fp16)[name = tensor<string, []>("linear_16_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_99_cast_fp16 = add(x = input_89_cast_fp16, y = linear_16_cast_fp16)[name = tensor<string, []>("input_99_cast_fp16")];
            tensor<int32, [1]> x_43_axes_0 = const()[name = tensor<string, []>("x_43_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_1_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(23478912)))];
            tensor<fp16, [512]> encoder_layers_1_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(23480000)))];
            tensor<fp16, [1, 17, 512]> x_43_cast_fp16 = layer_norm(axes = x_43_axes_0, beta = encoder_layers_1_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_1_norm_conv_weight_to_fp16, x = input_99_cast_fp16)[name = tensor<string, []>("x_43_cast_fp16")];
            tensor<int32, [3]> input_101_perm_0 = const()[name = tensor<string, []>("input_101_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_103_pad_type_0 = const()[name = tensor<string, []>("input_103_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_103_strides_0 = const()[name = tensor<string, []>("input_103_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_103_pad_0 = const()[name = tensor<string, []>("input_103_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_103_dilations_0 = const()[name = tensor<string, []>("input_103_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_103_groups_0 = const()[name = tensor<string, []>("input_103_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_1_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(23481088)))];
            tensor<fp16, [1, 512, 17]> input_101_cast_fp16 = transpose(perm = input_101_perm_0, x = x_43_cast_fp16)[name = tensor<string, []>("transpose_224")];
            tensor<fp16, [1, 1024, 17]> input_103_cast_fp16 = conv(dilations = input_103_dilations_0, groups = input_103_groups_0, pad = input_103_pad_0, pad_type = input_103_pad_type_0, strides = input_103_strides_0, weight = encoder_layers_1_conv_pointwise_conv1_weight_to_fp16, x = input_101_cast_fp16)[name = tensor<string, []>("input_103_cast_fp16")];
            tensor<int32, []> x_45_split_num_splits_0 = const()[name = tensor<string, []>("x_45_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_45_split_axis_0 = const()[name = tensor<string, []>("x_45_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_45_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_45_split_cast_fp16_1 = split(axis = x_45_split_axis_0, num_splits = x_45_split_num_splits_0, x = input_103_cast_fp16)[name = tensor<string, []>("x_45_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_45_split_1_sigmoid_cast_fp16 = sigmoid(x = x_45_split_cast_fp16_1)[name = tensor<string, []>("x_45_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_45_cast_fp16 = mul(x = x_45_split_cast_fp16_0, y = x_45_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_45_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_105_cast_fp16 = select(a = var_40_to_fp16, b = x_45_cast_fp16, cond = var_418)[name = tensor<string, []>("input_105_cast_fp16")];
            tensor<bool, []> new_x_7_interleave_0 = const()[name = tensor<string, []>("new_x_7_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_7_cast_fp16 = concat(axis = var_62, interleave = new_x_7_interleave_0, values = (cache_7_cast_fp16, input_105_cast_fp16))[name = tensor<string, []>("new_x_7_cast_fp16")];
            tensor<int32, [3]> var_635_begin_0 = const()[name = tensor<string, []>("op_635_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_635_end_0 = const()[name = tensor<string, []>("op_635_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_635_end_mask_0 = const()[name = tensor<string, []>("op_635_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_635_cast_fp16 = slice_by_index(begin = var_635_begin_0, end = var_635_end_0, end_mask = var_635_end_mask_0, x = new_x_7_cast_fp16)[name = tensor<string, []>("op_635_cast_fp16")];
            tensor<string, []> x_47_pad_type_0 = const()[name = tensor<string, []>("x_47_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_47_groups_0 = const()[name = tensor<string, []>("x_47_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_47_strides_0 = const()[name = tensor<string, []>("x_47_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_47_pad_0 = const()[name = tensor<string, []>("x_47_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_47_dilations_0 = const()[name = tensor<string, []>("x_47_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_1_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24529728)))];
            tensor<fp16, [1, 512, 17]> x_47_cast_fp16 = conv(dilations = x_47_dilations_0, groups = x_47_groups_0, pad = x_47_pad_0, pad_type = x_47_pad_type_0, strides = x_47_strides_0, weight = encoder_layers_1_conv_depthwise_conv_weight_to_fp16, x = new_x_7_cast_fp16)[name = tensor<string, []>("x_47_cast_fp16")];
            tensor<int32, [3]> input_107_perm_0 = const()[name = tensor<string, []>("input_107_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_49_axes_0 = const()[name = tensor<string, []>("x_49_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_1_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24539008)))];
            tensor<fp16, [512]> encoder_layers_1_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24540096)))];
            tensor<fp16, [1, 17, 512]> input_107_cast_fp16 = transpose(perm = input_107_perm_0, x = x_47_cast_fp16)[name = tensor<string, []>("transpose_223")];
            tensor<fp16, [1, 17, 512]> x_49_cast_fp16 = layer_norm(axes = x_49_axes_0, beta = encoder_layers_1_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_1_conv_batch_norm_weight_to_fp16, x = input_107_cast_fp16)[name = tensor<string, []>("x_49_cast_fp16")];
            tensor<int32, [3]> input_109_perm_0 = const()[name = tensor<string, []>("input_109_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_109_cast_fp16 = transpose(perm = input_109_perm_0, x = x_49_cast_fp16)[name = tensor<string, []>("transpose_222")];
            tensor<fp16, [1, 512, 17]> input_111_cast_fp16 = silu(x = input_109_cast_fp16)[name = tensor<string, []>("input_111_cast_fp16")];
            tensor<string, []> x_51_pad_type_0 = const()[name = tensor<string, []>("x_51_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_51_strides_0 = const()[name = tensor<string, []>("x_51_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_51_pad_0 = const()[name = tensor<string, []>("x_51_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_51_dilations_0 = const()[name = tensor<string, []>("x_51_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_51_groups_0 = const()[name = tensor<string, []>("x_51_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_1_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24541184)))];
            tensor<fp16, [1, 512, 17]> x_51_cast_fp16 = conv(dilations = x_51_dilations_0, groups = x_51_groups_0, pad = x_51_pad_0, pad_type = x_51_pad_type_0, strides = x_51_strides_0, weight = encoder_layers_1_conv_pointwise_conv2_weight_to_fp16, x = input_111_cast_fp16)[name = tensor<string, []>("x_51_cast_fp16")];
            tensor<int32, [3]> input_113_perm_0 = const()[name = tensor<string, []>("input_113_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_113_cast_fp16 = transpose(perm = input_113_perm_0, x = x_51_cast_fp16)[name = tensor<string, []>("transpose_221")];
            tensor<fp16, [1, 17, 512]> input_115_cast_fp16 = add(x = input_99_cast_fp16, y = input_113_cast_fp16)[name = tensor<string, []>("input_115_cast_fp16")];
            tensor<int32, [1]> input_117_axes_0 = const()[name = tensor<string, []>("input_117_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_1_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25065536)))];
            tensor<fp16, [512]> encoder_layers_1_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25066624)))];
            tensor<fp16, [1, 17, 512]> input_117_cast_fp16 = layer_norm(axes = input_117_axes_0, beta = encoder_layers_1_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_1_norm_feed_forward2_weight_to_fp16, x = input_115_cast_fp16)[name = tensor<string, []>("input_117_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_1_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25067712)))];
            tensor<fp16, [1, 17, 2048]> linear_17_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_1_feed_forward2_linear1_weight_to_fp16, x = input_117_cast_fp16)[name = tensor<string, []>("linear_17_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_121_cast_fp16 = silu(x = linear_17_cast_fp16)[name = tensor<string, []>("input_121_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_1_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(27164928)))];
            tensor<fp16, [1, 17, 512]> linear_18_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_1_feed_forward2_linear2_weight_to_fp16, x = input_121_cast_fp16)[name = tensor<string, []>("linear_18_cast_fp16")];
            tensor<fp16, []> var_676_to_fp16 = const()[name = tensor<string, []>("op_676_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_677_cast_fp16 = mul(x = linear_18_cast_fp16, y = var_676_to_fp16)[name = tensor<string, []>("op_677_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_127_cast_fp16 = add(x = input_115_cast_fp16, y = var_677_cast_fp16)[name = tensor<string, []>("input_127_cast_fp16")];
            tensor<int32, [1]> input_129_axes_0 = const()[name = tensor<string, []>("input_129_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_1_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29262144)))];
            tensor<fp16, [512]> encoder_layers_1_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_1_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29263232)))];
            tensor<fp16, [1, 17, 512]> input_129_cast_fp16 = layer_norm(axes = input_129_axes_0, beta = encoder_layers_1_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_1_norm_out_weight_to_fp16, x = input_127_cast_fp16)[name = tensor<string, []>("input_129_cast_fp16")];
            tensor<int32, [4]> cache_9_begin_0 = const()[name = tensor<string, []>("cache_9_begin_0"), val = tensor<int32, [4]>([2, 0, 0, 0])];
            tensor<int32, [4]> cache_9_end_0 = const()[name = tensor<string, []>("cache_9_end_0"), val = tensor<int32, [4]>([3, 1, 70, 512])];
            tensor<bool, [4]> cache_9_end_mask_0 = const()[name = tensor<string, []>("cache_9_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_9_squeeze_mask_0 = const()[name = tensor<string, []>("cache_9_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_9_cast_fp16 = slice_by_index(begin = cache_9_begin_0, end = cache_9_end_0, end_mask = cache_9_end_mask_0, squeeze_mask = cache_9_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_9_cast_fp16")];
            tensor<int32, [4]> cache_11_begin_0 = const()[name = tensor<string, []>("cache_11_begin_0"), val = tensor<int32, [4]>([2, 0, 0, 0])];
            tensor<int32, [4]> cache_11_end_0 = const()[name = tensor<string, []>("cache_11_end_0"), val = tensor<int32, [4]>([3, 1, 512, 8])];
            tensor<bool, [4]> cache_11_end_mask_0 = const()[name = tensor<string, []>("cache_11_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_11_squeeze_mask_0 = const()[name = tensor<string, []>("cache_11_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_11_cast_fp16 = slice_by_index(begin = cache_11_begin_0, end = cache_11_end_0, end_mask = cache_11_end_mask_0, squeeze_mask = cache_11_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_11_cast_fp16")];
            tensor<int32, [1]> input_131_axes_0 = const()[name = tensor<string, []>("input_131_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_2_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29264320)))];
            tensor<fp16, [512]> encoder_layers_2_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29265408)))];
            tensor<fp16, [1, 17, 512]> input_131_cast_fp16 = layer_norm(axes = input_131_axes_0, beta = encoder_layers_2_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_2_norm_feed_forward1_weight_to_fp16, x = input_129_cast_fp16)[name = tensor<string, []>("input_131_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_2_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29266496)))];
            tensor<fp16, [1, 17, 2048]> linear_19_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_2_feed_forward1_linear1_weight_to_fp16, x = input_131_cast_fp16)[name = tensor<string, []>("linear_19_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_135_cast_fp16 = silu(x = linear_19_cast_fp16)[name = tensor<string, []>("input_135_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_2_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(31363712)))];
            tensor<fp16, [1, 17, 512]> linear_20_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_2_feed_forward1_linear2_weight_to_fp16, x = input_135_cast_fp16)[name = tensor<string, []>("linear_20_cast_fp16")];
            tensor<fp16, []> var_711_to_fp16 = const()[name = tensor<string, []>("op_711_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_712_cast_fp16 = mul(x = linear_20_cast_fp16, y = var_711_to_fp16)[name = tensor<string, []>("op_712_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_141_cast_fp16 = add(x = input_129_cast_fp16, y = var_712_cast_fp16)[name = tensor<string, []>("input_141_cast_fp16")];
            tensor<int32, [1]> key_5_axes_0 = const()[name = tensor<string, []>("key_5_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_2_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(33460928)))];
            tensor<fp16, [512]> encoder_layers_2_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(33462016)))];
            tensor<fp16, [1, 17, 512]> key_5_cast_fp16 = layer_norm(axes = key_5_axes_0, beta = encoder_layers_2_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_2_norm_self_att_weight_to_fp16, x = input_141_cast_fp16)[name = tensor<string, []>("key_5_cast_fp16")];
            tensor<bool, []> input_143_interleave_0 = const()[name = tensor<string, []>("input_143_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_143_cast_fp16 = concat(axis = var_64, interleave = input_143_interleave_0, values = (cache_9_cast_fp16, key_5_cast_fp16))[name = tensor<string, []>("input_143_cast_fp16")];
            tensor<int32, [3]> var_734_begin_0 = const()[name = tensor<string, []>("op_734_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_734_end_0 = const()[name = tensor<string, []>("op_734_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_734_end_mask_0 = const()[name = tensor<string, []>("op_734_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_734_cast_fp16 = slice_by_index(begin = var_734_begin_0, end = var_734_end_0, end_mask = var_734_end_mask_0, x = cache_9_cast_fp16)[name = tensor<string, []>("op_734_cast_fp16")];
            tensor<bool, []> var_740_interleave_0 = const()[name = tensor<string, []>("op_740_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_740_cast_fp16 = concat(axis = var_64, interleave = var_740_interleave_0, values = (var_734_cast_fp16, key_5_cast_fp16))[name = tensor<string, []>("op_740_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_2_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(33463104)))];
            tensor<fp16, [1, 17, 512]> linear_21_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_2_self_attn_linear_q_weight_to_fp16, x = key_5_cast_fp16)[name = tensor<string, []>("linear_21_cast_fp16")];
            tensor<int32, [4]> var_744 = const()[name = tensor<string, []>("op_744"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_13_cast_fp16 = reshape(shape = var_744, x = linear_21_cast_fp16)[name = tensor<string, []>("q_13_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_2_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(33987456)))];
            tensor<fp16, [1, 87, 512]> linear_22_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_2_self_attn_linear_k_weight_to_fp16, x = input_143_cast_fp16)[name = tensor<string, []>("linear_22_cast_fp16")];
            tensor<int32, [4]> var_748 = const()[name = tensor<string, []>("op_748"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_9_cast_fp16 = reshape(shape = var_748, x = linear_22_cast_fp16)[name = tensor<string, []>("k_9_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_2_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(34511808)))];
            tensor<fp16, [1, 87, 512]> linear_23_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_2_self_attn_linear_v_weight_to_fp16, x = input_143_cast_fp16)[name = tensor<string, []>("linear_23_cast_fp16")];
            tensor<int32, [4]> var_752 = const()[name = tensor<string, []>("op_752"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_5_cast_fp16 = reshape(shape = var_752, x = linear_23_cast_fp16)[name = tensor<string, []>("v_5_cast_fp16")];
            tensor<int32, [4]> value_7_perm_0 = const()[name = tensor<string, []>("value_7_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_2_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35036160)))];
            tensor<fp16, [1, 17, 8, 64]> var_764_cast_fp16 = add(x = q_13_cast_fp16, y = encoder_layers_2_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_764_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_2_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35037248)))];
            tensor<fp16, [1, 17, 8, 64]> var_766_cast_fp16 = add(x = q_13_cast_fp16, y = encoder_layers_2_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_766_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_5_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_5_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_59_transpose_x_0 = const()[name = tensor<string, []>("x_59_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_59_transpose_y_0 = const()[name = tensor<string, []>("x_59_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_768_to_fp16 = const()[name = tensor<string, []>("op_768_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35038336)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_5_cast_fp16 = transpose(perm = q_with_bias_v_5_perm_0, x = var_766_cast_fp16)[name = tensor<string, []>("transpose_219")];
            tensor<fp16, [1, 8, 17, 173]> x_59_cast_fp16 = matmul(transpose_x = x_59_transpose_x_0, transpose_y = x_59_transpose_y_0, x = q_with_bias_v_5_cast_fp16, y = var_768_to_fp16)[name = tensor<string, []>("x_59_cast_fp16")];
            tensor<int32, [8]> x_61_pad_0 = const()[name = tensor<string, []>("x_61_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_61_mode_0 = const()[name = tensor<string, []>("x_61_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_49_to_fp16 = const()[name = tensor<string, []>("const_49_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_61_cast_fp16 = pad(constant_val = const_49_to_fp16, mode = x_61_mode_0, pad = x_61_pad_0, x = x_59_cast_fp16)[name = tensor<string, []>("x_61_cast_fp16")];
            tensor<int32, [4]> var_776 = const()[name = tensor<string, []>("op_776"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_63_cast_fp16 = reshape(shape = var_776, x = x_61_cast_fp16)[name = tensor<string, []>("x_63_cast_fp16")];
            tensor<int32, [4]> var_780_begin_0 = const()[name = tensor<string, []>("op_780_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_780_end_0 = const()[name = tensor<string, []>("op_780_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_780_end_mask_0 = const()[name = tensor<string, []>("op_780_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_780_cast_fp16 = slice_by_index(begin = var_780_begin_0, end = var_780_end_0, end_mask = var_780_end_mask_0, x = x_63_cast_fp16)[name = tensor<string, []>("op_780_cast_fp16")];
            tensor<int32, [4]> var_781 = const()[name = tensor<string, []>("op_781"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_9_cast_fp16 = reshape(shape = var_781, x = var_780_cast_fp16)[name = tensor<string, []>("matrix_bd_9_cast_fp16")];
            tensor<bool, []> matrix_ac_5_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_5_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_5_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_5_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_55_perm_0 = const()[name = tensor<string, []>("transpose_55_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_56_perm_0 = const()[name = tensor<string, []>("transpose_56_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_56 = transpose(perm = transpose_56_perm_0, x = k_9_cast_fp16)[name = tensor<string, []>("transpose_217")];
            tensor<fp16, [1, 8, 17, 64]> transpose_55 = transpose(perm = transpose_55_perm_0, x = var_764_cast_fp16)[name = tensor<string, []>("transpose_218")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_5_cast_fp16 = matmul(transpose_x = matrix_ac_5_transpose_x_0, transpose_y = matrix_ac_5_transpose_y_0, x = transpose_55, y = transpose_56)[name = tensor<string, []>("matrix_ac_5_cast_fp16")];
            tensor<int32, [4]> matrix_bd_11_begin_0 = const()[name = tensor<string, []>("matrix_bd_11_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_11_end_0 = const()[name = tensor<string, []>("matrix_bd_11_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_11_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_11_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_11_cast_fp16 = slice_by_index(begin = matrix_bd_11_begin_0, end = matrix_bd_11_end_0, end_mask = matrix_bd_11_end_mask_0, x = matrix_bd_9_cast_fp16)[name = tensor<string, []>("matrix_bd_11_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_790_cast_fp16 = add(x = matrix_ac_5_cast_fp16, y = matrix_bd_11_cast_fp16)[name = tensor<string, []>("op_790_cast_fp16")];
            tensor<fp16, []> _inversed_scores_9_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_9_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_9_cast_fp16 = mul(x = var_790_cast_fp16, y = _inversed_scores_9_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_9_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_11_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_9_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_11_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_796_cast_fp16 = softmax(axis = var_62, x = scores_11_cast_fp16)[name = tensor<string, []>("op_796_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_145_cast_fp16 = select(a = var_40_to_fp16, b = var_796_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_145_cast_fp16")];
            tensor<bool, []> x_65_transpose_x_0 = const()[name = tensor<string, []>("x_65_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_65_transpose_y_0 = const()[name = tensor<string, []>("x_65_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_7_cast_fp16 = transpose(perm = value_7_perm_0, x = v_5_cast_fp16)[name = tensor<string, []>("transpose_220")];
            tensor<fp16, [1, 8, 17, 64]> x_65_cast_fp16 = matmul(transpose_x = x_65_transpose_x_0, transpose_y = x_65_transpose_y_0, x = input_145_cast_fp16, y = value_7_cast_fp16)[name = tensor<string, []>("x_65_cast_fp16")];
            tensor<int32, [4]> var_800_perm_0 = const()[name = tensor<string, []>("op_800_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_801 = const()[name = tensor<string, []>("op_801"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_800_cast_fp16 = transpose(perm = var_800_perm_0, x = x_65_cast_fp16)[name = tensor<string, []>("transpose_216")];
            tensor<fp16, [1, 17, 512]> input_147_cast_fp16 = reshape(shape = var_801, x = var_800_cast_fp16)[name = tensor<string, []>("input_147_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_2_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35215552)))];
            tensor<fp16, [1, 17, 512]> linear_25_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_2_self_attn_linear_out_weight_to_fp16, x = input_147_cast_fp16)[name = tensor<string, []>("linear_25_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_151_cast_fp16 = add(x = input_141_cast_fp16, y = linear_25_cast_fp16)[name = tensor<string, []>("input_151_cast_fp16")];
            tensor<int32, [1]> x_69_axes_0 = const()[name = tensor<string, []>("x_69_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_2_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35739904)))];
            tensor<fp16, [512]> encoder_layers_2_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35740992)))];
            tensor<fp16, [1, 17, 512]> x_69_cast_fp16 = layer_norm(axes = x_69_axes_0, beta = encoder_layers_2_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_2_norm_conv_weight_to_fp16, x = input_151_cast_fp16)[name = tensor<string, []>("x_69_cast_fp16")];
            tensor<int32, [3]> input_153_perm_0 = const()[name = tensor<string, []>("input_153_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_155_pad_type_0 = const()[name = tensor<string, []>("input_155_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_155_strides_0 = const()[name = tensor<string, []>("input_155_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_155_pad_0 = const()[name = tensor<string, []>("input_155_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_155_dilations_0 = const()[name = tensor<string, []>("input_155_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_155_groups_0 = const()[name = tensor<string, []>("input_155_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_2_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35742080)))];
            tensor<fp16, [1, 512, 17]> input_153_cast_fp16 = transpose(perm = input_153_perm_0, x = x_69_cast_fp16)[name = tensor<string, []>("transpose_215")];
            tensor<fp16, [1, 1024, 17]> input_155_cast_fp16 = conv(dilations = input_155_dilations_0, groups = input_155_groups_0, pad = input_155_pad_0, pad_type = input_155_pad_type_0, strides = input_155_strides_0, weight = encoder_layers_2_conv_pointwise_conv1_weight_to_fp16, x = input_153_cast_fp16)[name = tensor<string, []>("input_155_cast_fp16")];
            tensor<int32, []> x_71_split_num_splits_0 = const()[name = tensor<string, []>("x_71_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_71_split_axis_0 = const()[name = tensor<string, []>("x_71_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_71_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_71_split_cast_fp16_1 = split(axis = x_71_split_axis_0, num_splits = x_71_split_num_splits_0, x = input_155_cast_fp16)[name = tensor<string, []>("x_71_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_71_split_1_sigmoid_cast_fp16 = sigmoid(x = x_71_split_cast_fp16_1)[name = tensor<string, []>("x_71_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_71_cast_fp16 = mul(x = x_71_split_cast_fp16_0, y = x_71_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_71_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_157_cast_fp16 = select(a = var_40_to_fp16, b = x_71_cast_fp16, cond = var_418)[name = tensor<string, []>("input_157_cast_fp16")];
            tensor<bool, []> new_x_11_interleave_0 = const()[name = tensor<string, []>("new_x_11_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_11_cast_fp16 = concat(axis = var_62, interleave = new_x_11_interleave_0, values = (cache_11_cast_fp16, input_157_cast_fp16))[name = tensor<string, []>("new_x_11_cast_fp16")];
            tensor<int32, [3]> var_839_begin_0 = const()[name = tensor<string, []>("op_839_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_839_end_0 = const()[name = tensor<string, []>("op_839_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_839_end_mask_0 = const()[name = tensor<string, []>("op_839_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_839_cast_fp16 = slice_by_index(begin = var_839_begin_0, end = var_839_end_0, end_mask = var_839_end_mask_0, x = new_x_11_cast_fp16)[name = tensor<string, []>("op_839_cast_fp16")];
            tensor<string, []> x_73_pad_type_0 = const()[name = tensor<string, []>("x_73_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_73_groups_0 = const()[name = tensor<string, []>("x_73_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_73_strides_0 = const()[name = tensor<string, []>("x_73_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_73_pad_0 = const()[name = tensor<string, []>("x_73_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_73_dilations_0 = const()[name = tensor<string, []>("x_73_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_2_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(36790720)))];
            tensor<fp16, [1, 512, 17]> x_73_cast_fp16 = conv(dilations = x_73_dilations_0, groups = x_73_groups_0, pad = x_73_pad_0, pad_type = x_73_pad_type_0, strides = x_73_strides_0, weight = encoder_layers_2_conv_depthwise_conv_weight_to_fp16, x = new_x_11_cast_fp16)[name = tensor<string, []>("x_73_cast_fp16")];
            tensor<int32, [3]> input_159_perm_0 = const()[name = tensor<string, []>("input_159_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_75_axes_0 = const()[name = tensor<string, []>("x_75_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_2_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(36800000)))];
            tensor<fp16, [512]> encoder_layers_2_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(36801088)))];
            tensor<fp16, [1, 17, 512]> input_159_cast_fp16 = transpose(perm = input_159_perm_0, x = x_73_cast_fp16)[name = tensor<string, []>("transpose_214")];
            tensor<fp16, [1, 17, 512]> x_75_cast_fp16 = layer_norm(axes = x_75_axes_0, beta = encoder_layers_2_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_2_conv_batch_norm_weight_to_fp16, x = input_159_cast_fp16)[name = tensor<string, []>("x_75_cast_fp16")];
            tensor<int32, [3]> input_161_perm_0 = const()[name = tensor<string, []>("input_161_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_161_cast_fp16 = transpose(perm = input_161_perm_0, x = x_75_cast_fp16)[name = tensor<string, []>("transpose_213")];
            tensor<fp16, [1, 512, 17]> input_163_cast_fp16 = silu(x = input_161_cast_fp16)[name = tensor<string, []>("input_163_cast_fp16")];
            tensor<string, []> x_77_pad_type_0 = const()[name = tensor<string, []>("x_77_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_77_strides_0 = const()[name = tensor<string, []>("x_77_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_77_pad_0 = const()[name = tensor<string, []>("x_77_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_77_dilations_0 = const()[name = tensor<string, []>("x_77_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_77_groups_0 = const()[name = tensor<string, []>("x_77_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_2_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(36802176)))];
            tensor<fp16, [1, 512, 17]> x_77_cast_fp16 = conv(dilations = x_77_dilations_0, groups = x_77_groups_0, pad = x_77_pad_0, pad_type = x_77_pad_type_0, strides = x_77_strides_0, weight = encoder_layers_2_conv_pointwise_conv2_weight_to_fp16, x = input_163_cast_fp16)[name = tensor<string, []>("x_77_cast_fp16")];
            tensor<int32, [3]> input_165_perm_0 = const()[name = tensor<string, []>("input_165_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_165_cast_fp16 = transpose(perm = input_165_perm_0, x = x_77_cast_fp16)[name = tensor<string, []>("transpose_212")];
            tensor<fp16, [1, 17, 512]> input_167_cast_fp16 = add(x = input_151_cast_fp16, y = input_165_cast_fp16)[name = tensor<string, []>("input_167_cast_fp16")];
            tensor<int32, [1]> input_169_axes_0 = const()[name = tensor<string, []>("input_169_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_2_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(37326528)))];
            tensor<fp16, [512]> encoder_layers_2_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(37327616)))];
            tensor<fp16, [1, 17, 512]> input_169_cast_fp16 = layer_norm(axes = input_169_axes_0, beta = encoder_layers_2_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_2_norm_feed_forward2_weight_to_fp16, x = input_167_cast_fp16)[name = tensor<string, []>("input_169_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_2_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(37328704)))];
            tensor<fp16, [1, 17, 2048]> linear_26_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_2_feed_forward2_linear1_weight_to_fp16, x = input_169_cast_fp16)[name = tensor<string, []>("linear_26_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_173_cast_fp16 = silu(x = linear_26_cast_fp16)[name = tensor<string, []>("input_173_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_2_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(39425920)))];
            tensor<fp16, [1, 17, 512]> linear_27_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_2_feed_forward2_linear2_weight_to_fp16, x = input_173_cast_fp16)[name = tensor<string, []>("linear_27_cast_fp16")];
            tensor<fp16, []> var_880_to_fp16 = const()[name = tensor<string, []>("op_880_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_881_cast_fp16 = mul(x = linear_27_cast_fp16, y = var_880_to_fp16)[name = tensor<string, []>("op_881_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_179_cast_fp16 = add(x = input_167_cast_fp16, y = var_881_cast_fp16)[name = tensor<string, []>("input_179_cast_fp16")];
            tensor<int32, [1]> input_181_axes_0 = const()[name = tensor<string, []>("input_181_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_2_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(41523136)))];
            tensor<fp16, [512]> encoder_layers_2_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_2_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(41524224)))];
            tensor<fp16, [1, 17, 512]> input_181_cast_fp16 = layer_norm(axes = input_181_axes_0, beta = encoder_layers_2_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_2_norm_out_weight_to_fp16, x = input_179_cast_fp16)[name = tensor<string, []>("input_181_cast_fp16")];
            tensor<int32, [4]> cache_13_begin_0 = const()[name = tensor<string, []>("cache_13_begin_0"), val = tensor<int32, [4]>([3, 0, 0, 0])];
            tensor<int32, [4]> cache_13_end_0 = const()[name = tensor<string, []>("cache_13_end_0"), val = tensor<int32, [4]>([4, 1, 70, 512])];
            tensor<bool, [4]> cache_13_end_mask_0 = const()[name = tensor<string, []>("cache_13_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_13_squeeze_mask_0 = const()[name = tensor<string, []>("cache_13_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_13_cast_fp16 = slice_by_index(begin = cache_13_begin_0, end = cache_13_end_0, end_mask = cache_13_end_mask_0, squeeze_mask = cache_13_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_13_cast_fp16")];
            tensor<int32, [4]> cache_15_begin_0 = const()[name = tensor<string, []>("cache_15_begin_0"), val = tensor<int32, [4]>([3, 0, 0, 0])];
            tensor<int32, [4]> cache_15_end_0 = const()[name = tensor<string, []>("cache_15_end_0"), val = tensor<int32, [4]>([4, 1, 512, 8])];
            tensor<bool, [4]> cache_15_end_mask_0 = const()[name = tensor<string, []>("cache_15_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_15_squeeze_mask_0 = const()[name = tensor<string, []>("cache_15_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_15_cast_fp16 = slice_by_index(begin = cache_15_begin_0, end = cache_15_end_0, end_mask = cache_15_end_mask_0, squeeze_mask = cache_15_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_15_cast_fp16")];
            tensor<int32, [1]> input_183_axes_0 = const()[name = tensor<string, []>("input_183_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_3_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(41525312)))];
            tensor<fp16, [512]> encoder_layers_3_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(41526400)))];
            tensor<fp16, [1, 17, 512]> input_183_cast_fp16 = layer_norm(axes = input_183_axes_0, beta = encoder_layers_3_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_3_norm_feed_forward1_weight_to_fp16, x = input_181_cast_fp16)[name = tensor<string, []>("input_183_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_3_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(41527488)))];
            tensor<fp16, [1, 17, 2048]> linear_28_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_3_feed_forward1_linear1_weight_to_fp16, x = input_183_cast_fp16)[name = tensor<string, []>("linear_28_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_187_cast_fp16 = silu(x = linear_28_cast_fp16)[name = tensor<string, []>("input_187_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_3_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(43624704)))];
            tensor<fp16, [1, 17, 512]> linear_29_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_3_feed_forward1_linear2_weight_to_fp16, x = input_187_cast_fp16)[name = tensor<string, []>("linear_29_cast_fp16")];
            tensor<fp16, []> var_915_to_fp16 = const()[name = tensor<string, []>("op_915_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_916_cast_fp16 = mul(x = linear_29_cast_fp16, y = var_915_to_fp16)[name = tensor<string, []>("op_916_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_193_cast_fp16 = add(x = input_181_cast_fp16, y = var_916_cast_fp16)[name = tensor<string, []>("input_193_cast_fp16")];
            tensor<int32, [1]> key_7_axes_0 = const()[name = tensor<string, []>("key_7_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_3_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(45721920)))];
            tensor<fp16, [512]> encoder_layers_3_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(45723008)))];
            tensor<fp16, [1, 17, 512]> key_7_cast_fp16 = layer_norm(axes = key_7_axes_0, beta = encoder_layers_3_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_3_norm_self_att_weight_to_fp16, x = input_193_cast_fp16)[name = tensor<string, []>("key_7_cast_fp16")];
            tensor<bool, []> input_195_interleave_0 = const()[name = tensor<string, []>("input_195_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_195_cast_fp16 = concat(axis = var_64, interleave = input_195_interleave_0, values = (cache_13_cast_fp16, key_7_cast_fp16))[name = tensor<string, []>("input_195_cast_fp16")];
            tensor<int32, [3]> var_938_begin_0 = const()[name = tensor<string, []>("op_938_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_938_end_0 = const()[name = tensor<string, []>("op_938_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_938_end_mask_0 = const()[name = tensor<string, []>("op_938_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_938_cast_fp16 = slice_by_index(begin = var_938_begin_0, end = var_938_end_0, end_mask = var_938_end_mask_0, x = cache_13_cast_fp16)[name = tensor<string, []>("op_938_cast_fp16")];
            tensor<bool, []> var_944_interleave_0 = const()[name = tensor<string, []>("op_944_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_944_cast_fp16 = concat(axis = var_64, interleave = var_944_interleave_0, values = (var_938_cast_fp16, key_7_cast_fp16))[name = tensor<string, []>("op_944_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_3_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(45724096)))];
            tensor<fp16, [1, 17, 512]> linear_30_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_3_self_attn_linear_q_weight_to_fp16, x = key_7_cast_fp16)[name = tensor<string, []>("linear_30_cast_fp16")];
            tensor<int32, [4]> var_948 = const()[name = tensor<string, []>("op_948"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_19_cast_fp16 = reshape(shape = var_948, x = linear_30_cast_fp16)[name = tensor<string, []>("q_19_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_3_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(46248448)))];
            tensor<fp16, [1, 87, 512]> linear_31_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_3_self_attn_linear_k_weight_to_fp16, x = input_195_cast_fp16)[name = tensor<string, []>("linear_31_cast_fp16")];
            tensor<int32, [4]> var_952 = const()[name = tensor<string, []>("op_952"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_13_cast_fp16 = reshape(shape = var_952, x = linear_31_cast_fp16)[name = tensor<string, []>("k_13_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_3_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(46772800)))];
            tensor<fp16, [1, 87, 512]> linear_32_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_3_self_attn_linear_v_weight_to_fp16, x = input_195_cast_fp16)[name = tensor<string, []>("linear_32_cast_fp16")];
            tensor<int32, [4]> var_956 = const()[name = tensor<string, []>("op_956"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_7_cast_fp16 = reshape(shape = var_956, x = linear_32_cast_fp16)[name = tensor<string, []>("v_7_cast_fp16")];
            tensor<int32, [4]> value_9_perm_0 = const()[name = tensor<string, []>("value_9_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_3_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47297152)))];
            tensor<fp16, [1, 17, 8, 64]> var_968_cast_fp16 = add(x = q_19_cast_fp16, y = encoder_layers_3_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_968_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_3_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47298240)))];
            tensor<fp16, [1, 17, 8, 64]> var_970_cast_fp16 = add(x = q_19_cast_fp16, y = encoder_layers_3_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_970_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_7_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_7_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_85_transpose_x_0 = const()[name = tensor<string, []>("x_85_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_85_transpose_y_0 = const()[name = tensor<string, []>("x_85_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_972_to_fp16 = const()[name = tensor<string, []>("op_972_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47299328)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_7_cast_fp16 = transpose(perm = q_with_bias_v_7_perm_0, x = var_970_cast_fp16)[name = tensor<string, []>("transpose_210")];
            tensor<fp16, [1, 8, 17, 173]> x_85_cast_fp16 = matmul(transpose_x = x_85_transpose_x_0, transpose_y = x_85_transpose_y_0, x = q_with_bias_v_7_cast_fp16, y = var_972_to_fp16)[name = tensor<string, []>("x_85_cast_fp16")];
            tensor<int32, [8]> x_87_pad_0 = const()[name = tensor<string, []>("x_87_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_87_mode_0 = const()[name = tensor<string, []>("x_87_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_62_to_fp16 = const()[name = tensor<string, []>("const_62_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_87_cast_fp16 = pad(constant_val = const_62_to_fp16, mode = x_87_mode_0, pad = x_87_pad_0, x = x_85_cast_fp16)[name = tensor<string, []>("x_87_cast_fp16")];
            tensor<int32, [4]> var_980 = const()[name = tensor<string, []>("op_980"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_89_cast_fp16 = reshape(shape = var_980, x = x_87_cast_fp16)[name = tensor<string, []>("x_89_cast_fp16")];
            tensor<int32, [4]> var_984_begin_0 = const()[name = tensor<string, []>("op_984_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_984_end_0 = const()[name = tensor<string, []>("op_984_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_984_end_mask_0 = const()[name = tensor<string, []>("op_984_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_984_cast_fp16 = slice_by_index(begin = var_984_begin_0, end = var_984_end_0, end_mask = var_984_end_mask_0, x = x_89_cast_fp16)[name = tensor<string, []>("op_984_cast_fp16")];
            tensor<int32, [4]> var_985 = const()[name = tensor<string, []>("op_985"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_13_cast_fp16 = reshape(shape = var_985, x = var_984_cast_fp16)[name = tensor<string, []>("matrix_bd_13_cast_fp16")];
            tensor<bool, []> matrix_ac_7_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_7_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_7_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_57_perm_0 = const()[name = tensor<string, []>("transpose_57_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_58_perm_0 = const()[name = tensor<string, []>("transpose_58_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_58 = transpose(perm = transpose_58_perm_0, x = k_13_cast_fp16)[name = tensor<string, []>("transpose_208")];
            tensor<fp16, [1, 8, 17, 64]> transpose_57 = transpose(perm = transpose_57_perm_0, x = var_968_cast_fp16)[name = tensor<string, []>("transpose_209")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_7_cast_fp16 = matmul(transpose_x = matrix_ac_7_transpose_x_0, transpose_y = matrix_ac_7_transpose_y_0, x = transpose_57, y = transpose_58)[name = tensor<string, []>("matrix_ac_7_cast_fp16")];
            tensor<int32, [4]> matrix_bd_15_begin_0 = const()[name = tensor<string, []>("matrix_bd_15_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_15_end_0 = const()[name = tensor<string, []>("matrix_bd_15_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_15_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_15_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_15_cast_fp16 = slice_by_index(begin = matrix_bd_15_begin_0, end = matrix_bd_15_end_0, end_mask = matrix_bd_15_end_mask_0, x = matrix_bd_13_cast_fp16)[name = tensor<string, []>("matrix_bd_15_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_994_cast_fp16 = add(x = matrix_ac_7_cast_fp16, y = matrix_bd_15_cast_fp16)[name = tensor<string, []>("op_994_cast_fp16")];
            tensor<fp16, []> _inversed_scores_13_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_13_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_13_cast_fp16 = mul(x = var_994_cast_fp16, y = _inversed_scores_13_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_13_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_15_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_13_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_15_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_1000_cast_fp16 = softmax(axis = var_62, x = scores_15_cast_fp16)[name = tensor<string, []>("op_1000_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_197_cast_fp16 = select(a = var_40_to_fp16, b = var_1000_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_197_cast_fp16")];
            tensor<bool, []> x_91_transpose_x_0 = const()[name = tensor<string, []>("x_91_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_91_transpose_y_0 = const()[name = tensor<string, []>("x_91_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_9_cast_fp16 = transpose(perm = value_9_perm_0, x = v_7_cast_fp16)[name = tensor<string, []>("transpose_211")];
            tensor<fp16, [1, 8, 17, 64]> x_91_cast_fp16 = matmul(transpose_x = x_91_transpose_x_0, transpose_y = x_91_transpose_y_0, x = input_197_cast_fp16, y = value_9_cast_fp16)[name = tensor<string, []>("x_91_cast_fp16")];
            tensor<int32, [4]> var_1004_perm_0 = const()[name = tensor<string, []>("op_1004_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1005 = const()[name = tensor<string, []>("op_1005"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_1004_cast_fp16 = transpose(perm = var_1004_perm_0, x = x_91_cast_fp16)[name = tensor<string, []>("transpose_207")];
            tensor<fp16, [1, 17, 512]> input_199_cast_fp16 = reshape(shape = var_1005, x = var_1004_cast_fp16)[name = tensor<string, []>("input_199_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_3_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47476544)))];
            tensor<fp16, [1, 17, 512]> linear_34_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_3_self_attn_linear_out_weight_to_fp16, x = input_199_cast_fp16)[name = tensor<string, []>("linear_34_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_203_cast_fp16 = add(x = input_193_cast_fp16, y = linear_34_cast_fp16)[name = tensor<string, []>("input_203_cast_fp16")];
            tensor<int32, [1]> x_95_axes_0 = const()[name = tensor<string, []>("x_95_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_3_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(48000896)))];
            tensor<fp16, [512]> encoder_layers_3_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(48001984)))];
            tensor<fp16, [1, 17, 512]> x_95_cast_fp16 = layer_norm(axes = x_95_axes_0, beta = encoder_layers_3_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_3_norm_conv_weight_to_fp16, x = input_203_cast_fp16)[name = tensor<string, []>("x_95_cast_fp16")];
            tensor<int32, [3]> input_205_perm_0 = const()[name = tensor<string, []>("input_205_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_207_pad_type_0 = const()[name = tensor<string, []>("input_207_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_207_strides_0 = const()[name = tensor<string, []>("input_207_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_207_pad_0 = const()[name = tensor<string, []>("input_207_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_207_dilations_0 = const()[name = tensor<string, []>("input_207_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_207_groups_0 = const()[name = tensor<string, []>("input_207_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_3_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(48003072)))];
            tensor<fp16, [1, 512, 17]> input_205_cast_fp16 = transpose(perm = input_205_perm_0, x = x_95_cast_fp16)[name = tensor<string, []>("transpose_206")];
            tensor<fp16, [1, 1024, 17]> input_207_cast_fp16 = conv(dilations = input_207_dilations_0, groups = input_207_groups_0, pad = input_207_pad_0, pad_type = input_207_pad_type_0, strides = input_207_strides_0, weight = encoder_layers_3_conv_pointwise_conv1_weight_to_fp16, x = input_205_cast_fp16)[name = tensor<string, []>("input_207_cast_fp16")];
            tensor<int32, []> x_97_split_num_splits_0 = const()[name = tensor<string, []>("x_97_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_97_split_axis_0 = const()[name = tensor<string, []>("x_97_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_97_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_97_split_cast_fp16_1 = split(axis = x_97_split_axis_0, num_splits = x_97_split_num_splits_0, x = input_207_cast_fp16)[name = tensor<string, []>("x_97_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_97_split_1_sigmoid_cast_fp16 = sigmoid(x = x_97_split_cast_fp16_1)[name = tensor<string, []>("x_97_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_97_cast_fp16 = mul(x = x_97_split_cast_fp16_0, y = x_97_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_97_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_209_cast_fp16 = select(a = var_40_to_fp16, b = x_97_cast_fp16, cond = var_418)[name = tensor<string, []>("input_209_cast_fp16")];
            tensor<bool, []> new_x_15_interleave_0 = const()[name = tensor<string, []>("new_x_15_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_15_cast_fp16 = concat(axis = var_62, interleave = new_x_15_interleave_0, values = (cache_15_cast_fp16, input_209_cast_fp16))[name = tensor<string, []>("new_x_15_cast_fp16")];
            tensor<int32, [3]> var_1043_begin_0 = const()[name = tensor<string, []>("op_1043_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_1043_end_0 = const()[name = tensor<string, []>("op_1043_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_1043_end_mask_0 = const()[name = tensor<string, []>("op_1043_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_1043_cast_fp16 = slice_by_index(begin = var_1043_begin_0, end = var_1043_end_0, end_mask = var_1043_end_mask_0, x = new_x_15_cast_fp16)[name = tensor<string, []>("op_1043_cast_fp16")];
            tensor<string, []> x_99_pad_type_0 = const()[name = tensor<string, []>("x_99_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_99_groups_0 = const()[name = tensor<string, []>("x_99_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_99_strides_0 = const()[name = tensor<string, []>("x_99_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_99_pad_0 = const()[name = tensor<string, []>("x_99_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_99_dilations_0 = const()[name = tensor<string, []>("x_99_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_3_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(49051712)))];
            tensor<fp16, [1, 512, 17]> x_99_cast_fp16 = conv(dilations = x_99_dilations_0, groups = x_99_groups_0, pad = x_99_pad_0, pad_type = x_99_pad_type_0, strides = x_99_strides_0, weight = encoder_layers_3_conv_depthwise_conv_weight_to_fp16, x = new_x_15_cast_fp16)[name = tensor<string, []>("x_99_cast_fp16")];
            tensor<int32, [3]> input_211_perm_0 = const()[name = tensor<string, []>("input_211_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_101_axes_0 = const()[name = tensor<string, []>("x_101_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_3_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(49060992)))];
            tensor<fp16, [512]> encoder_layers_3_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(49062080)))];
            tensor<fp16, [1, 17, 512]> input_211_cast_fp16 = transpose(perm = input_211_perm_0, x = x_99_cast_fp16)[name = tensor<string, []>("transpose_205")];
            tensor<fp16, [1, 17, 512]> x_101_cast_fp16 = layer_norm(axes = x_101_axes_0, beta = encoder_layers_3_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_3_conv_batch_norm_weight_to_fp16, x = input_211_cast_fp16)[name = tensor<string, []>("x_101_cast_fp16")];
            tensor<int32, [3]> input_213_perm_0 = const()[name = tensor<string, []>("input_213_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_213_cast_fp16 = transpose(perm = input_213_perm_0, x = x_101_cast_fp16)[name = tensor<string, []>("transpose_204")];
            tensor<fp16, [1, 512, 17]> input_215_cast_fp16 = silu(x = input_213_cast_fp16)[name = tensor<string, []>("input_215_cast_fp16")];
            tensor<string, []> x_103_pad_type_0 = const()[name = tensor<string, []>("x_103_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_103_strides_0 = const()[name = tensor<string, []>("x_103_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_103_pad_0 = const()[name = tensor<string, []>("x_103_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_103_dilations_0 = const()[name = tensor<string, []>("x_103_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_103_groups_0 = const()[name = tensor<string, []>("x_103_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_3_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(49063168)))];
            tensor<fp16, [1, 512, 17]> x_103_cast_fp16 = conv(dilations = x_103_dilations_0, groups = x_103_groups_0, pad = x_103_pad_0, pad_type = x_103_pad_type_0, strides = x_103_strides_0, weight = encoder_layers_3_conv_pointwise_conv2_weight_to_fp16, x = input_215_cast_fp16)[name = tensor<string, []>("x_103_cast_fp16")];
            tensor<int32, [3]> input_217_perm_0 = const()[name = tensor<string, []>("input_217_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_217_cast_fp16 = transpose(perm = input_217_perm_0, x = x_103_cast_fp16)[name = tensor<string, []>("transpose_203")];
            tensor<fp16, [1, 17, 512]> input_219_cast_fp16 = add(x = input_203_cast_fp16, y = input_217_cast_fp16)[name = tensor<string, []>("input_219_cast_fp16")];
            tensor<int32, [1]> input_221_axes_0 = const()[name = tensor<string, []>("input_221_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_3_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(49587520)))];
            tensor<fp16, [512]> encoder_layers_3_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(49588608)))];
            tensor<fp16, [1, 17, 512]> input_221_cast_fp16 = layer_norm(axes = input_221_axes_0, beta = encoder_layers_3_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_3_norm_feed_forward2_weight_to_fp16, x = input_219_cast_fp16)[name = tensor<string, []>("input_221_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_3_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(49589696)))];
            tensor<fp16, [1, 17, 2048]> linear_35_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_3_feed_forward2_linear1_weight_to_fp16, x = input_221_cast_fp16)[name = tensor<string, []>("linear_35_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_225_cast_fp16 = silu(x = linear_35_cast_fp16)[name = tensor<string, []>("input_225_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_3_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(51686912)))];
            tensor<fp16, [1, 17, 512]> linear_36_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_3_feed_forward2_linear2_weight_to_fp16, x = input_225_cast_fp16)[name = tensor<string, []>("linear_36_cast_fp16")];
            tensor<fp16, []> var_1084_to_fp16 = const()[name = tensor<string, []>("op_1084_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1085_cast_fp16 = mul(x = linear_36_cast_fp16, y = var_1084_to_fp16)[name = tensor<string, []>("op_1085_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_231_cast_fp16 = add(x = input_219_cast_fp16, y = var_1085_cast_fp16)[name = tensor<string, []>("input_231_cast_fp16")];
            tensor<int32, [1]> input_233_axes_0 = const()[name = tensor<string, []>("input_233_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_3_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(53784128)))];
            tensor<fp16, [512]> encoder_layers_3_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_3_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(53785216)))];
            tensor<fp16, [1, 17, 512]> input_233_cast_fp16 = layer_norm(axes = input_233_axes_0, beta = encoder_layers_3_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_3_norm_out_weight_to_fp16, x = input_231_cast_fp16)[name = tensor<string, []>("input_233_cast_fp16")];
            tensor<int32, [4]> cache_17_begin_0 = const()[name = tensor<string, []>("cache_17_begin_0"), val = tensor<int32, [4]>([4, 0, 0, 0])];
            tensor<int32, [4]> cache_17_end_0 = const()[name = tensor<string, []>("cache_17_end_0"), val = tensor<int32, [4]>([5, 1, 70, 512])];
            tensor<bool, [4]> cache_17_end_mask_0 = const()[name = tensor<string, []>("cache_17_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_17_squeeze_mask_0 = const()[name = tensor<string, []>("cache_17_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_17_cast_fp16 = slice_by_index(begin = cache_17_begin_0, end = cache_17_end_0, end_mask = cache_17_end_mask_0, squeeze_mask = cache_17_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_17_cast_fp16")];
            tensor<int32, [4]> cache_19_begin_0 = const()[name = tensor<string, []>("cache_19_begin_0"), val = tensor<int32, [4]>([4, 0, 0, 0])];
            tensor<int32, [4]> cache_19_end_0 = const()[name = tensor<string, []>("cache_19_end_0"), val = tensor<int32, [4]>([5, 1, 512, 8])];
            tensor<bool, [4]> cache_19_end_mask_0 = const()[name = tensor<string, []>("cache_19_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_19_squeeze_mask_0 = const()[name = tensor<string, []>("cache_19_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_19_cast_fp16 = slice_by_index(begin = cache_19_begin_0, end = cache_19_end_0, end_mask = cache_19_end_mask_0, squeeze_mask = cache_19_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_19_cast_fp16")];
            tensor<int32, [1]> input_235_axes_0 = const()[name = tensor<string, []>("input_235_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_4_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(53786304)))];
            tensor<fp16, [512]> encoder_layers_4_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(53787392)))];
            tensor<fp16, [1, 17, 512]> input_235_cast_fp16 = layer_norm(axes = input_235_axes_0, beta = encoder_layers_4_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_4_norm_feed_forward1_weight_to_fp16, x = input_233_cast_fp16)[name = tensor<string, []>("input_235_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_4_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(53788480)))];
            tensor<fp16, [1, 17, 2048]> linear_37_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_4_feed_forward1_linear1_weight_to_fp16, x = input_235_cast_fp16)[name = tensor<string, []>("linear_37_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_239_cast_fp16 = silu(x = linear_37_cast_fp16)[name = tensor<string, []>("input_239_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_4_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(55885696)))];
            tensor<fp16, [1, 17, 512]> linear_38_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_4_feed_forward1_linear2_weight_to_fp16, x = input_239_cast_fp16)[name = tensor<string, []>("linear_38_cast_fp16")];
            tensor<fp16, []> var_1119_to_fp16 = const()[name = tensor<string, []>("op_1119_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1120_cast_fp16 = mul(x = linear_38_cast_fp16, y = var_1119_to_fp16)[name = tensor<string, []>("op_1120_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_245_cast_fp16 = add(x = input_233_cast_fp16, y = var_1120_cast_fp16)[name = tensor<string, []>("input_245_cast_fp16")];
            tensor<int32, [1]> key_9_axes_0 = const()[name = tensor<string, []>("key_9_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_4_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(57982912)))];
            tensor<fp16, [512]> encoder_layers_4_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(57984000)))];
            tensor<fp16, [1, 17, 512]> key_9_cast_fp16 = layer_norm(axes = key_9_axes_0, beta = encoder_layers_4_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_4_norm_self_att_weight_to_fp16, x = input_245_cast_fp16)[name = tensor<string, []>("key_9_cast_fp16")];
            tensor<bool, []> input_247_interleave_0 = const()[name = tensor<string, []>("input_247_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_247_cast_fp16 = concat(axis = var_64, interleave = input_247_interleave_0, values = (cache_17_cast_fp16, key_9_cast_fp16))[name = tensor<string, []>("input_247_cast_fp16")];
            tensor<int32, [3]> var_1142_begin_0 = const()[name = tensor<string, []>("op_1142_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_1142_end_0 = const()[name = tensor<string, []>("op_1142_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_1142_end_mask_0 = const()[name = tensor<string, []>("op_1142_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_1142_cast_fp16 = slice_by_index(begin = var_1142_begin_0, end = var_1142_end_0, end_mask = var_1142_end_mask_0, x = cache_17_cast_fp16)[name = tensor<string, []>("op_1142_cast_fp16")];
            tensor<bool, []> var_1148_interleave_0 = const()[name = tensor<string, []>("op_1148_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_1148_cast_fp16 = concat(axis = var_64, interleave = var_1148_interleave_0, values = (var_1142_cast_fp16, key_9_cast_fp16))[name = tensor<string, []>("op_1148_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_4_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(57985088)))];
            tensor<fp16, [1, 17, 512]> linear_39_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_4_self_attn_linear_q_weight_to_fp16, x = key_9_cast_fp16)[name = tensor<string, []>("linear_39_cast_fp16")];
            tensor<int32, [4]> var_1152 = const()[name = tensor<string, []>("op_1152"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_25_cast_fp16 = reshape(shape = var_1152, x = linear_39_cast_fp16)[name = tensor<string, []>("q_25_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_4_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(58509440)))];
            tensor<fp16, [1, 87, 512]> linear_40_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_4_self_attn_linear_k_weight_to_fp16, x = input_247_cast_fp16)[name = tensor<string, []>("linear_40_cast_fp16")];
            tensor<int32, [4]> var_1156 = const()[name = tensor<string, []>("op_1156"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_17_cast_fp16 = reshape(shape = var_1156, x = linear_40_cast_fp16)[name = tensor<string, []>("k_17_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_4_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59033792)))];
            tensor<fp16, [1, 87, 512]> linear_41_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_4_self_attn_linear_v_weight_to_fp16, x = input_247_cast_fp16)[name = tensor<string, []>("linear_41_cast_fp16")];
            tensor<int32, [4]> var_1160 = const()[name = tensor<string, []>("op_1160"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_9_cast_fp16 = reshape(shape = var_1160, x = linear_41_cast_fp16)[name = tensor<string, []>("v_9_cast_fp16")];
            tensor<int32, [4]> value_11_perm_0 = const()[name = tensor<string, []>("value_11_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_4_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59558144)))];
            tensor<fp16, [1, 17, 8, 64]> var_1172_cast_fp16 = add(x = q_25_cast_fp16, y = encoder_layers_4_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_1172_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_4_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59559232)))];
            tensor<fp16, [1, 17, 8, 64]> var_1174_cast_fp16 = add(x = q_25_cast_fp16, y = encoder_layers_4_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_1174_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_9_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_9_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_111_transpose_x_0 = const()[name = tensor<string, []>("x_111_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_111_transpose_y_0 = const()[name = tensor<string, []>("x_111_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_1176_to_fp16 = const()[name = tensor<string, []>("op_1176_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59560320)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_9_cast_fp16 = transpose(perm = q_with_bias_v_9_perm_0, x = var_1174_cast_fp16)[name = tensor<string, []>("transpose_201")];
            tensor<fp16, [1, 8, 17, 173]> x_111_cast_fp16 = matmul(transpose_x = x_111_transpose_x_0, transpose_y = x_111_transpose_y_0, x = q_with_bias_v_9_cast_fp16, y = var_1176_to_fp16)[name = tensor<string, []>("x_111_cast_fp16")];
            tensor<int32, [8]> x_113_pad_0 = const()[name = tensor<string, []>("x_113_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_113_mode_0 = const()[name = tensor<string, []>("x_113_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_75_to_fp16 = const()[name = tensor<string, []>("const_75_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_113_cast_fp16 = pad(constant_val = const_75_to_fp16, mode = x_113_mode_0, pad = x_113_pad_0, x = x_111_cast_fp16)[name = tensor<string, []>("x_113_cast_fp16")];
            tensor<int32, [4]> var_1184 = const()[name = tensor<string, []>("op_1184"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_115_cast_fp16 = reshape(shape = var_1184, x = x_113_cast_fp16)[name = tensor<string, []>("x_115_cast_fp16")];
            tensor<int32, [4]> var_1188_begin_0 = const()[name = tensor<string, []>("op_1188_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_1188_end_0 = const()[name = tensor<string, []>("op_1188_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_1188_end_mask_0 = const()[name = tensor<string, []>("op_1188_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_1188_cast_fp16 = slice_by_index(begin = var_1188_begin_0, end = var_1188_end_0, end_mask = var_1188_end_mask_0, x = x_115_cast_fp16)[name = tensor<string, []>("op_1188_cast_fp16")];
            tensor<int32, [4]> var_1189 = const()[name = tensor<string, []>("op_1189"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_17_cast_fp16 = reshape(shape = var_1189, x = var_1188_cast_fp16)[name = tensor<string, []>("matrix_bd_17_cast_fp16")];
            tensor<bool, []> matrix_ac_9_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_9_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_9_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_9_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_59_perm_0 = const()[name = tensor<string, []>("transpose_59_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_60_perm_0 = const()[name = tensor<string, []>("transpose_60_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_60 = transpose(perm = transpose_60_perm_0, x = k_17_cast_fp16)[name = tensor<string, []>("transpose_199")];
            tensor<fp16, [1, 8, 17, 64]> transpose_59 = transpose(perm = transpose_59_perm_0, x = var_1172_cast_fp16)[name = tensor<string, []>("transpose_200")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_9_cast_fp16 = matmul(transpose_x = matrix_ac_9_transpose_x_0, transpose_y = matrix_ac_9_transpose_y_0, x = transpose_59, y = transpose_60)[name = tensor<string, []>("matrix_ac_9_cast_fp16")];
            tensor<int32, [4]> matrix_bd_19_begin_0 = const()[name = tensor<string, []>("matrix_bd_19_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_19_end_0 = const()[name = tensor<string, []>("matrix_bd_19_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_19_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_19_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_19_cast_fp16 = slice_by_index(begin = matrix_bd_19_begin_0, end = matrix_bd_19_end_0, end_mask = matrix_bd_19_end_mask_0, x = matrix_bd_17_cast_fp16)[name = tensor<string, []>("matrix_bd_19_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_1198_cast_fp16 = add(x = matrix_ac_9_cast_fp16, y = matrix_bd_19_cast_fp16)[name = tensor<string, []>("op_1198_cast_fp16")];
            tensor<fp16, []> _inversed_scores_17_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_17_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_17_cast_fp16 = mul(x = var_1198_cast_fp16, y = _inversed_scores_17_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_17_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_19_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_17_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_19_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_1204_cast_fp16 = softmax(axis = var_62, x = scores_19_cast_fp16)[name = tensor<string, []>("op_1204_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_249_cast_fp16 = select(a = var_40_to_fp16, b = var_1204_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_249_cast_fp16")];
            tensor<bool, []> x_117_transpose_x_0 = const()[name = tensor<string, []>("x_117_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_117_transpose_y_0 = const()[name = tensor<string, []>("x_117_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_11_cast_fp16 = transpose(perm = value_11_perm_0, x = v_9_cast_fp16)[name = tensor<string, []>("transpose_202")];
            tensor<fp16, [1, 8, 17, 64]> x_117_cast_fp16 = matmul(transpose_x = x_117_transpose_x_0, transpose_y = x_117_transpose_y_0, x = input_249_cast_fp16, y = value_11_cast_fp16)[name = tensor<string, []>("x_117_cast_fp16")];
            tensor<int32, [4]> var_1208_perm_0 = const()[name = tensor<string, []>("op_1208_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1209 = const()[name = tensor<string, []>("op_1209"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_1208_cast_fp16 = transpose(perm = var_1208_perm_0, x = x_117_cast_fp16)[name = tensor<string, []>("transpose_198")];
            tensor<fp16, [1, 17, 512]> input_251_cast_fp16 = reshape(shape = var_1209, x = var_1208_cast_fp16)[name = tensor<string, []>("input_251_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_4_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59737536)))];
            tensor<fp16, [1, 17, 512]> linear_43_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_4_self_attn_linear_out_weight_to_fp16, x = input_251_cast_fp16)[name = tensor<string, []>("linear_43_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_255_cast_fp16 = add(x = input_245_cast_fp16, y = linear_43_cast_fp16)[name = tensor<string, []>("input_255_cast_fp16")];
            tensor<int32, [1]> x_121_axes_0 = const()[name = tensor<string, []>("x_121_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_4_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(60261888)))];
            tensor<fp16, [512]> encoder_layers_4_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(60262976)))];
            tensor<fp16, [1, 17, 512]> x_121_cast_fp16 = layer_norm(axes = x_121_axes_0, beta = encoder_layers_4_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_4_norm_conv_weight_to_fp16, x = input_255_cast_fp16)[name = tensor<string, []>("x_121_cast_fp16")];
            tensor<int32, [3]> input_257_perm_0 = const()[name = tensor<string, []>("input_257_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_259_pad_type_0 = const()[name = tensor<string, []>("input_259_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_259_strides_0 = const()[name = tensor<string, []>("input_259_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_259_pad_0 = const()[name = tensor<string, []>("input_259_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_259_dilations_0 = const()[name = tensor<string, []>("input_259_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_259_groups_0 = const()[name = tensor<string, []>("input_259_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_4_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(60264064)))];
            tensor<fp16, [1, 512, 17]> input_257_cast_fp16 = transpose(perm = input_257_perm_0, x = x_121_cast_fp16)[name = tensor<string, []>("transpose_197")];
            tensor<fp16, [1, 1024, 17]> input_259_cast_fp16 = conv(dilations = input_259_dilations_0, groups = input_259_groups_0, pad = input_259_pad_0, pad_type = input_259_pad_type_0, strides = input_259_strides_0, weight = encoder_layers_4_conv_pointwise_conv1_weight_to_fp16, x = input_257_cast_fp16)[name = tensor<string, []>("input_259_cast_fp16")];
            tensor<int32, []> x_123_split_num_splits_0 = const()[name = tensor<string, []>("x_123_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_123_split_axis_0 = const()[name = tensor<string, []>("x_123_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_123_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_123_split_cast_fp16_1 = split(axis = x_123_split_axis_0, num_splits = x_123_split_num_splits_0, x = input_259_cast_fp16)[name = tensor<string, []>("x_123_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_123_split_1_sigmoid_cast_fp16 = sigmoid(x = x_123_split_cast_fp16_1)[name = tensor<string, []>("x_123_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_123_cast_fp16 = mul(x = x_123_split_cast_fp16_0, y = x_123_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_123_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_261_cast_fp16 = select(a = var_40_to_fp16, b = x_123_cast_fp16, cond = var_418)[name = tensor<string, []>("input_261_cast_fp16")];
            tensor<bool, []> new_x_19_interleave_0 = const()[name = tensor<string, []>("new_x_19_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_19_cast_fp16 = concat(axis = var_62, interleave = new_x_19_interleave_0, values = (cache_19_cast_fp16, input_261_cast_fp16))[name = tensor<string, []>("new_x_19_cast_fp16")];
            tensor<int32, [3]> var_1247_begin_0 = const()[name = tensor<string, []>("op_1247_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_1247_end_0 = const()[name = tensor<string, []>("op_1247_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_1247_end_mask_0 = const()[name = tensor<string, []>("op_1247_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_1247_cast_fp16 = slice_by_index(begin = var_1247_begin_0, end = var_1247_end_0, end_mask = var_1247_end_mask_0, x = new_x_19_cast_fp16)[name = tensor<string, []>("op_1247_cast_fp16")];
            tensor<string, []> x_125_pad_type_0 = const()[name = tensor<string, []>("x_125_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_125_groups_0 = const()[name = tensor<string, []>("x_125_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_125_strides_0 = const()[name = tensor<string, []>("x_125_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_125_pad_0 = const()[name = tensor<string, []>("x_125_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_125_dilations_0 = const()[name = tensor<string, []>("x_125_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_4_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61312704)))];
            tensor<fp16, [1, 512, 17]> x_125_cast_fp16 = conv(dilations = x_125_dilations_0, groups = x_125_groups_0, pad = x_125_pad_0, pad_type = x_125_pad_type_0, strides = x_125_strides_0, weight = encoder_layers_4_conv_depthwise_conv_weight_to_fp16, x = new_x_19_cast_fp16)[name = tensor<string, []>("x_125_cast_fp16")];
            tensor<int32, [3]> input_263_perm_0 = const()[name = tensor<string, []>("input_263_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_127_axes_0 = const()[name = tensor<string, []>("x_127_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_4_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61321984)))];
            tensor<fp16, [512]> encoder_layers_4_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61323072)))];
            tensor<fp16, [1, 17, 512]> input_263_cast_fp16 = transpose(perm = input_263_perm_0, x = x_125_cast_fp16)[name = tensor<string, []>("transpose_196")];
            tensor<fp16, [1, 17, 512]> x_127_cast_fp16 = layer_norm(axes = x_127_axes_0, beta = encoder_layers_4_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_4_conv_batch_norm_weight_to_fp16, x = input_263_cast_fp16)[name = tensor<string, []>("x_127_cast_fp16")];
            tensor<int32, [3]> input_265_perm_0 = const()[name = tensor<string, []>("input_265_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_265_cast_fp16 = transpose(perm = input_265_perm_0, x = x_127_cast_fp16)[name = tensor<string, []>("transpose_195")];
            tensor<fp16, [1, 512, 17]> input_267_cast_fp16 = silu(x = input_265_cast_fp16)[name = tensor<string, []>("input_267_cast_fp16")];
            tensor<string, []> x_129_pad_type_0 = const()[name = tensor<string, []>("x_129_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_129_strides_0 = const()[name = tensor<string, []>("x_129_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_129_pad_0 = const()[name = tensor<string, []>("x_129_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_129_dilations_0 = const()[name = tensor<string, []>("x_129_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_129_groups_0 = const()[name = tensor<string, []>("x_129_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_4_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61324160)))];
            tensor<fp16, [1, 512, 17]> x_129_cast_fp16 = conv(dilations = x_129_dilations_0, groups = x_129_groups_0, pad = x_129_pad_0, pad_type = x_129_pad_type_0, strides = x_129_strides_0, weight = encoder_layers_4_conv_pointwise_conv2_weight_to_fp16, x = input_267_cast_fp16)[name = tensor<string, []>("x_129_cast_fp16")];
            tensor<int32, [3]> input_269_perm_0 = const()[name = tensor<string, []>("input_269_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_269_cast_fp16 = transpose(perm = input_269_perm_0, x = x_129_cast_fp16)[name = tensor<string, []>("transpose_194")];
            tensor<fp16, [1, 17, 512]> input_271_cast_fp16 = add(x = input_255_cast_fp16, y = input_269_cast_fp16)[name = tensor<string, []>("input_271_cast_fp16")];
            tensor<int32, [1]> input_273_axes_0 = const()[name = tensor<string, []>("input_273_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_4_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61848512)))];
            tensor<fp16, [512]> encoder_layers_4_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61849600)))];
            tensor<fp16, [1, 17, 512]> input_273_cast_fp16 = layer_norm(axes = input_273_axes_0, beta = encoder_layers_4_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_4_norm_feed_forward2_weight_to_fp16, x = input_271_cast_fp16)[name = tensor<string, []>("input_273_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_4_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61850688)))];
            tensor<fp16, [1, 17, 2048]> linear_44_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_4_feed_forward2_linear1_weight_to_fp16, x = input_273_cast_fp16)[name = tensor<string, []>("linear_44_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_277_cast_fp16 = silu(x = linear_44_cast_fp16)[name = tensor<string, []>("input_277_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_4_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(63947904)))];
            tensor<fp16, [1, 17, 512]> linear_45_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_4_feed_forward2_linear2_weight_to_fp16, x = input_277_cast_fp16)[name = tensor<string, []>("linear_45_cast_fp16")];
            tensor<fp16, []> var_1288_to_fp16 = const()[name = tensor<string, []>("op_1288_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1289_cast_fp16 = mul(x = linear_45_cast_fp16, y = var_1288_to_fp16)[name = tensor<string, []>("op_1289_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_283_cast_fp16 = add(x = input_271_cast_fp16, y = var_1289_cast_fp16)[name = tensor<string, []>("input_283_cast_fp16")];
            tensor<int32, [1]> input_285_axes_0 = const()[name = tensor<string, []>("input_285_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_4_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(66045120)))];
            tensor<fp16, [512]> encoder_layers_4_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_4_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(66046208)))];
            tensor<fp16, [1, 17, 512]> input_285_cast_fp16 = layer_norm(axes = input_285_axes_0, beta = encoder_layers_4_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_4_norm_out_weight_to_fp16, x = input_283_cast_fp16)[name = tensor<string, []>("input_285_cast_fp16")];
            tensor<int32, [4]> cache_21_begin_0 = const()[name = tensor<string, []>("cache_21_begin_0"), val = tensor<int32, [4]>([5, 0, 0, 0])];
            tensor<int32, [4]> cache_21_end_0 = const()[name = tensor<string, []>("cache_21_end_0"), val = tensor<int32, [4]>([6, 1, 70, 512])];
            tensor<bool, [4]> cache_21_end_mask_0 = const()[name = tensor<string, []>("cache_21_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_21_squeeze_mask_0 = const()[name = tensor<string, []>("cache_21_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_21_cast_fp16 = slice_by_index(begin = cache_21_begin_0, end = cache_21_end_0, end_mask = cache_21_end_mask_0, squeeze_mask = cache_21_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_21_cast_fp16")];
            tensor<int32, [4]> cache_23_begin_0 = const()[name = tensor<string, []>("cache_23_begin_0"), val = tensor<int32, [4]>([5, 0, 0, 0])];
            tensor<int32, [4]> cache_23_end_0 = const()[name = tensor<string, []>("cache_23_end_0"), val = tensor<int32, [4]>([6, 1, 512, 8])];
            tensor<bool, [4]> cache_23_end_mask_0 = const()[name = tensor<string, []>("cache_23_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_23_squeeze_mask_0 = const()[name = tensor<string, []>("cache_23_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_23_cast_fp16 = slice_by_index(begin = cache_23_begin_0, end = cache_23_end_0, end_mask = cache_23_end_mask_0, squeeze_mask = cache_23_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_23_cast_fp16")];
            tensor<int32, [1]> input_287_axes_0 = const()[name = tensor<string, []>("input_287_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_5_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(66047296)))];
            tensor<fp16, [512]> encoder_layers_5_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(66048384)))];
            tensor<fp16, [1, 17, 512]> input_287_cast_fp16 = layer_norm(axes = input_287_axes_0, beta = encoder_layers_5_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_5_norm_feed_forward1_weight_to_fp16, x = input_285_cast_fp16)[name = tensor<string, []>("input_287_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_5_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(66049472)))];
            tensor<fp16, [1, 17, 2048]> linear_46_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_5_feed_forward1_linear1_weight_to_fp16, x = input_287_cast_fp16)[name = tensor<string, []>("linear_46_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_291_cast_fp16 = silu(x = linear_46_cast_fp16)[name = tensor<string, []>("input_291_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_5_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(68146688)))];
            tensor<fp16, [1, 17, 512]> linear_47_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_5_feed_forward1_linear2_weight_to_fp16, x = input_291_cast_fp16)[name = tensor<string, []>("linear_47_cast_fp16")];
            tensor<fp16, []> var_1323_to_fp16 = const()[name = tensor<string, []>("op_1323_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1324_cast_fp16 = mul(x = linear_47_cast_fp16, y = var_1323_to_fp16)[name = tensor<string, []>("op_1324_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_297_cast_fp16 = add(x = input_285_cast_fp16, y = var_1324_cast_fp16)[name = tensor<string, []>("input_297_cast_fp16")];
            tensor<int32, [1]> key_11_axes_0 = const()[name = tensor<string, []>("key_11_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_5_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(70243904)))];
            tensor<fp16, [512]> encoder_layers_5_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(70244992)))];
            tensor<fp16, [1, 17, 512]> key_11_cast_fp16 = layer_norm(axes = key_11_axes_0, beta = encoder_layers_5_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_5_norm_self_att_weight_to_fp16, x = input_297_cast_fp16)[name = tensor<string, []>("key_11_cast_fp16")];
            tensor<bool, []> input_299_interleave_0 = const()[name = tensor<string, []>("input_299_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_299_cast_fp16 = concat(axis = var_64, interleave = input_299_interleave_0, values = (cache_21_cast_fp16, key_11_cast_fp16))[name = tensor<string, []>("input_299_cast_fp16")];
            tensor<int32, [3]> var_1346_begin_0 = const()[name = tensor<string, []>("op_1346_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_1346_end_0 = const()[name = tensor<string, []>("op_1346_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_1346_end_mask_0 = const()[name = tensor<string, []>("op_1346_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_1346_cast_fp16 = slice_by_index(begin = var_1346_begin_0, end = var_1346_end_0, end_mask = var_1346_end_mask_0, x = cache_21_cast_fp16)[name = tensor<string, []>("op_1346_cast_fp16")];
            tensor<bool, []> var_1352_interleave_0 = const()[name = tensor<string, []>("op_1352_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_1352_cast_fp16 = concat(axis = var_64, interleave = var_1352_interleave_0, values = (var_1346_cast_fp16, key_11_cast_fp16))[name = tensor<string, []>("op_1352_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_5_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(70246080)))];
            tensor<fp16, [1, 17, 512]> linear_48_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_5_self_attn_linear_q_weight_to_fp16, x = key_11_cast_fp16)[name = tensor<string, []>("linear_48_cast_fp16")];
            tensor<int32, [4]> var_1356 = const()[name = tensor<string, []>("op_1356"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_31_cast_fp16 = reshape(shape = var_1356, x = linear_48_cast_fp16)[name = tensor<string, []>("q_31_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_5_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(70770432)))];
            tensor<fp16, [1, 87, 512]> linear_49_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_5_self_attn_linear_k_weight_to_fp16, x = input_299_cast_fp16)[name = tensor<string, []>("linear_49_cast_fp16")];
            tensor<int32, [4]> var_1360 = const()[name = tensor<string, []>("op_1360"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_21_cast_fp16 = reshape(shape = var_1360, x = linear_49_cast_fp16)[name = tensor<string, []>("k_21_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_5_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(71294784)))];
            tensor<fp16, [1, 87, 512]> linear_50_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_5_self_attn_linear_v_weight_to_fp16, x = input_299_cast_fp16)[name = tensor<string, []>("linear_50_cast_fp16")];
            tensor<int32, [4]> var_1364 = const()[name = tensor<string, []>("op_1364"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_11_cast_fp16 = reshape(shape = var_1364, x = linear_50_cast_fp16)[name = tensor<string, []>("v_11_cast_fp16")];
            tensor<int32, [4]> value_13_perm_0 = const()[name = tensor<string, []>("value_13_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_5_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(71819136)))];
            tensor<fp16, [1, 17, 8, 64]> var_1376_cast_fp16 = add(x = q_31_cast_fp16, y = encoder_layers_5_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_1376_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_5_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(71820224)))];
            tensor<fp16, [1, 17, 8, 64]> var_1378_cast_fp16 = add(x = q_31_cast_fp16, y = encoder_layers_5_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_1378_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_11_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_11_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_137_transpose_x_0 = const()[name = tensor<string, []>("x_137_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_137_transpose_y_0 = const()[name = tensor<string, []>("x_137_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_1380_to_fp16 = const()[name = tensor<string, []>("op_1380_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(71821312)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_11_cast_fp16 = transpose(perm = q_with_bias_v_11_perm_0, x = var_1378_cast_fp16)[name = tensor<string, []>("transpose_192")];
            tensor<fp16, [1, 8, 17, 173]> x_137_cast_fp16 = matmul(transpose_x = x_137_transpose_x_0, transpose_y = x_137_transpose_y_0, x = q_with_bias_v_11_cast_fp16, y = var_1380_to_fp16)[name = tensor<string, []>("x_137_cast_fp16")];
            tensor<int32, [8]> x_139_pad_0 = const()[name = tensor<string, []>("x_139_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_139_mode_0 = const()[name = tensor<string, []>("x_139_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_88_to_fp16 = const()[name = tensor<string, []>("const_88_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_139_cast_fp16 = pad(constant_val = const_88_to_fp16, mode = x_139_mode_0, pad = x_139_pad_0, x = x_137_cast_fp16)[name = tensor<string, []>("x_139_cast_fp16")];
            tensor<int32, [4]> var_1388 = const()[name = tensor<string, []>("op_1388"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_141_cast_fp16 = reshape(shape = var_1388, x = x_139_cast_fp16)[name = tensor<string, []>("x_141_cast_fp16")];
            tensor<int32, [4]> var_1392_begin_0 = const()[name = tensor<string, []>("op_1392_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_1392_end_0 = const()[name = tensor<string, []>("op_1392_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_1392_end_mask_0 = const()[name = tensor<string, []>("op_1392_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_1392_cast_fp16 = slice_by_index(begin = var_1392_begin_0, end = var_1392_end_0, end_mask = var_1392_end_mask_0, x = x_141_cast_fp16)[name = tensor<string, []>("op_1392_cast_fp16")];
            tensor<int32, [4]> var_1393 = const()[name = tensor<string, []>("op_1393"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_21_cast_fp16 = reshape(shape = var_1393, x = var_1392_cast_fp16)[name = tensor<string, []>("matrix_bd_21_cast_fp16")];
            tensor<bool, []> matrix_ac_11_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_11_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_11_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_11_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_61_perm_0 = const()[name = tensor<string, []>("transpose_61_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_62_perm_0 = const()[name = tensor<string, []>("transpose_62_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_62 = transpose(perm = transpose_62_perm_0, x = k_21_cast_fp16)[name = tensor<string, []>("transpose_190")];
            tensor<fp16, [1, 8, 17, 64]> transpose_61 = transpose(perm = transpose_61_perm_0, x = var_1376_cast_fp16)[name = tensor<string, []>("transpose_191")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_11_cast_fp16 = matmul(transpose_x = matrix_ac_11_transpose_x_0, transpose_y = matrix_ac_11_transpose_y_0, x = transpose_61, y = transpose_62)[name = tensor<string, []>("matrix_ac_11_cast_fp16")];
            tensor<int32, [4]> matrix_bd_23_begin_0 = const()[name = tensor<string, []>("matrix_bd_23_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_23_end_0 = const()[name = tensor<string, []>("matrix_bd_23_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_23_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_23_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_23_cast_fp16 = slice_by_index(begin = matrix_bd_23_begin_0, end = matrix_bd_23_end_0, end_mask = matrix_bd_23_end_mask_0, x = matrix_bd_21_cast_fp16)[name = tensor<string, []>("matrix_bd_23_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_1402_cast_fp16 = add(x = matrix_ac_11_cast_fp16, y = matrix_bd_23_cast_fp16)[name = tensor<string, []>("op_1402_cast_fp16")];
            tensor<fp16, []> _inversed_scores_21_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_21_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_21_cast_fp16 = mul(x = var_1402_cast_fp16, y = _inversed_scores_21_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_21_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_23_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_21_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_23_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_1408_cast_fp16 = softmax(axis = var_62, x = scores_23_cast_fp16)[name = tensor<string, []>("op_1408_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_301_cast_fp16 = select(a = var_40_to_fp16, b = var_1408_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_301_cast_fp16")];
            tensor<bool, []> x_143_transpose_x_0 = const()[name = tensor<string, []>("x_143_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_143_transpose_y_0 = const()[name = tensor<string, []>("x_143_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_13_cast_fp16 = transpose(perm = value_13_perm_0, x = v_11_cast_fp16)[name = tensor<string, []>("transpose_193")];
            tensor<fp16, [1, 8, 17, 64]> x_143_cast_fp16 = matmul(transpose_x = x_143_transpose_x_0, transpose_y = x_143_transpose_y_0, x = input_301_cast_fp16, y = value_13_cast_fp16)[name = tensor<string, []>("x_143_cast_fp16")];
            tensor<int32, [4]> var_1412_perm_0 = const()[name = tensor<string, []>("op_1412_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1413 = const()[name = tensor<string, []>("op_1413"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_1412_cast_fp16 = transpose(perm = var_1412_perm_0, x = x_143_cast_fp16)[name = tensor<string, []>("transpose_189")];
            tensor<fp16, [1, 17, 512]> input_303_cast_fp16 = reshape(shape = var_1413, x = var_1412_cast_fp16)[name = tensor<string, []>("input_303_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_5_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(71998528)))];
            tensor<fp16, [1, 17, 512]> linear_52_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_5_self_attn_linear_out_weight_to_fp16, x = input_303_cast_fp16)[name = tensor<string, []>("linear_52_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_307_cast_fp16 = add(x = input_297_cast_fp16, y = linear_52_cast_fp16)[name = tensor<string, []>("input_307_cast_fp16")];
            tensor<int32, [1]> x_147_axes_0 = const()[name = tensor<string, []>("x_147_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_5_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(72522880)))];
            tensor<fp16, [512]> encoder_layers_5_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(72523968)))];
            tensor<fp16, [1, 17, 512]> x_147_cast_fp16 = layer_norm(axes = x_147_axes_0, beta = encoder_layers_5_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_5_norm_conv_weight_to_fp16, x = input_307_cast_fp16)[name = tensor<string, []>("x_147_cast_fp16")];
            tensor<int32, [3]> input_309_perm_0 = const()[name = tensor<string, []>("input_309_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_311_pad_type_0 = const()[name = tensor<string, []>("input_311_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_311_strides_0 = const()[name = tensor<string, []>("input_311_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_311_pad_0 = const()[name = tensor<string, []>("input_311_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_311_dilations_0 = const()[name = tensor<string, []>("input_311_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_311_groups_0 = const()[name = tensor<string, []>("input_311_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_5_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(72525056)))];
            tensor<fp16, [1, 512, 17]> input_309_cast_fp16 = transpose(perm = input_309_perm_0, x = x_147_cast_fp16)[name = tensor<string, []>("transpose_188")];
            tensor<fp16, [1, 1024, 17]> input_311_cast_fp16 = conv(dilations = input_311_dilations_0, groups = input_311_groups_0, pad = input_311_pad_0, pad_type = input_311_pad_type_0, strides = input_311_strides_0, weight = encoder_layers_5_conv_pointwise_conv1_weight_to_fp16, x = input_309_cast_fp16)[name = tensor<string, []>("input_311_cast_fp16")];
            tensor<int32, []> x_149_split_num_splits_0 = const()[name = tensor<string, []>("x_149_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_149_split_axis_0 = const()[name = tensor<string, []>("x_149_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_149_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_149_split_cast_fp16_1 = split(axis = x_149_split_axis_0, num_splits = x_149_split_num_splits_0, x = input_311_cast_fp16)[name = tensor<string, []>("x_149_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_149_split_1_sigmoid_cast_fp16 = sigmoid(x = x_149_split_cast_fp16_1)[name = tensor<string, []>("x_149_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_149_cast_fp16 = mul(x = x_149_split_cast_fp16_0, y = x_149_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_149_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_313_cast_fp16 = select(a = var_40_to_fp16, b = x_149_cast_fp16, cond = var_418)[name = tensor<string, []>("input_313_cast_fp16")];
            tensor<bool, []> new_x_23_interleave_0 = const()[name = tensor<string, []>("new_x_23_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_23_cast_fp16 = concat(axis = var_62, interleave = new_x_23_interleave_0, values = (cache_23_cast_fp16, input_313_cast_fp16))[name = tensor<string, []>("new_x_23_cast_fp16")];
            tensor<int32, [3]> var_1451_begin_0 = const()[name = tensor<string, []>("op_1451_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_1451_end_0 = const()[name = tensor<string, []>("op_1451_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_1451_end_mask_0 = const()[name = tensor<string, []>("op_1451_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_1451_cast_fp16 = slice_by_index(begin = var_1451_begin_0, end = var_1451_end_0, end_mask = var_1451_end_mask_0, x = new_x_23_cast_fp16)[name = tensor<string, []>("op_1451_cast_fp16")];
            tensor<string, []> x_151_pad_type_0 = const()[name = tensor<string, []>("x_151_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_151_groups_0 = const()[name = tensor<string, []>("x_151_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_151_strides_0 = const()[name = tensor<string, []>("x_151_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_151_pad_0 = const()[name = tensor<string, []>("x_151_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_151_dilations_0 = const()[name = tensor<string, []>("x_151_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_5_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73573696)))];
            tensor<fp16, [1, 512, 17]> x_151_cast_fp16 = conv(dilations = x_151_dilations_0, groups = x_151_groups_0, pad = x_151_pad_0, pad_type = x_151_pad_type_0, strides = x_151_strides_0, weight = encoder_layers_5_conv_depthwise_conv_weight_to_fp16, x = new_x_23_cast_fp16)[name = tensor<string, []>("x_151_cast_fp16")];
            tensor<int32, [3]> input_315_perm_0 = const()[name = tensor<string, []>("input_315_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_153_axes_0 = const()[name = tensor<string, []>("x_153_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_5_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73582976)))];
            tensor<fp16, [512]> encoder_layers_5_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73584064)))];
            tensor<fp16, [1, 17, 512]> input_315_cast_fp16 = transpose(perm = input_315_perm_0, x = x_151_cast_fp16)[name = tensor<string, []>("transpose_187")];
            tensor<fp16, [1, 17, 512]> x_153_cast_fp16 = layer_norm(axes = x_153_axes_0, beta = encoder_layers_5_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_5_conv_batch_norm_weight_to_fp16, x = input_315_cast_fp16)[name = tensor<string, []>("x_153_cast_fp16")];
            tensor<int32, [3]> input_317_perm_0 = const()[name = tensor<string, []>("input_317_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_317_cast_fp16 = transpose(perm = input_317_perm_0, x = x_153_cast_fp16)[name = tensor<string, []>("transpose_186")];
            tensor<fp16, [1, 512, 17]> input_319_cast_fp16 = silu(x = input_317_cast_fp16)[name = tensor<string, []>("input_319_cast_fp16")];
            tensor<string, []> x_155_pad_type_0 = const()[name = tensor<string, []>("x_155_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_155_strides_0 = const()[name = tensor<string, []>("x_155_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_155_pad_0 = const()[name = tensor<string, []>("x_155_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_155_dilations_0 = const()[name = tensor<string, []>("x_155_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_155_groups_0 = const()[name = tensor<string, []>("x_155_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_5_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73585152)))];
            tensor<fp16, [1, 512, 17]> x_155_cast_fp16 = conv(dilations = x_155_dilations_0, groups = x_155_groups_0, pad = x_155_pad_0, pad_type = x_155_pad_type_0, strides = x_155_strides_0, weight = encoder_layers_5_conv_pointwise_conv2_weight_to_fp16, x = input_319_cast_fp16)[name = tensor<string, []>("x_155_cast_fp16")];
            tensor<int32, [3]> input_321_perm_0 = const()[name = tensor<string, []>("input_321_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_321_cast_fp16 = transpose(perm = input_321_perm_0, x = x_155_cast_fp16)[name = tensor<string, []>("transpose_185")];
            tensor<fp16, [1, 17, 512]> input_323_cast_fp16 = add(x = input_307_cast_fp16, y = input_321_cast_fp16)[name = tensor<string, []>("input_323_cast_fp16")];
            tensor<int32, [1]> input_325_axes_0 = const()[name = tensor<string, []>("input_325_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_5_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(74109504)))];
            tensor<fp16, [512]> encoder_layers_5_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(74110592)))];
            tensor<fp16, [1, 17, 512]> input_325_cast_fp16 = layer_norm(axes = input_325_axes_0, beta = encoder_layers_5_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_5_norm_feed_forward2_weight_to_fp16, x = input_323_cast_fp16)[name = tensor<string, []>("input_325_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_5_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(74111680)))];
            tensor<fp16, [1, 17, 2048]> linear_53_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_5_feed_forward2_linear1_weight_to_fp16, x = input_325_cast_fp16)[name = tensor<string, []>("linear_53_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_329_cast_fp16 = silu(x = linear_53_cast_fp16)[name = tensor<string, []>("input_329_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_5_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(76208896)))];
            tensor<fp16, [1, 17, 512]> linear_54_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_5_feed_forward2_linear2_weight_to_fp16, x = input_329_cast_fp16)[name = tensor<string, []>("linear_54_cast_fp16")];
            tensor<fp16, []> var_1492_to_fp16 = const()[name = tensor<string, []>("op_1492_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1493_cast_fp16 = mul(x = linear_54_cast_fp16, y = var_1492_to_fp16)[name = tensor<string, []>("op_1493_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_335_cast_fp16 = add(x = input_323_cast_fp16, y = var_1493_cast_fp16)[name = tensor<string, []>("input_335_cast_fp16")];
            tensor<int32, [1]> input_337_axes_0 = const()[name = tensor<string, []>("input_337_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_5_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(78306112)))];
            tensor<fp16, [512]> encoder_layers_5_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_5_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(78307200)))];
            tensor<fp16, [1, 17, 512]> input_337_cast_fp16 = layer_norm(axes = input_337_axes_0, beta = encoder_layers_5_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_5_norm_out_weight_to_fp16, x = input_335_cast_fp16)[name = tensor<string, []>("input_337_cast_fp16")];
            tensor<int32, [4]> cache_25_begin_0 = const()[name = tensor<string, []>("cache_25_begin_0"), val = tensor<int32, [4]>([6, 0, 0, 0])];
            tensor<int32, [4]> cache_25_end_0 = const()[name = tensor<string, []>("cache_25_end_0"), val = tensor<int32, [4]>([7, 1, 70, 512])];
            tensor<bool, [4]> cache_25_end_mask_0 = const()[name = tensor<string, []>("cache_25_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_25_squeeze_mask_0 = const()[name = tensor<string, []>("cache_25_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_25_cast_fp16 = slice_by_index(begin = cache_25_begin_0, end = cache_25_end_0, end_mask = cache_25_end_mask_0, squeeze_mask = cache_25_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_25_cast_fp16")];
            tensor<int32, [4]> cache_27_begin_0 = const()[name = tensor<string, []>("cache_27_begin_0"), val = tensor<int32, [4]>([6, 0, 0, 0])];
            tensor<int32, [4]> cache_27_end_0 = const()[name = tensor<string, []>("cache_27_end_0"), val = tensor<int32, [4]>([7, 1, 512, 8])];
            tensor<bool, [4]> cache_27_end_mask_0 = const()[name = tensor<string, []>("cache_27_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_27_squeeze_mask_0 = const()[name = tensor<string, []>("cache_27_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_27_cast_fp16 = slice_by_index(begin = cache_27_begin_0, end = cache_27_end_0, end_mask = cache_27_end_mask_0, squeeze_mask = cache_27_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_27_cast_fp16")];
            tensor<int32, [1]> input_339_axes_0 = const()[name = tensor<string, []>("input_339_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_6_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(78308288)))];
            tensor<fp16, [512]> encoder_layers_6_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(78309376)))];
            tensor<fp16, [1, 17, 512]> input_339_cast_fp16 = layer_norm(axes = input_339_axes_0, beta = encoder_layers_6_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_6_norm_feed_forward1_weight_to_fp16, x = input_337_cast_fp16)[name = tensor<string, []>("input_339_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_6_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(78310464)))];
            tensor<fp16, [1, 17, 2048]> linear_55_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_6_feed_forward1_linear1_weight_to_fp16, x = input_339_cast_fp16)[name = tensor<string, []>("linear_55_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_343_cast_fp16 = silu(x = linear_55_cast_fp16)[name = tensor<string, []>("input_343_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_6_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(80407680)))];
            tensor<fp16, [1, 17, 512]> linear_56_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_6_feed_forward1_linear2_weight_to_fp16, x = input_343_cast_fp16)[name = tensor<string, []>("linear_56_cast_fp16")];
            tensor<fp16, []> var_1527_to_fp16 = const()[name = tensor<string, []>("op_1527_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1528_cast_fp16 = mul(x = linear_56_cast_fp16, y = var_1527_to_fp16)[name = tensor<string, []>("op_1528_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_349_cast_fp16 = add(x = input_337_cast_fp16, y = var_1528_cast_fp16)[name = tensor<string, []>("input_349_cast_fp16")];
            tensor<int32, [1]> key_13_axes_0 = const()[name = tensor<string, []>("key_13_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_6_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(82504896)))];
            tensor<fp16, [512]> encoder_layers_6_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(82505984)))];
            tensor<fp16, [1, 17, 512]> key_13_cast_fp16 = layer_norm(axes = key_13_axes_0, beta = encoder_layers_6_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_6_norm_self_att_weight_to_fp16, x = input_349_cast_fp16)[name = tensor<string, []>("key_13_cast_fp16")];
            tensor<bool, []> input_351_interleave_0 = const()[name = tensor<string, []>("input_351_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_351_cast_fp16 = concat(axis = var_64, interleave = input_351_interleave_0, values = (cache_25_cast_fp16, key_13_cast_fp16))[name = tensor<string, []>("input_351_cast_fp16")];
            tensor<int32, [3]> var_1550_begin_0 = const()[name = tensor<string, []>("op_1550_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_1550_end_0 = const()[name = tensor<string, []>("op_1550_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_1550_end_mask_0 = const()[name = tensor<string, []>("op_1550_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_1550_cast_fp16 = slice_by_index(begin = var_1550_begin_0, end = var_1550_end_0, end_mask = var_1550_end_mask_0, x = cache_25_cast_fp16)[name = tensor<string, []>("op_1550_cast_fp16")];
            tensor<bool, []> var_1556_interleave_0 = const()[name = tensor<string, []>("op_1556_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_1556_cast_fp16 = concat(axis = var_64, interleave = var_1556_interleave_0, values = (var_1550_cast_fp16, key_13_cast_fp16))[name = tensor<string, []>("op_1556_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_6_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(82507072)))];
            tensor<fp16, [1, 17, 512]> linear_57_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_6_self_attn_linear_q_weight_to_fp16, x = key_13_cast_fp16)[name = tensor<string, []>("linear_57_cast_fp16")];
            tensor<int32, [4]> var_1560 = const()[name = tensor<string, []>("op_1560"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_37_cast_fp16 = reshape(shape = var_1560, x = linear_57_cast_fp16)[name = tensor<string, []>("q_37_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_6_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(83031424)))];
            tensor<fp16, [1, 87, 512]> linear_58_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_6_self_attn_linear_k_weight_to_fp16, x = input_351_cast_fp16)[name = tensor<string, []>("linear_58_cast_fp16")];
            tensor<int32, [4]> var_1564 = const()[name = tensor<string, []>("op_1564"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_25_cast_fp16 = reshape(shape = var_1564, x = linear_58_cast_fp16)[name = tensor<string, []>("k_25_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_6_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(83555776)))];
            tensor<fp16, [1, 87, 512]> linear_59_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_6_self_attn_linear_v_weight_to_fp16, x = input_351_cast_fp16)[name = tensor<string, []>("linear_59_cast_fp16")];
            tensor<int32, [4]> var_1568 = const()[name = tensor<string, []>("op_1568"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_13_cast_fp16 = reshape(shape = var_1568, x = linear_59_cast_fp16)[name = tensor<string, []>("v_13_cast_fp16")];
            tensor<int32, [4]> value_15_perm_0 = const()[name = tensor<string, []>("value_15_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_6_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84080128)))];
            tensor<fp16, [1, 17, 8, 64]> var_1580_cast_fp16 = add(x = q_37_cast_fp16, y = encoder_layers_6_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_1580_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_6_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84081216)))];
            tensor<fp16, [1, 17, 8, 64]> var_1582_cast_fp16 = add(x = q_37_cast_fp16, y = encoder_layers_6_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_1582_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_13_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_13_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_163_transpose_x_0 = const()[name = tensor<string, []>("x_163_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_163_transpose_y_0 = const()[name = tensor<string, []>("x_163_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_1584_to_fp16 = const()[name = tensor<string, []>("op_1584_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84082304)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_13_cast_fp16 = transpose(perm = q_with_bias_v_13_perm_0, x = var_1582_cast_fp16)[name = tensor<string, []>("transpose_183")];
            tensor<fp16, [1, 8, 17, 173]> x_163_cast_fp16 = matmul(transpose_x = x_163_transpose_x_0, transpose_y = x_163_transpose_y_0, x = q_with_bias_v_13_cast_fp16, y = var_1584_to_fp16)[name = tensor<string, []>("x_163_cast_fp16")];
            tensor<int32, [8]> x_165_pad_0 = const()[name = tensor<string, []>("x_165_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_165_mode_0 = const()[name = tensor<string, []>("x_165_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_101_to_fp16 = const()[name = tensor<string, []>("const_101_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_165_cast_fp16 = pad(constant_val = const_101_to_fp16, mode = x_165_mode_0, pad = x_165_pad_0, x = x_163_cast_fp16)[name = tensor<string, []>("x_165_cast_fp16")];
            tensor<int32, [4]> var_1592 = const()[name = tensor<string, []>("op_1592"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_167_cast_fp16 = reshape(shape = var_1592, x = x_165_cast_fp16)[name = tensor<string, []>("x_167_cast_fp16")];
            tensor<int32, [4]> var_1596_begin_0 = const()[name = tensor<string, []>("op_1596_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_1596_end_0 = const()[name = tensor<string, []>("op_1596_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_1596_end_mask_0 = const()[name = tensor<string, []>("op_1596_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_1596_cast_fp16 = slice_by_index(begin = var_1596_begin_0, end = var_1596_end_0, end_mask = var_1596_end_mask_0, x = x_167_cast_fp16)[name = tensor<string, []>("op_1596_cast_fp16")];
            tensor<int32, [4]> var_1597 = const()[name = tensor<string, []>("op_1597"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_25_cast_fp16 = reshape(shape = var_1597, x = var_1596_cast_fp16)[name = tensor<string, []>("matrix_bd_25_cast_fp16")];
            tensor<bool, []> matrix_ac_13_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_13_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_13_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_13_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_63_perm_0 = const()[name = tensor<string, []>("transpose_63_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_64_perm_0 = const()[name = tensor<string, []>("transpose_64_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_64 = transpose(perm = transpose_64_perm_0, x = k_25_cast_fp16)[name = tensor<string, []>("transpose_181")];
            tensor<fp16, [1, 8, 17, 64]> transpose_63 = transpose(perm = transpose_63_perm_0, x = var_1580_cast_fp16)[name = tensor<string, []>("transpose_182")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_13_cast_fp16 = matmul(transpose_x = matrix_ac_13_transpose_x_0, transpose_y = matrix_ac_13_transpose_y_0, x = transpose_63, y = transpose_64)[name = tensor<string, []>("matrix_ac_13_cast_fp16")];
            tensor<int32, [4]> matrix_bd_27_begin_0 = const()[name = tensor<string, []>("matrix_bd_27_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_27_end_0 = const()[name = tensor<string, []>("matrix_bd_27_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_27_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_27_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_27_cast_fp16 = slice_by_index(begin = matrix_bd_27_begin_0, end = matrix_bd_27_end_0, end_mask = matrix_bd_27_end_mask_0, x = matrix_bd_25_cast_fp16)[name = tensor<string, []>("matrix_bd_27_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_1606_cast_fp16 = add(x = matrix_ac_13_cast_fp16, y = matrix_bd_27_cast_fp16)[name = tensor<string, []>("op_1606_cast_fp16")];
            tensor<fp16, []> _inversed_scores_25_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_25_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_25_cast_fp16 = mul(x = var_1606_cast_fp16, y = _inversed_scores_25_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_25_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_27_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_25_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_27_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_1612_cast_fp16 = softmax(axis = var_62, x = scores_27_cast_fp16)[name = tensor<string, []>("op_1612_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_353_cast_fp16 = select(a = var_40_to_fp16, b = var_1612_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_353_cast_fp16")];
            tensor<bool, []> x_169_transpose_x_0 = const()[name = tensor<string, []>("x_169_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_169_transpose_y_0 = const()[name = tensor<string, []>("x_169_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_15_cast_fp16 = transpose(perm = value_15_perm_0, x = v_13_cast_fp16)[name = tensor<string, []>("transpose_184")];
            tensor<fp16, [1, 8, 17, 64]> x_169_cast_fp16 = matmul(transpose_x = x_169_transpose_x_0, transpose_y = x_169_transpose_y_0, x = input_353_cast_fp16, y = value_15_cast_fp16)[name = tensor<string, []>("x_169_cast_fp16")];
            tensor<int32, [4]> var_1616_perm_0 = const()[name = tensor<string, []>("op_1616_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1617 = const()[name = tensor<string, []>("op_1617"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_1616_cast_fp16 = transpose(perm = var_1616_perm_0, x = x_169_cast_fp16)[name = tensor<string, []>("transpose_180")];
            tensor<fp16, [1, 17, 512]> input_355_cast_fp16 = reshape(shape = var_1617, x = var_1616_cast_fp16)[name = tensor<string, []>("input_355_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_6_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84259520)))];
            tensor<fp16, [1, 17, 512]> linear_61_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_6_self_attn_linear_out_weight_to_fp16, x = input_355_cast_fp16)[name = tensor<string, []>("linear_61_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_359_cast_fp16 = add(x = input_349_cast_fp16, y = linear_61_cast_fp16)[name = tensor<string, []>("input_359_cast_fp16")];
            tensor<int32, [1]> x_173_axes_0 = const()[name = tensor<string, []>("x_173_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_6_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84783872)))];
            tensor<fp16, [512]> encoder_layers_6_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84784960)))];
            tensor<fp16, [1, 17, 512]> x_173_cast_fp16 = layer_norm(axes = x_173_axes_0, beta = encoder_layers_6_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_6_norm_conv_weight_to_fp16, x = input_359_cast_fp16)[name = tensor<string, []>("x_173_cast_fp16")];
            tensor<int32, [3]> input_361_perm_0 = const()[name = tensor<string, []>("input_361_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_363_pad_type_0 = const()[name = tensor<string, []>("input_363_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_363_strides_0 = const()[name = tensor<string, []>("input_363_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_363_pad_0 = const()[name = tensor<string, []>("input_363_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_363_dilations_0 = const()[name = tensor<string, []>("input_363_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_363_groups_0 = const()[name = tensor<string, []>("input_363_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_6_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(84786048)))];
            tensor<fp16, [1, 512, 17]> input_361_cast_fp16 = transpose(perm = input_361_perm_0, x = x_173_cast_fp16)[name = tensor<string, []>("transpose_179")];
            tensor<fp16, [1, 1024, 17]> input_363_cast_fp16 = conv(dilations = input_363_dilations_0, groups = input_363_groups_0, pad = input_363_pad_0, pad_type = input_363_pad_type_0, strides = input_363_strides_0, weight = encoder_layers_6_conv_pointwise_conv1_weight_to_fp16, x = input_361_cast_fp16)[name = tensor<string, []>("input_363_cast_fp16")];
            tensor<int32, []> x_175_split_num_splits_0 = const()[name = tensor<string, []>("x_175_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_175_split_axis_0 = const()[name = tensor<string, []>("x_175_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_175_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_175_split_cast_fp16_1 = split(axis = x_175_split_axis_0, num_splits = x_175_split_num_splits_0, x = input_363_cast_fp16)[name = tensor<string, []>("x_175_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_175_split_1_sigmoid_cast_fp16 = sigmoid(x = x_175_split_cast_fp16_1)[name = tensor<string, []>("x_175_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_175_cast_fp16 = mul(x = x_175_split_cast_fp16_0, y = x_175_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_175_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_365_cast_fp16 = select(a = var_40_to_fp16, b = x_175_cast_fp16, cond = var_418)[name = tensor<string, []>("input_365_cast_fp16")];
            tensor<bool, []> new_x_27_interleave_0 = const()[name = tensor<string, []>("new_x_27_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_27_cast_fp16 = concat(axis = var_62, interleave = new_x_27_interleave_0, values = (cache_27_cast_fp16, input_365_cast_fp16))[name = tensor<string, []>("new_x_27_cast_fp16")];
            tensor<int32, [3]> var_1655_begin_0 = const()[name = tensor<string, []>("op_1655_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_1655_end_0 = const()[name = tensor<string, []>("op_1655_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_1655_end_mask_0 = const()[name = tensor<string, []>("op_1655_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_1655_cast_fp16 = slice_by_index(begin = var_1655_begin_0, end = var_1655_end_0, end_mask = var_1655_end_mask_0, x = new_x_27_cast_fp16)[name = tensor<string, []>("op_1655_cast_fp16")];
            tensor<string, []> x_177_pad_type_0 = const()[name = tensor<string, []>("x_177_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_177_groups_0 = const()[name = tensor<string, []>("x_177_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_177_strides_0 = const()[name = tensor<string, []>("x_177_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_177_pad_0 = const()[name = tensor<string, []>("x_177_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_177_dilations_0 = const()[name = tensor<string, []>("x_177_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_6_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(85834688)))];
            tensor<fp16, [1, 512, 17]> x_177_cast_fp16 = conv(dilations = x_177_dilations_0, groups = x_177_groups_0, pad = x_177_pad_0, pad_type = x_177_pad_type_0, strides = x_177_strides_0, weight = encoder_layers_6_conv_depthwise_conv_weight_to_fp16, x = new_x_27_cast_fp16)[name = tensor<string, []>("x_177_cast_fp16")];
            tensor<int32, [3]> input_367_perm_0 = const()[name = tensor<string, []>("input_367_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_179_axes_0 = const()[name = tensor<string, []>("x_179_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_6_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(85843968)))];
            tensor<fp16, [512]> encoder_layers_6_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(85845056)))];
            tensor<fp16, [1, 17, 512]> input_367_cast_fp16 = transpose(perm = input_367_perm_0, x = x_177_cast_fp16)[name = tensor<string, []>("transpose_178")];
            tensor<fp16, [1, 17, 512]> x_179_cast_fp16 = layer_norm(axes = x_179_axes_0, beta = encoder_layers_6_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_6_conv_batch_norm_weight_to_fp16, x = input_367_cast_fp16)[name = tensor<string, []>("x_179_cast_fp16")];
            tensor<int32, [3]> input_369_perm_0 = const()[name = tensor<string, []>("input_369_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_369_cast_fp16 = transpose(perm = input_369_perm_0, x = x_179_cast_fp16)[name = tensor<string, []>("transpose_177")];
            tensor<fp16, [1, 512, 17]> input_371_cast_fp16 = silu(x = input_369_cast_fp16)[name = tensor<string, []>("input_371_cast_fp16")];
            tensor<string, []> x_181_pad_type_0 = const()[name = tensor<string, []>("x_181_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_181_strides_0 = const()[name = tensor<string, []>("x_181_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_181_pad_0 = const()[name = tensor<string, []>("x_181_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_181_dilations_0 = const()[name = tensor<string, []>("x_181_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_181_groups_0 = const()[name = tensor<string, []>("x_181_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_6_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(85846144)))];
            tensor<fp16, [1, 512, 17]> x_181_cast_fp16 = conv(dilations = x_181_dilations_0, groups = x_181_groups_0, pad = x_181_pad_0, pad_type = x_181_pad_type_0, strides = x_181_strides_0, weight = encoder_layers_6_conv_pointwise_conv2_weight_to_fp16, x = input_371_cast_fp16)[name = tensor<string, []>("x_181_cast_fp16")];
            tensor<int32, [3]> input_373_perm_0 = const()[name = tensor<string, []>("input_373_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_373_cast_fp16 = transpose(perm = input_373_perm_0, x = x_181_cast_fp16)[name = tensor<string, []>("transpose_176")];
            tensor<fp16, [1, 17, 512]> input_375_cast_fp16 = add(x = input_359_cast_fp16, y = input_373_cast_fp16)[name = tensor<string, []>("input_375_cast_fp16")];
            tensor<int32, [1]> input_377_axes_0 = const()[name = tensor<string, []>("input_377_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_6_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(86370496)))];
            tensor<fp16, [512]> encoder_layers_6_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(86371584)))];
            tensor<fp16, [1, 17, 512]> input_377_cast_fp16 = layer_norm(axes = input_377_axes_0, beta = encoder_layers_6_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_6_norm_feed_forward2_weight_to_fp16, x = input_375_cast_fp16)[name = tensor<string, []>("input_377_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_6_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(86372672)))];
            tensor<fp16, [1, 17, 2048]> linear_62_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_6_feed_forward2_linear1_weight_to_fp16, x = input_377_cast_fp16)[name = tensor<string, []>("linear_62_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_381_cast_fp16 = silu(x = linear_62_cast_fp16)[name = tensor<string, []>("input_381_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_6_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(88469888)))];
            tensor<fp16, [1, 17, 512]> linear_63_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_6_feed_forward2_linear2_weight_to_fp16, x = input_381_cast_fp16)[name = tensor<string, []>("linear_63_cast_fp16")];
            tensor<fp16, []> var_1696_to_fp16 = const()[name = tensor<string, []>("op_1696_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1697_cast_fp16 = mul(x = linear_63_cast_fp16, y = var_1696_to_fp16)[name = tensor<string, []>("op_1697_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_387_cast_fp16 = add(x = input_375_cast_fp16, y = var_1697_cast_fp16)[name = tensor<string, []>("input_387_cast_fp16")];
            tensor<int32, [1]> input_389_axes_0 = const()[name = tensor<string, []>("input_389_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_6_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(90567104)))];
            tensor<fp16, [512]> encoder_layers_6_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_6_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(90568192)))];
            tensor<fp16, [1, 17, 512]> input_389_cast_fp16 = layer_norm(axes = input_389_axes_0, beta = encoder_layers_6_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_6_norm_out_weight_to_fp16, x = input_387_cast_fp16)[name = tensor<string, []>("input_389_cast_fp16")];
            tensor<int32, [4]> cache_29_begin_0 = const()[name = tensor<string, []>("cache_29_begin_0"), val = tensor<int32, [4]>([7, 0, 0, 0])];
            tensor<int32, [4]> cache_29_end_0 = const()[name = tensor<string, []>("cache_29_end_0"), val = tensor<int32, [4]>([8, 1, 70, 512])];
            tensor<bool, [4]> cache_29_end_mask_0 = const()[name = tensor<string, []>("cache_29_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_29_squeeze_mask_0 = const()[name = tensor<string, []>("cache_29_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_29_cast_fp16 = slice_by_index(begin = cache_29_begin_0, end = cache_29_end_0, end_mask = cache_29_end_mask_0, squeeze_mask = cache_29_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_29_cast_fp16")];
            tensor<int32, [4]> cache_31_begin_0 = const()[name = tensor<string, []>("cache_31_begin_0"), val = tensor<int32, [4]>([7, 0, 0, 0])];
            tensor<int32, [4]> cache_31_end_0 = const()[name = tensor<string, []>("cache_31_end_0"), val = tensor<int32, [4]>([8, 1, 512, 8])];
            tensor<bool, [4]> cache_31_end_mask_0 = const()[name = tensor<string, []>("cache_31_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_31_squeeze_mask_0 = const()[name = tensor<string, []>("cache_31_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_31_cast_fp16 = slice_by_index(begin = cache_31_begin_0, end = cache_31_end_0, end_mask = cache_31_end_mask_0, squeeze_mask = cache_31_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_31_cast_fp16")];
            tensor<int32, [1]> input_391_axes_0 = const()[name = tensor<string, []>("input_391_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_7_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(90569280)))];
            tensor<fp16, [512]> encoder_layers_7_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(90570368)))];
            tensor<fp16, [1, 17, 512]> input_391_cast_fp16 = layer_norm(axes = input_391_axes_0, beta = encoder_layers_7_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_7_norm_feed_forward1_weight_to_fp16, x = input_389_cast_fp16)[name = tensor<string, []>("input_391_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_7_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(90571456)))];
            tensor<fp16, [1, 17, 2048]> linear_64_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_7_feed_forward1_linear1_weight_to_fp16, x = input_391_cast_fp16)[name = tensor<string, []>("linear_64_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_395_cast_fp16 = silu(x = linear_64_cast_fp16)[name = tensor<string, []>("input_395_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_7_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(92668672)))];
            tensor<fp16, [1, 17, 512]> linear_65_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_7_feed_forward1_linear2_weight_to_fp16, x = input_395_cast_fp16)[name = tensor<string, []>("linear_65_cast_fp16")];
            tensor<fp16, []> var_1731_to_fp16 = const()[name = tensor<string, []>("op_1731_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1732_cast_fp16 = mul(x = linear_65_cast_fp16, y = var_1731_to_fp16)[name = tensor<string, []>("op_1732_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_401_cast_fp16 = add(x = input_389_cast_fp16, y = var_1732_cast_fp16)[name = tensor<string, []>("input_401_cast_fp16")];
            tensor<int32, [1]> key_15_axes_0 = const()[name = tensor<string, []>("key_15_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_7_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(94765888)))];
            tensor<fp16, [512]> encoder_layers_7_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(94766976)))];
            tensor<fp16, [1, 17, 512]> key_15_cast_fp16 = layer_norm(axes = key_15_axes_0, beta = encoder_layers_7_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_7_norm_self_att_weight_to_fp16, x = input_401_cast_fp16)[name = tensor<string, []>("key_15_cast_fp16")];
            tensor<bool, []> input_403_interleave_0 = const()[name = tensor<string, []>("input_403_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_403_cast_fp16 = concat(axis = var_64, interleave = input_403_interleave_0, values = (cache_29_cast_fp16, key_15_cast_fp16))[name = tensor<string, []>("input_403_cast_fp16")];
            tensor<int32, [3]> var_1754_begin_0 = const()[name = tensor<string, []>("op_1754_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_1754_end_0 = const()[name = tensor<string, []>("op_1754_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_1754_end_mask_0 = const()[name = tensor<string, []>("op_1754_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_1754_cast_fp16 = slice_by_index(begin = var_1754_begin_0, end = var_1754_end_0, end_mask = var_1754_end_mask_0, x = cache_29_cast_fp16)[name = tensor<string, []>("op_1754_cast_fp16")];
            tensor<bool, []> var_1760_interleave_0 = const()[name = tensor<string, []>("op_1760_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_1760_cast_fp16 = concat(axis = var_64, interleave = var_1760_interleave_0, values = (var_1754_cast_fp16, key_15_cast_fp16))[name = tensor<string, []>("op_1760_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_7_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(94768064)))];
            tensor<fp16, [1, 17, 512]> linear_66_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_7_self_attn_linear_q_weight_to_fp16, x = key_15_cast_fp16)[name = tensor<string, []>("linear_66_cast_fp16")];
            tensor<int32, [4]> var_1764 = const()[name = tensor<string, []>("op_1764"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_43_cast_fp16 = reshape(shape = var_1764, x = linear_66_cast_fp16)[name = tensor<string, []>("q_43_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_7_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(95292416)))];
            tensor<fp16, [1, 87, 512]> linear_67_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_7_self_attn_linear_k_weight_to_fp16, x = input_403_cast_fp16)[name = tensor<string, []>("linear_67_cast_fp16")];
            tensor<int32, [4]> var_1768 = const()[name = tensor<string, []>("op_1768"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_29_cast_fp16 = reshape(shape = var_1768, x = linear_67_cast_fp16)[name = tensor<string, []>("k_29_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_7_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(95816768)))];
            tensor<fp16, [1, 87, 512]> linear_68_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_7_self_attn_linear_v_weight_to_fp16, x = input_403_cast_fp16)[name = tensor<string, []>("linear_68_cast_fp16")];
            tensor<int32, [4]> var_1772 = const()[name = tensor<string, []>("op_1772"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_15_cast_fp16 = reshape(shape = var_1772, x = linear_68_cast_fp16)[name = tensor<string, []>("v_15_cast_fp16")];
            tensor<int32, [4]> value_17_perm_0 = const()[name = tensor<string, []>("value_17_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_7_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(96341120)))];
            tensor<fp16, [1, 17, 8, 64]> var_1784_cast_fp16 = add(x = q_43_cast_fp16, y = encoder_layers_7_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_1784_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_7_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(96342208)))];
            tensor<fp16, [1, 17, 8, 64]> var_1786_cast_fp16 = add(x = q_43_cast_fp16, y = encoder_layers_7_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_1786_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_15_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_15_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_189_transpose_x_0 = const()[name = tensor<string, []>("x_189_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_189_transpose_y_0 = const()[name = tensor<string, []>("x_189_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_1788_to_fp16 = const()[name = tensor<string, []>("op_1788_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(96343296)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_15_cast_fp16 = transpose(perm = q_with_bias_v_15_perm_0, x = var_1786_cast_fp16)[name = tensor<string, []>("transpose_174")];
            tensor<fp16, [1, 8, 17, 173]> x_189_cast_fp16 = matmul(transpose_x = x_189_transpose_x_0, transpose_y = x_189_transpose_y_0, x = q_with_bias_v_15_cast_fp16, y = var_1788_to_fp16)[name = tensor<string, []>("x_189_cast_fp16")];
            tensor<int32, [8]> x_191_pad_0 = const()[name = tensor<string, []>("x_191_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_191_mode_0 = const()[name = tensor<string, []>("x_191_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_114_to_fp16 = const()[name = tensor<string, []>("const_114_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_191_cast_fp16 = pad(constant_val = const_114_to_fp16, mode = x_191_mode_0, pad = x_191_pad_0, x = x_189_cast_fp16)[name = tensor<string, []>("x_191_cast_fp16")];
            tensor<int32, [4]> var_1796 = const()[name = tensor<string, []>("op_1796"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_193_cast_fp16 = reshape(shape = var_1796, x = x_191_cast_fp16)[name = tensor<string, []>("x_193_cast_fp16")];
            tensor<int32, [4]> var_1800_begin_0 = const()[name = tensor<string, []>("op_1800_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_1800_end_0 = const()[name = tensor<string, []>("op_1800_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_1800_end_mask_0 = const()[name = tensor<string, []>("op_1800_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_1800_cast_fp16 = slice_by_index(begin = var_1800_begin_0, end = var_1800_end_0, end_mask = var_1800_end_mask_0, x = x_193_cast_fp16)[name = tensor<string, []>("op_1800_cast_fp16")];
            tensor<int32, [4]> var_1801 = const()[name = tensor<string, []>("op_1801"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_29_cast_fp16 = reshape(shape = var_1801, x = var_1800_cast_fp16)[name = tensor<string, []>("matrix_bd_29_cast_fp16")];
            tensor<bool, []> matrix_ac_15_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_15_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_15_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_15_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_65_perm_0 = const()[name = tensor<string, []>("transpose_65_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_66_perm_0 = const()[name = tensor<string, []>("transpose_66_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_66 = transpose(perm = transpose_66_perm_0, x = k_29_cast_fp16)[name = tensor<string, []>("transpose_172")];
            tensor<fp16, [1, 8, 17, 64]> transpose_65 = transpose(perm = transpose_65_perm_0, x = var_1784_cast_fp16)[name = tensor<string, []>("transpose_173")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_15_cast_fp16 = matmul(transpose_x = matrix_ac_15_transpose_x_0, transpose_y = matrix_ac_15_transpose_y_0, x = transpose_65, y = transpose_66)[name = tensor<string, []>("matrix_ac_15_cast_fp16")];
            tensor<int32, [4]> matrix_bd_31_begin_0 = const()[name = tensor<string, []>("matrix_bd_31_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_31_end_0 = const()[name = tensor<string, []>("matrix_bd_31_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_31_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_31_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_31_cast_fp16 = slice_by_index(begin = matrix_bd_31_begin_0, end = matrix_bd_31_end_0, end_mask = matrix_bd_31_end_mask_0, x = matrix_bd_29_cast_fp16)[name = tensor<string, []>("matrix_bd_31_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_1810_cast_fp16 = add(x = matrix_ac_15_cast_fp16, y = matrix_bd_31_cast_fp16)[name = tensor<string, []>("op_1810_cast_fp16")];
            tensor<fp16, []> _inversed_scores_29_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_29_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_29_cast_fp16 = mul(x = var_1810_cast_fp16, y = _inversed_scores_29_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_29_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_31_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_29_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_31_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_1816_cast_fp16 = softmax(axis = var_62, x = scores_31_cast_fp16)[name = tensor<string, []>("op_1816_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_405_cast_fp16 = select(a = var_40_to_fp16, b = var_1816_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_405_cast_fp16")];
            tensor<bool, []> x_195_transpose_x_0 = const()[name = tensor<string, []>("x_195_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_195_transpose_y_0 = const()[name = tensor<string, []>("x_195_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_17_cast_fp16 = transpose(perm = value_17_perm_0, x = v_15_cast_fp16)[name = tensor<string, []>("transpose_175")];
            tensor<fp16, [1, 8, 17, 64]> x_195_cast_fp16 = matmul(transpose_x = x_195_transpose_x_0, transpose_y = x_195_transpose_y_0, x = input_405_cast_fp16, y = value_17_cast_fp16)[name = tensor<string, []>("x_195_cast_fp16")];
            tensor<int32, [4]> var_1820_perm_0 = const()[name = tensor<string, []>("op_1820_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1821 = const()[name = tensor<string, []>("op_1821"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_1820_cast_fp16 = transpose(perm = var_1820_perm_0, x = x_195_cast_fp16)[name = tensor<string, []>("transpose_171")];
            tensor<fp16, [1, 17, 512]> input_407_cast_fp16 = reshape(shape = var_1821, x = var_1820_cast_fp16)[name = tensor<string, []>("input_407_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_7_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(96520512)))];
            tensor<fp16, [1, 17, 512]> linear_70_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_7_self_attn_linear_out_weight_to_fp16, x = input_407_cast_fp16)[name = tensor<string, []>("linear_70_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_411_cast_fp16 = add(x = input_401_cast_fp16, y = linear_70_cast_fp16)[name = tensor<string, []>("input_411_cast_fp16")];
            tensor<int32, [1]> x_199_axes_0 = const()[name = tensor<string, []>("x_199_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_7_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(97044864)))];
            tensor<fp16, [512]> encoder_layers_7_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(97045952)))];
            tensor<fp16, [1, 17, 512]> x_199_cast_fp16 = layer_norm(axes = x_199_axes_0, beta = encoder_layers_7_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_7_norm_conv_weight_to_fp16, x = input_411_cast_fp16)[name = tensor<string, []>("x_199_cast_fp16")];
            tensor<int32, [3]> input_413_perm_0 = const()[name = tensor<string, []>("input_413_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_415_pad_type_0 = const()[name = tensor<string, []>("input_415_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_415_strides_0 = const()[name = tensor<string, []>("input_415_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_415_pad_0 = const()[name = tensor<string, []>("input_415_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_415_dilations_0 = const()[name = tensor<string, []>("input_415_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_415_groups_0 = const()[name = tensor<string, []>("input_415_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_7_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(97047040)))];
            tensor<fp16, [1, 512, 17]> input_413_cast_fp16 = transpose(perm = input_413_perm_0, x = x_199_cast_fp16)[name = tensor<string, []>("transpose_170")];
            tensor<fp16, [1, 1024, 17]> input_415_cast_fp16 = conv(dilations = input_415_dilations_0, groups = input_415_groups_0, pad = input_415_pad_0, pad_type = input_415_pad_type_0, strides = input_415_strides_0, weight = encoder_layers_7_conv_pointwise_conv1_weight_to_fp16, x = input_413_cast_fp16)[name = tensor<string, []>("input_415_cast_fp16")];
            tensor<int32, []> x_201_split_num_splits_0 = const()[name = tensor<string, []>("x_201_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_201_split_axis_0 = const()[name = tensor<string, []>("x_201_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_201_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_201_split_cast_fp16_1 = split(axis = x_201_split_axis_0, num_splits = x_201_split_num_splits_0, x = input_415_cast_fp16)[name = tensor<string, []>("x_201_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_201_split_1_sigmoid_cast_fp16 = sigmoid(x = x_201_split_cast_fp16_1)[name = tensor<string, []>("x_201_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_201_cast_fp16 = mul(x = x_201_split_cast_fp16_0, y = x_201_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_201_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_417_cast_fp16 = select(a = var_40_to_fp16, b = x_201_cast_fp16, cond = var_418)[name = tensor<string, []>("input_417_cast_fp16")];
            tensor<bool, []> new_x_31_interleave_0 = const()[name = tensor<string, []>("new_x_31_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_31_cast_fp16 = concat(axis = var_62, interleave = new_x_31_interleave_0, values = (cache_31_cast_fp16, input_417_cast_fp16))[name = tensor<string, []>("new_x_31_cast_fp16")];
            tensor<int32, [3]> var_1859_begin_0 = const()[name = tensor<string, []>("op_1859_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_1859_end_0 = const()[name = tensor<string, []>("op_1859_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_1859_end_mask_0 = const()[name = tensor<string, []>("op_1859_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_1859_cast_fp16 = slice_by_index(begin = var_1859_begin_0, end = var_1859_end_0, end_mask = var_1859_end_mask_0, x = new_x_31_cast_fp16)[name = tensor<string, []>("op_1859_cast_fp16")];
            tensor<string, []> x_203_pad_type_0 = const()[name = tensor<string, []>("x_203_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_203_groups_0 = const()[name = tensor<string, []>("x_203_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_203_strides_0 = const()[name = tensor<string, []>("x_203_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_203_pad_0 = const()[name = tensor<string, []>("x_203_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_203_dilations_0 = const()[name = tensor<string, []>("x_203_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_7_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(98095680)))];
            tensor<fp16, [1, 512, 17]> x_203_cast_fp16 = conv(dilations = x_203_dilations_0, groups = x_203_groups_0, pad = x_203_pad_0, pad_type = x_203_pad_type_0, strides = x_203_strides_0, weight = encoder_layers_7_conv_depthwise_conv_weight_to_fp16, x = new_x_31_cast_fp16)[name = tensor<string, []>("x_203_cast_fp16")];
            tensor<int32, [3]> input_419_perm_0 = const()[name = tensor<string, []>("input_419_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_205_axes_0 = const()[name = tensor<string, []>("x_205_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_7_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(98104960)))];
            tensor<fp16, [512]> encoder_layers_7_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(98106048)))];
            tensor<fp16, [1, 17, 512]> input_419_cast_fp16 = transpose(perm = input_419_perm_0, x = x_203_cast_fp16)[name = tensor<string, []>("transpose_169")];
            tensor<fp16, [1, 17, 512]> x_205_cast_fp16 = layer_norm(axes = x_205_axes_0, beta = encoder_layers_7_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_7_conv_batch_norm_weight_to_fp16, x = input_419_cast_fp16)[name = tensor<string, []>("x_205_cast_fp16")];
            tensor<int32, [3]> input_421_perm_0 = const()[name = tensor<string, []>("input_421_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_421_cast_fp16 = transpose(perm = input_421_perm_0, x = x_205_cast_fp16)[name = tensor<string, []>("transpose_168")];
            tensor<fp16, [1, 512, 17]> input_423_cast_fp16 = silu(x = input_421_cast_fp16)[name = tensor<string, []>("input_423_cast_fp16")];
            tensor<string, []> x_207_pad_type_0 = const()[name = tensor<string, []>("x_207_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_207_strides_0 = const()[name = tensor<string, []>("x_207_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_207_pad_0 = const()[name = tensor<string, []>("x_207_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_207_dilations_0 = const()[name = tensor<string, []>("x_207_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_207_groups_0 = const()[name = tensor<string, []>("x_207_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_7_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(98107136)))];
            tensor<fp16, [1, 512, 17]> x_207_cast_fp16 = conv(dilations = x_207_dilations_0, groups = x_207_groups_0, pad = x_207_pad_0, pad_type = x_207_pad_type_0, strides = x_207_strides_0, weight = encoder_layers_7_conv_pointwise_conv2_weight_to_fp16, x = input_423_cast_fp16)[name = tensor<string, []>("x_207_cast_fp16")];
            tensor<int32, [3]> input_425_perm_0 = const()[name = tensor<string, []>("input_425_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_425_cast_fp16 = transpose(perm = input_425_perm_0, x = x_207_cast_fp16)[name = tensor<string, []>("transpose_167")];
            tensor<fp16, [1, 17, 512]> input_427_cast_fp16 = add(x = input_411_cast_fp16, y = input_425_cast_fp16)[name = tensor<string, []>("input_427_cast_fp16")];
            tensor<int32, [1]> input_429_axes_0 = const()[name = tensor<string, []>("input_429_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_7_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(98631488)))];
            tensor<fp16, [512]> encoder_layers_7_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(98632576)))];
            tensor<fp16, [1, 17, 512]> input_429_cast_fp16 = layer_norm(axes = input_429_axes_0, beta = encoder_layers_7_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_7_norm_feed_forward2_weight_to_fp16, x = input_427_cast_fp16)[name = tensor<string, []>("input_429_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_7_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(98633664)))];
            tensor<fp16, [1, 17, 2048]> linear_71_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_7_feed_forward2_linear1_weight_to_fp16, x = input_429_cast_fp16)[name = tensor<string, []>("linear_71_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_433_cast_fp16 = silu(x = linear_71_cast_fp16)[name = tensor<string, []>("input_433_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_7_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(100730880)))];
            tensor<fp16, [1, 17, 512]> linear_72_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_7_feed_forward2_linear2_weight_to_fp16, x = input_433_cast_fp16)[name = tensor<string, []>("linear_72_cast_fp16")];
            tensor<fp16, []> var_1900_to_fp16 = const()[name = tensor<string, []>("op_1900_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1901_cast_fp16 = mul(x = linear_72_cast_fp16, y = var_1900_to_fp16)[name = tensor<string, []>("op_1901_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_439_cast_fp16 = add(x = input_427_cast_fp16, y = var_1901_cast_fp16)[name = tensor<string, []>("input_439_cast_fp16")];
            tensor<int32, [1]> input_441_axes_0 = const()[name = tensor<string, []>("input_441_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_7_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102828096)))];
            tensor<fp16, [512]> encoder_layers_7_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_7_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102829184)))];
            tensor<fp16, [1, 17, 512]> input_441_cast_fp16 = layer_norm(axes = input_441_axes_0, beta = encoder_layers_7_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_7_norm_out_weight_to_fp16, x = input_439_cast_fp16)[name = tensor<string, []>("input_441_cast_fp16")];
            tensor<int32, [4]> cache_33_begin_0 = const()[name = tensor<string, []>("cache_33_begin_0"), val = tensor<int32, [4]>([8, 0, 0, 0])];
            tensor<int32, [4]> cache_33_end_0 = const()[name = tensor<string, []>("cache_33_end_0"), val = tensor<int32, [4]>([9, 1, 70, 512])];
            tensor<bool, [4]> cache_33_end_mask_0 = const()[name = tensor<string, []>("cache_33_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_33_squeeze_mask_0 = const()[name = tensor<string, []>("cache_33_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_33_cast_fp16 = slice_by_index(begin = cache_33_begin_0, end = cache_33_end_0, end_mask = cache_33_end_mask_0, squeeze_mask = cache_33_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_33_cast_fp16")];
            tensor<int32, [4]> cache_35_begin_0 = const()[name = tensor<string, []>("cache_35_begin_0"), val = tensor<int32, [4]>([8, 0, 0, 0])];
            tensor<int32, [4]> cache_35_end_0 = const()[name = tensor<string, []>("cache_35_end_0"), val = tensor<int32, [4]>([9, 1, 512, 8])];
            tensor<bool, [4]> cache_35_end_mask_0 = const()[name = tensor<string, []>("cache_35_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_35_squeeze_mask_0 = const()[name = tensor<string, []>("cache_35_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_35_cast_fp16 = slice_by_index(begin = cache_35_begin_0, end = cache_35_end_0, end_mask = cache_35_end_mask_0, squeeze_mask = cache_35_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_35_cast_fp16")];
            tensor<int32, [1]> input_443_axes_0 = const()[name = tensor<string, []>("input_443_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_8_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102830272)))];
            tensor<fp16, [512]> encoder_layers_8_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102831360)))];
            tensor<fp16, [1, 17, 512]> input_443_cast_fp16 = layer_norm(axes = input_443_axes_0, beta = encoder_layers_8_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_8_norm_feed_forward1_weight_to_fp16, x = input_441_cast_fp16)[name = tensor<string, []>("input_443_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_8_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102832448)))];
            tensor<fp16, [1, 17, 2048]> linear_73_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_8_feed_forward1_linear1_weight_to_fp16, x = input_443_cast_fp16)[name = tensor<string, []>("linear_73_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_447_cast_fp16 = silu(x = linear_73_cast_fp16)[name = tensor<string, []>("input_447_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_8_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(104929664)))];
            tensor<fp16, [1, 17, 512]> linear_74_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_8_feed_forward1_linear2_weight_to_fp16, x = input_447_cast_fp16)[name = tensor<string, []>("linear_74_cast_fp16")];
            tensor<fp16, []> var_1935_to_fp16 = const()[name = tensor<string, []>("op_1935_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_1936_cast_fp16 = mul(x = linear_74_cast_fp16, y = var_1935_to_fp16)[name = tensor<string, []>("op_1936_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_453_cast_fp16 = add(x = input_441_cast_fp16, y = var_1936_cast_fp16)[name = tensor<string, []>("input_453_cast_fp16")];
            tensor<int32, [1]> key_17_axes_0 = const()[name = tensor<string, []>("key_17_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_8_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(107026880)))];
            tensor<fp16, [512]> encoder_layers_8_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(107027968)))];
            tensor<fp16, [1, 17, 512]> key_17_cast_fp16 = layer_norm(axes = key_17_axes_0, beta = encoder_layers_8_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_8_norm_self_att_weight_to_fp16, x = input_453_cast_fp16)[name = tensor<string, []>("key_17_cast_fp16")];
            tensor<bool, []> input_455_interleave_0 = const()[name = tensor<string, []>("input_455_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_455_cast_fp16 = concat(axis = var_64, interleave = input_455_interleave_0, values = (cache_33_cast_fp16, key_17_cast_fp16))[name = tensor<string, []>("input_455_cast_fp16")];
            tensor<int32, [3]> var_1958_begin_0 = const()[name = tensor<string, []>("op_1958_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_1958_end_0 = const()[name = tensor<string, []>("op_1958_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_1958_end_mask_0 = const()[name = tensor<string, []>("op_1958_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_1958_cast_fp16 = slice_by_index(begin = var_1958_begin_0, end = var_1958_end_0, end_mask = var_1958_end_mask_0, x = cache_33_cast_fp16)[name = tensor<string, []>("op_1958_cast_fp16")];
            tensor<bool, []> var_1964_interleave_0 = const()[name = tensor<string, []>("op_1964_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_1964_cast_fp16 = concat(axis = var_64, interleave = var_1964_interleave_0, values = (var_1958_cast_fp16, key_17_cast_fp16))[name = tensor<string, []>("op_1964_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_8_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(107029056)))];
            tensor<fp16, [1, 17, 512]> linear_75_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_8_self_attn_linear_q_weight_to_fp16, x = key_17_cast_fp16)[name = tensor<string, []>("linear_75_cast_fp16")];
            tensor<int32, [4]> var_1968 = const()[name = tensor<string, []>("op_1968"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_49_cast_fp16 = reshape(shape = var_1968, x = linear_75_cast_fp16)[name = tensor<string, []>("q_49_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_8_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(107553408)))];
            tensor<fp16, [1, 87, 512]> linear_76_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_8_self_attn_linear_k_weight_to_fp16, x = input_455_cast_fp16)[name = tensor<string, []>("linear_76_cast_fp16")];
            tensor<int32, [4]> var_1972 = const()[name = tensor<string, []>("op_1972"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_33_cast_fp16 = reshape(shape = var_1972, x = linear_76_cast_fp16)[name = tensor<string, []>("k_33_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_8_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(108077760)))];
            tensor<fp16, [1, 87, 512]> linear_77_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_8_self_attn_linear_v_weight_to_fp16, x = input_455_cast_fp16)[name = tensor<string, []>("linear_77_cast_fp16")];
            tensor<int32, [4]> var_1976 = const()[name = tensor<string, []>("op_1976"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_17_cast_fp16 = reshape(shape = var_1976, x = linear_77_cast_fp16)[name = tensor<string, []>("v_17_cast_fp16")];
            tensor<int32, [4]> value_19_perm_0 = const()[name = tensor<string, []>("value_19_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_8_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(108602112)))];
            tensor<fp16, [1, 17, 8, 64]> var_1988_cast_fp16 = add(x = q_49_cast_fp16, y = encoder_layers_8_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_1988_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_8_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(108603200)))];
            tensor<fp16, [1, 17, 8, 64]> var_1990_cast_fp16 = add(x = q_49_cast_fp16, y = encoder_layers_8_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_1990_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_17_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_17_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_215_transpose_x_0 = const()[name = tensor<string, []>("x_215_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_215_transpose_y_0 = const()[name = tensor<string, []>("x_215_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_1992_to_fp16 = const()[name = tensor<string, []>("op_1992_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(108604288)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_17_cast_fp16 = transpose(perm = q_with_bias_v_17_perm_0, x = var_1990_cast_fp16)[name = tensor<string, []>("transpose_165")];
            tensor<fp16, [1, 8, 17, 173]> x_215_cast_fp16 = matmul(transpose_x = x_215_transpose_x_0, transpose_y = x_215_transpose_y_0, x = q_with_bias_v_17_cast_fp16, y = var_1992_to_fp16)[name = tensor<string, []>("x_215_cast_fp16")];
            tensor<int32, [8]> x_217_pad_0 = const()[name = tensor<string, []>("x_217_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_217_mode_0 = const()[name = tensor<string, []>("x_217_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_127_to_fp16 = const()[name = tensor<string, []>("const_127_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_217_cast_fp16 = pad(constant_val = const_127_to_fp16, mode = x_217_mode_0, pad = x_217_pad_0, x = x_215_cast_fp16)[name = tensor<string, []>("x_217_cast_fp16")];
            tensor<int32, [4]> var_2000 = const()[name = tensor<string, []>("op_2000"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_219_cast_fp16 = reshape(shape = var_2000, x = x_217_cast_fp16)[name = tensor<string, []>("x_219_cast_fp16")];
            tensor<int32, [4]> var_2004_begin_0 = const()[name = tensor<string, []>("op_2004_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_2004_end_0 = const()[name = tensor<string, []>("op_2004_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_2004_end_mask_0 = const()[name = tensor<string, []>("op_2004_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_2004_cast_fp16 = slice_by_index(begin = var_2004_begin_0, end = var_2004_end_0, end_mask = var_2004_end_mask_0, x = x_219_cast_fp16)[name = tensor<string, []>("op_2004_cast_fp16")];
            tensor<int32, [4]> var_2005 = const()[name = tensor<string, []>("op_2005"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_33_cast_fp16 = reshape(shape = var_2005, x = var_2004_cast_fp16)[name = tensor<string, []>("matrix_bd_33_cast_fp16")];
            tensor<bool, []> matrix_ac_17_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_17_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_17_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_17_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_67_perm_0 = const()[name = tensor<string, []>("transpose_67_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_68_perm_0 = const()[name = tensor<string, []>("transpose_68_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_68 = transpose(perm = transpose_68_perm_0, x = k_33_cast_fp16)[name = tensor<string, []>("transpose_163")];
            tensor<fp16, [1, 8, 17, 64]> transpose_67 = transpose(perm = transpose_67_perm_0, x = var_1988_cast_fp16)[name = tensor<string, []>("transpose_164")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_17_cast_fp16 = matmul(transpose_x = matrix_ac_17_transpose_x_0, transpose_y = matrix_ac_17_transpose_y_0, x = transpose_67, y = transpose_68)[name = tensor<string, []>("matrix_ac_17_cast_fp16")];
            tensor<int32, [4]> matrix_bd_35_begin_0 = const()[name = tensor<string, []>("matrix_bd_35_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_35_end_0 = const()[name = tensor<string, []>("matrix_bd_35_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_35_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_35_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_35_cast_fp16 = slice_by_index(begin = matrix_bd_35_begin_0, end = matrix_bd_35_end_0, end_mask = matrix_bd_35_end_mask_0, x = matrix_bd_33_cast_fp16)[name = tensor<string, []>("matrix_bd_35_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2014_cast_fp16 = add(x = matrix_ac_17_cast_fp16, y = matrix_bd_35_cast_fp16)[name = tensor<string, []>("op_2014_cast_fp16")];
            tensor<fp16, []> _inversed_scores_33_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_33_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_33_cast_fp16 = mul(x = var_2014_cast_fp16, y = _inversed_scores_33_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_33_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_35_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_33_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_35_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2020_cast_fp16 = softmax(axis = var_62, x = scores_35_cast_fp16)[name = tensor<string, []>("op_2020_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_457_cast_fp16 = select(a = var_40_to_fp16, b = var_2020_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_457_cast_fp16")];
            tensor<bool, []> x_221_transpose_x_0 = const()[name = tensor<string, []>("x_221_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_221_transpose_y_0 = const()[name = tensor<string, []>("x_221_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_19_cast_fp16 = transpose(perm = value_19_perm_0, x = v_17_cast_fp16)[name = tensor<string, []>("transpose_166")];
            tensor<fp16, [1, 8, 17, 64]> x_221_cast_fp16 = matmul(transpose_x = x_221_transpose_x_0, transpose_y = x_221_transpose_y_0, x = input_457_cast_fp16, y = value_19_cast_fp16)[name = tensor<string, []>("x_221_cast_fp16")];
            tensor<int32, [4]> var_2024_perm_0 = const()[name = tensor<string, []>("op_2024_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_2025 = const()[name = tensor<string, []>("op_2025"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_2024_cast_fp16 = transpose(perm = var_2024_perm_0, x = x_221_cast_fp16)[name = tensor<string, []>("transpose_162")];
            tensor<fp16, [1, 17, 512]> input_459_cast_fp16 = reshape(shape = var_2025, x = var_2024_cast_fp16)[name = tensor<string, []>("input_459_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_8_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(108781504)))];
            tensor<fp16, [1, 17, 512]> linear_79_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_8_self_attn_linear_out_weight_to_fp16, x = input_459_cast_fp16)[name = tensor<string, []>("linear_79_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_463_cast_fp16 = add(x = input_453_cast_fp16, y = linear_79_cast_fp16)[name = tensor<string, []>("input_463_cast_fp16")];
            tensor<int32, [1]> x_225_axes_0 = const()[name = tensor<string, []>("x_225_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_8_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(109305856)))];
            tensor<fp16, [512]> encoder_layers_8_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(109306944)))];
            tensor<fp16, [1, 17, 512]> x_225_cast_fp16 = layer_norm(axes = x_225_axes_0, beta = encoder_layers_8_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_8_norm_conv_weight_to_fp16, x = input_463_cast_fp16)[name = tensor<string, []>("x_225_cast_fp16")];
            tensor<int32, [3]> input_465_perm_0 = const()[name = tensor<string, []>("input_465_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_467_pad_type_0 = const()[name = tensor<string, []>("input_467_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_467_strides_0 = const()[name = tensor<string, []>("input_467_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_467_pad_0 = const()[name = tensor<string, []>("input_467_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_467_dilations_0 = const()[name = tensor<string, []>("input_467_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_467_groups_0 = const()[name = tensor<string, []>("input_467_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_8_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(109308032)))];
            tensor<fp16, [1, 512, 17]> input_465_cast_fp16 = transpose(perm = input_465_perm_0, x = x_225_cast_fp16)[name = tensor<string, []>("transpose_161")];
            tensor<fp16, [1, 1024, 17]> input_467_cast_fp16 = conv(dilations = input_467_dilations_0, groups = input_467_groups_0, pad = input_467_pad_0, pad_type = input_467_pad_type_0, strides = input_467_strides_0, weight = encoder_layers_8_conv_pointwise_conv1_weight_to_fp16, x = input_465_cast_fp16)[name = tensor<string, []>("input_467_cast_fp16")];
            tensor<int32, []> x_227_split_num_splits_0 = const()[name = tensor<string, []>("x_227_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_227_split_axis_0 = const()[name = tensor<string, []>("x_227_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_227_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_227_split_cast_fp16_1 = split(axis = x_227_split_axis_0, num_splits = x_227_split_num_splits_0, x = input_467_cast_fp16)[name = tensor<string, []>("x_227_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_227_split_1_sigmoid_cast_fp16 = sigmoid(x = x_227_split_cast_fp16_1)[name = tensor<string, []>("x_227_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_227_cast_fp16 = mul(x = x_227_split_cast_fp16_0, y = x_227_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_227_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_469_cast_fp16 = select(a = var_40_to_fp16, b = x_227_cast_fp16, cond = var_418)[name = tensor<string, []>("input_469_cast_fp16")];
            tensor<bool, []> new_x_35_interleave_0 = const()[name = tensor<string, []>("new_x_35_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_35_cast_fp16 = concat(axis = var_62, interleave = new_x_35_interleave_0, values = (cache_35_cast_fp16, input_469_cast_fp16))[name = tensor<string, []>("new_x_35_cast_fp16")];
            tensor<int32, [3]> var_2063_begin_0 = const()[name = tensor<string, []>("op_2063_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_2063_end_0 = const()[name = tensor<string, []>("op_2063_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_2063_end_mask_0 = const()[name = tensor<string, []>("op_2063_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_2063_cast_fp16 = slice_by_index(begin = var_2063_begin_0, end = var_2063_end_0, end_mask = var_2063_end_mask_0, x = new_x_35_cast_fp16)[name = tensor<string, []>("op_2063_cast_fp16")];
            tensor<string, []> x_229_pad_type_0 = const()[name = tensor<string, []>("x_229_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_229_groups_0 = const()[name = tensor<string, []>("x_229_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_229_strides_0 = const()[name = tensor<string, []>("x_229_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_229_pad_0 = const()[name = tensor<string, []>("x_229_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_229_dilations_0 = const()[name = tensor<string, []>("x_229_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_8_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110356672)))];
            tensor<fp16, [1, 512, 17]> x_229_cast_fp16 = conv(dilations = x_229_dilations_0, groups = x_229_groups_0, pad = x_229_pad_0, pad_type = x_229_pad_type_0, strides = x_229_strides_0, weight = encoder_layers_8_conv_depthwise_conv_weight_to_fp16, x = new_x_35_cast_fp16)[name = tensor<string, []>("x_229_cast_fp16")];
            tensor<int32, [3]> input_471_perm_0 = const()[name = tensor<string, []>("input_471_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_231_axes_0 = const()[name = tensor<string, []>("x_231_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_8_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110365952)))];
            tensor<fp16, [512]> encoder_layers_8_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110367040)))];
            tensor<fp16, [1, 17, 512]> input_471_cast_fp16 = transpose(perm = input_471_perm_0, x = x_229_cast_fp16)[name = tensor<string, []>("transpose_160")];
            tensor<fp16, [1, 17, 512]> x_231_cast_fp16 = layer_norm(axes = x_231_axes_0, beta = encoder_layers_8_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_8_conv_batch_norm_weight_to_fp16, x = input_471_cast_fp16)[name = tensor<string, []>("x_231_cast_fp16")];
            tensor<int32, [3]> input_473_perm_0 = const()[name = tensor<string, []>("input_473_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_473_cast_fp16 = transpose(perm = input_473_perm_0, x = x_231_cast_fp16)[name = tensor<string, []>("transpose_159")];
            tensor<fp16, [1, 512, 17]> input_475_cast_fp16 = silu(x = input_473_cast_fp16)[name = tensor<string, []>("input_475_cast_fp16")];
            tensor<string, []> x_233_pad_type_0 = const()[name = tensor<string, []>("x_233_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_233_strides_0 = const()[name = tensor<string, []>("x_233_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_233_pad_0 = const()[name = tensor<string, []>("x_233_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_233_dilations_0 = const()[name = tensor<string, []>("x_233_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_233_groups_0 = const()[name = tensor<string, []>("x_233_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_8_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110368128)))];
            tensor<fp16, [1, 512, 17]> x_233_cast_fp16 = conv(dilations = x_233_dilations_0, groups = x_233_groups_0, pad = x_233_pad_0, pad_type = x_233_pad_type_0, strides = x_233_strides_0, weight = encoder_layers_8_conv_pointwise_conv2_weight_to_fp16, x = input_475_cast_fp16)[name = tensor<string, []>("x_233_cast_fp16")];
            tensor<int32, [3]> input_477_perm_0 = const()[name = tensor<string, []>("input_477_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_477_cast_fp16 = transpose(perm = input_477_perm_0, x = x_233_cast_fp16)[name = tensor<string, []>("transpose_158")];
            tensor<fp16, [1, 17, 512]> input_479_cast_fp16 = add(x = input_463_cast_fp16, y = input_477_cast_fp16)[name = tensor<string, []>("input_479_cast_fp16")];
            tensor<int32, [1]> input_481_axes_0 = const()[name = tensor<string, []>("input_481_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_8_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110892480)))];
            tensor<fp16, [512]> encoder_layers_8_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110893568)))];
            tensor<fp16, [1, 17, 512]> input_481_cast_fp16 = layer_norm(axes = input_481_axes_0, beta = encoder_layers_8_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_8_norm_feed_forward2_weight_to_fp16, x = input_479_cast_fp16)[name = tensor<string, []>("input_481_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_8_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110894656)))];
            tensor<fp16, [1, 17, 2048]> linear_80_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_8_feed_forward2_linear1_weight_to_fp16, x = input_481_cast_fp16)[name = tensor<string, []>("linear_80_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_485_cast_fp16 = silu(x = linear_80_cast_fp16)[name = tensor<string, []>("input_485_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_8_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(112991872)))];
            tensor<fp16, [1, 17, 512]> linear_81_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_8_feed_forward2_linear2_weight_to_fp16, x = input_485_cast_fp16)[name = tensor<string, []>("linear_81_cast_fp16")];
            tensor<fp16, []> var_2104_to_fp16 = const()[name = tensor<string, []>("op_2104_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2105_cast_fp16 = mul(x = linear_81_cast_fp16, y = var_2104_to_fp16)[name = tensor<string, []>("op_2105_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_491_cast_fp16 = add(x = input_479_cast_fp16, y = var_2105_cast_fp16)[name = tensor<string, []>("input_491_cast_fp16")];
            tensor<int32, [1]> input_493_axes_0 = const()[name = tensor<string, []>("input_493_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_8_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(115089088)))];
            tensor<fp16, [512]> encoder_layers_8_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_8_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(115090176)))];
            tensor<fp16, [1, 17, 512]> input_493_cast_fp16 = layer_norm(axes = input_493_axes_0, beta = encoder_layers_8_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_8_norm_out_weight_to_fp16, x = input_491_cast_fp16)[name = tensor<string, []>("input_493_cast_fp16")];
            tensor<int32, [4]> cache_37_begin_0 = const()[name = tensor<string, []>("cache_37_begin_0"), val = tensor<int32, [4]>([9, 0, 0, 0])];
            tensor<int32, [4]> cache_37_end_0 = const()[name = tensor<string, []>("cache_37_end_0"), val = tensor<int32, [4]>([10, 1, 70, 512])];
            tensor<bool, [4]> cache_37_end_mask_0 = const()[name = tensor<string, []>("cache_37_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_37_squeeze_mask_0 = const()[name = tensor<string, []>("cache_37_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_37_cast_fp16 = slice_by_index(begin = cache_37_begin_0, end = cache_37_end_0, end_mask = cache_37_end_mask_0, squeeze_mask = cache_37_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_37_cast_fp16")];
            tensor<int32, [4]> cache_39_begin_0 = const()[name = tensor<string, []>("cache_39_begin_0"), val = tensor<int32, [4]>([9, 0, 0, 0])];
            tensor<int32, [4]> cache_39_end_0 = const()[name = tensor<string, []>("cache_39_end_0"), val = tensor<int32, [4]>([10, 1, 512, 8])];
            tensor<bool, [4]> cache_39_end_mask_0 = const()[name = tensor<string, []>("cache_39_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_39_squeeze_mask_0 = const()[name = tensor<string, []>("cache_39_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_39_cast_fp16 = slice_by_index(begin = cache_39_begin_0, end = cache_39_end_0, end_mask = cache_39_end_mask_0, squeeze_mask = cache_39_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_39_cast_fp16")];
            tensor<int32, [1]> input_495_axes_0 = const()[name = tensor<string, []>("input_495_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_9_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(115091264)))];
            tensor<fp16, [512]> encoder_layers_9_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(115092352)))];
            tensor<fp16, [1, 17, 512]> input_495_cast_fp16 = layer_norm(axes = input_495_axes_0, beta = encoder_layers_9_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_9_norm_feed_forward1_weight_to_fp16, x = input_493_cast_fp16)[name = tensor<string, []>("input_495_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_9_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(115093440)))];
            tensor<fp16, [1, 17, 2048]> linear_82_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_9_feed_forward1_linear1_weight_to_fp16, x = input_495_cast_fp16)[name = tensor<string, []>("linear_82_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_499_cast_fp16 = silu(x = linear_82_cast_fp16)[name = tensor<string, []>("input_499_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_9_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(117190656)))];
            tensor<fp16, [1, 17, 512]> linear_83_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_9_feed_forward1_linear2_weight_to_fp16, x = input_499_cast_fp16)[name = tensor<string, []>("linear_83_cast_fp16")];
            tensor<fp16, []> var_2139_to_fp16 = const()[name = tensor<string, []>("op_2139_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2140_cast_fp16 = mul(x = linear_83_cast_fp16, y = var_2139_to_fp16)[name = tensor<string, []>("op_2140_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_505_cast_fp16 = add(x = input_493_cast_fp16, y = var_2140_cast_fp16)[name = tensor<string, []>("input_505_cast_fp16")];
            tensor<int32, [1]> key_19_axes_0 = const()[name = tensor<string, []>("key_19_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_9_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(119287872)))];
            tensor<fp16, [512]> encoder_layers_9_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(119288960)))];
            tensor<fp16, [1, 17, 512]> key_19_cast_fp16 = layer_norm(axes = key_19_axes_0, beta = encoder_layers_9_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_9_norm_self_att_weight_to_fp16, x = input_505_cast_fp16)[name = tensor<string, []>("key_19_cast_fp16")];
            tensor<bool, []> input_507_interleave_0 = const()[name = tensor<string, []>("input_507_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_507_cast_fp16 = concat(axis = var_64, interleave = input_507_interleave_0, values = (cache_37_cast_fp16, key_19_cast_fp16))[name = tensor<string, []>("input_507_cast_fp16")];
            tensor<int32, [3]> var_2162_begin_0 = const()[name = tensor<string, []>("op_2162_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_2162_end_0 = const()[name = tensor<string, []>("op_2162_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_2162_end_mask_0 = const()[name = tensor<string, []>("op_2162_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_2162_cast_fp16 = slice_by_index(begin = var_2162_begin_0, end = var_2162_end_0, end_mask = var_2162_end_mask_0, x = cache_37_cast_fp16)[name = tensor<string, []>("op_2162_cast_fp16")];
            tensor<bool, []> var_2168_interleave_0 = const()[name = tensor<string, []>("op_2168_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_2168_cast_fp16 = concat(axis = var_64, interleave = var_2168_interleave_0, values = (var_2162_cast_fp16, key_19_cast_fp16))[name = tensor<string, []>("op_2168_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_9_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(119290048)))];
            tensor<fp16, [1, 17, 512]> linear_84_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_9_self_attn_linear_q_weight_to_fp16, x = key_19_cast_fp16)[name = tensor<string, []>("linear_84_cast_fp16")];
            tensor<int32, [4]> var_2172 = const()[name = tensor<string, []>("op_2172"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_55_cast_fp16 = reshape(shape = var_2172, x = linear_84_cast_fp16)[name = tensor<string, []>("q_55_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_9_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(119814400)))];
            tensor<fp16, [1, 87, 512]> linear_85_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_9_self_attn_linear_k_weight_to_fp16, x = input_507_cast_fp16)[name = tensor<string, []>("linear_85_cast_fp16")];
            tensor<int32, [4]> var_2176 = const()[name = tensor<string, []>("op_2176"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_37_cast_fp16 = reshape(shape = var_2176, x = linear_85_cast_fp16)[name = tensor<string, []>("k_37_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_9_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(120338752)))];
            tensor<fp16, [1, 87, 512]> linear_86_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_9_self_attn_linear_v_weight_to_fp16, x = input_507_cast_fp16)[name = tensor<string, []>("linear_86_cast_fp16")];
            tensor<int32, [4]> var_2180 = const()[name = tensor<string, []>("op_2180"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_19_cast_fp16 = reshape(shape = var_2180, x = linear_86_cast_fp16)[name = tensor<string, []>("v_19_cast_fp16")];
            tensor<int32, [4]> value_21_perm_0 = const()[name = tensor<string, []>("value_21_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_9_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(120863104)))];
            tensor<fp16, [1, 17, 8, 64]> var_2192_cast_fp16 = add(x = q_55_cast_fp16, y = encoder_layers_9_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_2192_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_9_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(120864192)))];
            tensor<fp16, [1, 17, 8, 64]> var_2194_cast_fp16 = add(x = q_55_cast_fp16, y = encoder_layers_9_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_2194_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_19_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_19_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_241_transpose_x_0 = const()[name = tensor<string, []>("x_241_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_241_transpose_y_0 = const()[name = tensor<string, []>("x_241_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_2196_to_fp16 = const()[name = tensor<string, []>("op_2196_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(120865280)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_19_cast_fp16 = transpose(perm = q_with_bias_v_19_perm_0, x = var_2194_cast_fp16)[name = tensor<string, []>("transpose_156")];
            tensor<fp16, [1, 8, 17, 173]> x_241_cast_fp16 = matmul(transpose_x = x_241_transpose_x_0, transpose_y = x_241_transpose_y_0, x = q_with_bias_v_19_cast_fp16, y = var_2196_to_fp16)[name = tensor<string, []>("x_241_cast_fp16")];
            tensor<int32, [8]> x_243_pad_0 = const()[name = tensor<string, []>("x_243_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_243_mode_0 = const()[name = tensor<string, []>("x_243_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_140_to_fp16 = const()[name = tensor<string, []>("const_140_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_243_cast_fp16 = pad(constant_val = const_140_to_fp16, mode = x_243_mode_0, pad = x_243_pad_0, x = x_241_cast_fp16)[name = tensor<string, []>("x_243_cast_fp16")];
            tensor<int32, [4]> var_2204 = const()[name = tensor<string, []>("op_2204"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_245_cast_fp16 = reshape(shape = var_2204, x = x_243_cast_fp16)[name = tensor<string, []>("x_245_cast_fp16")];
            tensor<int32, [4]> var_2208_begin_0 = const()[name = tensor<string, []>("op_2208_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_2208_end_0 = const()[name = tensor<string, []>("op_2208_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_2208_end_mask_0 = const()[name = tensor<string, []>("op_2208_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_2208_cast_fp16 = slice_by_index(begin = var_2208_begin_0, end = var_2208_end_0, end_mask = var_2208_end_mask_0, x = x_245_cast_fp16)[name = tensor<string, []>("op_2208_cast_fp16")];
            tensor<int32, [4]> var_2209 = const()[name = tensor<string, []>("op_2209"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_37_cast_fp16 = reshape(shape = var_2209, x = var_2208_cast_fp16)[name = tensor<string, []>("matrix_bd_37_cast_fp16")];
            tensor<bool, []> matrix_ac_19_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_19_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_19_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_19_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_69_perm_0 = const()[name = tensor<string, []>("transpose_69_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_70_perm_0 = const()[name = tensor<string, []>("transpose_70_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_70 = transpose(perm = transpose_70_perm_0, x = k_37_cast_fp16)[name = tensor<string, []>("transpose_154")];
            tensor<fp16, [1, 8, 17, 64]> transpose_69 = transpose(perm = transpose_69_perm_0, x = var_2192_cast_fp16)[name = tensor<string, []>("transpose_155")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_19_cast_fp16 = matmul(transpose_x = matrix_ac_19_transpose_x_0, transpose_y = matrix_ac_19_transpose_y_0, x = transpose_69, y = transpose_70)[name = tensor<string, []>("matrix_ac_19_cast_fp16")];
            tensor<int32, [4]> matrix_bd_39_begin_0 = const()[name = tensor<string, []>("matrix_bd_39_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_39_end_0 = const()[name = tensor<string, []>("matrix_bd_39_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_39_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_39_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_39_cast_fp16 = slice_by_index(begin = matrix_bd_39_begin_0, end = matrix_bd_39_end_0, end_mask = matrix_bd_39_end_mask_0, x = matrix_bd_37_cast_fp16)[name = tensor<string, []>("matrix_bd_39_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2218_cast_fp16 = add(x = matrix_ac_19_cast_fp16, y = matrix_bd_39_cast_fp16)[name = tensor<string, []>("op_2218_cast_fp16")];
            tensor<fp16, []> _inversed_scores_37_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_37_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_37_cast_fp16 = mul(x = var_2218_cast_fp16, y = _inversed_scores_37_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_37_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_39_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_37_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_39_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2224_cast_fp16 = softmax(axis = var_62, x = scores_39_cast_fp16)[name = tensor<string, []>("op_2224_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_509_cast_fp16 = select(a = var_40_to_fp16, b = var_2224_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_509_cast_fp16")];
            tensor<bool, []> x_247_transpose_x_0 = const()[name = tensor<string, []>("x_247_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_247_transpose_y_0 = const()[name = tensor<string, []>("x_247_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_21_cast_fp16 = transpose(perm = value_21_perm_0, x = v_19_cast_fp16)[name = tensor<string, []>("transpose_157")];
            tensor<fp16, [1, 8, 17, 64]> x_247_cast_fp16 = matmul(transpose_x = x_247_transpose_x_0, transpose_y = x_247_transpose_y_0, x = input_509_cast_fp16, y = value_21_cast_fp16)[name = tensor<string, []>("x_247_cast_fp16")];
            tensor<int32, [4]> var_2228_perm_0 = const()[name = tensor<string, []>("op_2228_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_2229 = const()[name = tensor<string, []>("op_2229"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_2228_cast_fp16 = transpose(perm = var_2228_perm_0, x = x_247_cast_fp16)[name = tensor<string, []>("transpose_153")];
            tensor<fp16, [1, 17, 512]> input_511_cast_fp16 = reshape(shape = var_2229, x = var_2228_cast_fp16)[name = tensor<string, []>("input_511_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_9_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(121042496)))];
            tensor<fp16, [1, 17, 512]> linear_88_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_9_self_attn_linear_out_weight_to_fp16, x = input_511_cast_fp16)[name = tensor<string, []>("linear_88_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_515_cast_fp16 = add(x = input_505_cast_fp16, y = linear_88_cast_fp16)[name = tensor<string, []>("input_515_cast_fp16")];
            tensor<int32, [1]> x_251_axes_0 = const()[name = tensor<string, []>("x_251_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_9_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(121566848)))];
            tensor<fp16, [512]> encoder_layers_9_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(121567936)))];
            tensor<fp16, [1, 17, 512]> x_251_cast_fp16 = layer_norm(axes = x_251_axes_0, beta = encoder_layers_9_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_9_norm_conv_weight_to_fp16, x = input_515_cast_fp16)[name = tensor<string, []>("x_251_cast_fp16")];
            tensor<int32, [3]> input_517_perm_0 = const()[name = tensor<string, []>("input_517_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_519_pad_type_0 = const()[name = tensor<string, []>("input_519_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_519_strides_0 = const()[name = tensor<string, []>("input_519_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_519_pad_0 = const()[name = tensor<string, []>("input_519_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_519_dilations_0 = const()[name = tensor<string, []>("input_519_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_519_groups_0 = const()[name = tensor<string, []>("input_519_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_9_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(121569024)))];
            tensor<fp16, [1, 512, 17]> input_517_cast_fp16 = transpose(perm = input_517_perm_0, x = x_251_cast_fp16)[name = tensor<string, []>("transpose_152")];
            tensor<fp16, [1, 1024, 17]> input_519_cast_fp16 = conv(dilations = input_519_dilations_0, groups = input_519_groups_0, pad = input_519_pad_0, pad_type = input_519_pad_type_0, strides = input_519_strides_0, weight = encoder_layers_9_conv_pointwise_conv1_weight_to_fp16, x = input_517_cast_fp16)[name = tensor<string, []>("input_519_cast_fp16")];
            tensor<int32, []> x_253_split_num_splits_0 = const()[name = tensor<string, []>("x_253_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_253_split_axis_0 = const()[name = tensor<string, []>("x_253_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_253_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_253_split_cast_fp16_1 = split(axis = x_253_split_axis_0, num_splits = x_253_split_num_splits_0, x = input_519_cast_fp16)[name = tensor<string, []>("x_253_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_253_split_1_sigmoid_cast_fp16 = sigmoid(x = x_253_split_cast_fp16_1)[name = tensor<string, []>("x_253_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_253_cast_fp16 = mul(x = x_253_split_cast_fp16_0, y = x_253_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_253_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_521_cast_fp16 = select(a = var_40_to_fp16, b = x_253_cast_fp16, cond = var_418)[name = tensor<string, []>("input_521_cast_fp16")];
            tensor<bool, []> new_x_39_interleave_0 = const()[name = tensor<string, []>("new_x_39_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_39_cast_fp16 = concat(axis = var_62, interleave = new_x_39_interleave_0, values = (cache_39_cast_fp16, input_521_cast_fp16))[name = tensor<string, []>("new_x_39_cast_fp16")];
            tensor<int32, [3]> var_2267_begin_0 = const()[name = tensor<string, []>("op_2267_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_2267_end_0 = const()[name = tensor<string, []>("op_2267_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_2267_end_mask_0 = const()[name = tensor<string, []>("op_2267_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_2267_cast_fp16 = slice_by_index(begin = var_2267_begin_0, end = var_2267_end_0, end_mask = var_2267_end_mask_0, x = new_x_39_cast_fp16)[name = tensor<string, []>("op_2267_cast_fp16")];
            tensor<string, []> x_255_pad_type_0 = const()[name = tensor<string, []>("x_255_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_255_groups_0 = const()[name = tensor<string, []>("x_255_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_255_strides_0 = const()[name = tensor<string, []>("x_255_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_255_pad_0 = const()[name = tensor<string, []>("x_255_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_255_dilations_0 = const()[name = tensor<string, []>("x_255_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_9_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(122617664)))];
            tensor<fp16, [1, 512, 17]> x_255_cast_fp16 = conv(dilations = x_255_dilations_0, groups = x_255_groups_0, pad = x_255_pad_0, pad_type = x_255_pad_type_0, strides = x_255_strides_0, weight = encoder_layers_9_conv_depthwise_conv_weight_to_fp16, x = new_x_39_cast_fp16)[name = tensor<string, []>("x_255_cast_fp16")];
            tensor<int32, [3]> input_523_perm_0 = const()[name = tensor<string, []>("input_523_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_257_axes_0 = const()[name = tensor<string, []>("x_257_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_9_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(122626944)))];
            tensor<fp16, [512]> encoder_layers_9_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(122628032)))];
            tensor<fp16, [1, 17, 512]> input_523_cast_fp16 = transpose(perm = input_523_perm_0, x = x_255_cast_fp16)[name = tensor<string, []>("transpose_151")];
            tensor<fp16, [1, 17, 512]> x_257_cast_fp16 = layer_norm(axes = x_257_axes_0, beta = encoder_layers_9_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_9_conv_batch_norm_weight_to_fp16, x = input_523_cast_fp16)[name = tensor<string, []>("x_257_cast_fp16")];
            tensor<int32, [3]> input_525_perm_0 = const()[name = tensor<string, []>("input_525_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_525_cast_fp16 = transpose(perm = input_525_perm_0, x = x_257_cast_fp16)[name = tensor<string, []>("transpose_150")];
            tensor<fp16, [1, 512, 17]> input_527_cast_fp16 = silu(x = input_525_cast_fp16)[name = tensor<string, []>("input_527_cast_fp16")];
            tensor<string, []> x_259_pad_type_0 = const()[name = tensor<string, []>("x_259_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_259_strides_0 = const()[name = tensor<string, []>("x_259_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_259_pad_0 = const()[name = tensor<string, []>("x_259_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_259_dilations_0 = const()[name = tensor<string, []>("x_259_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_259_groups_0 = const()[name = tensor<string, []>("x_259_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_9_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(122629120)))];
            tensor<fp16, [1, 512, 17]> x_259_cast_fp16 = conv(dilations = x_259_dilations_0, groups = x_259_groups_0, pad = x_259_pad_0, pad_type = x_259_pad_type_0, strides = x_259_strides_0, weight = encoder_layers_9_conv_pointwise_conv2_weight_to_fp16, x = input_527_cast_fp16)[name = tensor<string, []>("x_259_cast_fp16")];
            tensor<int32, [3]> input_529_perm_0 = const()[name = tensor<string, []>("input_529_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_529_cast_fp16 = transpose(perm = input_529_perm_0, x = x_259_cast_fp16)[name = tensor<string, []>("transpose_149")];
            tensor<fp16, [1, 17, 512]> input_531_cast_fp16 = add(x = input_515_cast_fp16, y = input_529_cast_fp16)[name = tensor<string, []>("input_531_cast_fp16")];
            tensor<int32, [1]> input_533_axes_0 = const()[name = tensor<string, []>("input_533_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_9_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(123153472)))];
            tensor<fp16, [512]> encoder_layers_9_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(123154560)))];
            tensor<fp16, [1, 17, 512]> input_533_cast_fp16 = layer_norm(axes = input_533_axes_0, beta = encoder_layers_9_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_9_norm_feed_forward2_weight_to_fp16, x = input_531_cast_fp16)[name = tensor<string, []>("input_533_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_9_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(123155648)))];
            tensor<fp16, [1, 17, 2048]> linear_89_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_9_feed_forward2_linear1_weight_to_fp16, x = input_533_cast_fp16)[name = tensor<string, []>("linear_89_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_537_cast_fp16 = silu(x = linear_89_cast_fp16)[name = tensor<string, []>("input_537_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_9_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(125252864)))];
            tensor<fp16, [1, 17, 512]> linear_90_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_9_feed_forward2_linear2_weight_to_fp16, x = input_537_cast_fp16)[name = tensor<string, []>("linear_90_cast_fp16")];
            tensor<fp16, []> var_2308_to_fp16 = const()[name = tensor<string, []>("op_2308_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2309_cast_fp16 = mul(x = linear_90_cast_fp16, y = var_2308_to_fp16)[name = tensor<string, []>("op_2309_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_543_cast_fp16 = add(x = input_531_cast_fp16, y = var_2309_cast_fp16)[name = tensor<string, []>("input_543_cast_fp16")];
            tensor<int32, [1]> input_545_axes_0 = const()[name = tensor<string, []>("input_545_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_9_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(127350080)))];
            tensor<fp16, [512]> encoder_layers_9_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_9_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(127351168)))];
            tensor<fp16, [1, 17, 512]> input_545_cast_fp16 = layer_norm(axes = input_545_axes_0, beta = encoder_layers_9_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_9_norm_out_weight_to_fp16, x = input_543_cast_fp16)[name = tensor<string, []>("input_545_cast_fp16")];
            tensor<int32, [4]> cache_41_begin_0 = const()[name = tensor<string, []>("cache_41_begin_0"), val = tensor<int32, [4]>([10, 0, 0, 0])];
            tensor<int32, [4]> cache_41_end_0 = const()[name = tensor<string, []>("cache_41_end_0"), val = tensor<int32, [4]>([11, 1, 70, 512])];
            tensor<bool, [4]> cache_41_end_mask_0 = const()[name = tensor<string, []>("cache_41_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_41_squeeze_mask_0 = const()[name = tensor<string, []>("cache_41_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_41_cast_fp16 = slice_by_index(begin = cache_41_begin_0, end = cache_41_end_0, end_mask = cache_41_end_mask_0, squeeze_mask = cache_41_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_41_cast_fp16")];
            tensor<int32, [4]> cache_43_begin_0 = const()[name = tensor<string, []>("cache_43_begin_0"), val = tensor<int32, [4]>([10, 0, 0, 0])];
            tensor<int32, [4]> cache_43_end_0 = const()[name = tensor<string, []>("cache_43_end_0"), val = tensor<int32, [4]>([11, 1, 512, 8])];
            tensor<bool, [4]> cache_43_end_mask_0 = const()[name = tensor<string, []>("cache_43_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_43_squeeze_mask_0 = const()[name = tensor<string, []>("cache_43_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_43_cast_fp16 = slice_by_index(begin = cache_43_begin_0, end = cache_43_end_0, end_mask = cache_43_end_mask_0, squeeze_mask = cache_43_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_43_cast_fp16")];
            tensor<int32, [1]> input_547_axes_0 = const()[name = tensor<string, []>("input_547_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_10_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(127352256)))];
            tensor<fp16, [512]> encoder_layers_10_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(127353344)))];
            tensor<fp16, [1, 17, 512]> input_547_cast_fp16 = layer_norm(axes = input_547_axes_0, beta = encoder_layers_10_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_10_norm_feed_forward1_weight_to_fp16, x = input_545_cast_fp16)[name = tensor<string, []>("input_547_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_10_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(127354432)))];
            tensor<fp16, [1, 17, 2048]> linear_91_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_10_feed_forward1_linear1_weight_to_fp16, x = input_547_cast_fp16)[name = tensor<string, []>("linear_91_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_551_cast_fp16 = silu(x = linear_91_cast_fp16)[name = tensor<string, []>("input_551_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_10_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(129451648)))];
            tensor<fp16, [1, 17, 512]> linear_92_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_10_feed_forward1_linear2_weight_to_fp16, x = input_551_cast_fp16)[name = tensor<string, []>("linear_92_cast_fp16")];
            tensor<fp16, []> var_2343_to_fp16 = const()[name = tensor<string, []>("op_2343_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2344_cast_fp16 = mul(x = linear_92_cast_fp16, y = var_2343_to_fp16)[name = tensor<string, []>("op_2344_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_557_cast_fp16 = add(x = input_545_cast_fp16, y = var_2344_cast_fp16)[name = tensor<string, []>("input_557_cast_fp16")];
            tensor<int32, [1]> key_21_axes_0 = const()[name = tensor<string, []>("key_21_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_10_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(131548864)))];
            tensor<fp16, [512]> encoder_layers_10_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(131549952)))];
            tensor<fp16, [1, 17, 512]> key_21_cast_fp16 = layer_norm(axes = key_21_axes_0, beta = encoder_layers_10_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_10_norm_self_att_weight_to_fp16, x = input_557_cast_fp16)[name = tensor<string, []>("key_21_cast_fp16")];
            tensor<bool, []> input_559_interleave_0 = const()[name = tensor<string, []>("input_559_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_559_cast_fp16 = concat(axis = var_64, interleave = input_559_interleave_0, values = (cache_41_cast_fp16, key_21_cast_fp16))[name = tensor<string, []>("input_559_cast_fp16")];
            tensor<int32, [3]> var_2366_begin_0 = const()[name = tensor<string, []>("op_2366_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_2366_end_0 = const()[name = tensor<string, []>("op_2366_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_2366_end_mask_0 = const()[name = tensor<string, []>("op_2366_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_2366_cast_fp16 = slice_by_index(begin = var_2366_begin_0, end = var_2366_end_0, end_mask = var_2366_end_mask_0, x = cache_41_cast_fp16)[name = tensor<string, []>("op_2366_cast_fp16")];
            tensor<bool, []> var_2372_interleave_0 = const()[name = tensor<string, []>("op_2372_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_2372_cast_fp16 = concat(axis = var_64, interleave = var_2372_interleave_0, values = (var_2366_cast_fp16, key_21_cast_fp16))[name = tensor<string, []>("op_2372_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_10_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(131551040)))];
            tensor<fp16, [1, 17, 512]> linear_93_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_10_self_attn_linear_q_weight_to_fp16, x = key_21_cast_fp16)[name = tensor<string, []>("linear_93_cast_fp16")];
            tensor<int32, [4]> var_2376 = const()[name = tensor<string, []>("op_2376"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_61_cast_fp16 = reshape(shape = var_2376, x = linear_93_cast_fp16)[name = tensor<string, []>("q_61_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_10_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(132075392)))];
            tensor<fp16, [1, 87, 512]> linear_94_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_10_self_attn_linear_k_weight_to_fp16, x = input_559_cast_fp16)[name = tensor<string, []>("linear_94_cast_fp16")];
            tensor<int32, [4]> var_2380 = const()[name = tensor<string, []>("op_2380"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_41_cast_fp16 = reshape(shape = var_2380, x = linear_94_cast_fp16)[name = tensor<string, []>("k_41_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_10_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(132599744)))];
            tensor<fp16, [1, 87, 512]> linear_95_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_10_self_attn_linear_v_weight_to_fp16, x = input_559_cast_fp16)[name = tensor<string, []>("linear_95_cast_fp16")];
            tensor<int32, [4]> var_2384 = const()[name = tensor<string, []>("op_2384"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_21_cast_fp16 = reshape(shape = var_2384, x = linear_95_cast_fp16)[name = tensor<string, []>("v_21_cast_fp16")];
            tensor<int32, [4]> value_23_perm_0 = const()[name = tensor<string, []>("value_23_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_10_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133124096)))];
            tensor<fp16, [1, 17, 8, 64]> var_2396_cast_fp16 = add(x = q_61_cast_fp16, y = encoder_layers_10_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_2396_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_10_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133125184)))];
            tensor<fp16, [1, 17, 8, 64]> var_2398_cast_fp16 = add(x = q_61_cast_fp16, y = encoder_layers_10_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_2398_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_21_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_21_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_267_transpose_x_0 = const()[name = tensor<string, []>("x_267_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_267_transpose_y_0 = const()[name = tensor<string, []>("x_267_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_2400_to_fp16 = const()[name = tensor<string, []>("op_2400_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133126272)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_21_cast_fp16 = transpose(perm = q_with_bias_v_21_perm_0, x = var_2398_cast_fp16)[name = tensor<string, []>("transpose_147")];
            tensor<fp16, [1, 8, 17, 173]> x_267_cast_fp16 = matmul(transpose_x = x_267_transpose_x_0, transpose_y = x_267_transpose_y_0, x = q_with_bias_v_21_cast_fp16, y = var_2400_to_fp16)[name = tensor<string, []>("x_267_cast_fp16")];
            tensor<int32, [8]> x_269_pad_0 = const()[name = tensor<string, []>("x_269_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_269_mode_0 = const()[name = tensor<string, []>("x_269_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_153_to_fp16 = const()[name = tensor<string, []>("const_153_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_269_cast_fp16 = pad(constant_val = const_153_to_fp16, mode = x_269_mode_0, pad = x_269_pad_0, x = x_267_cast_fp16)[name = tensor<string, []>("x_269_cast_fp16")];
            tensor<int32, [4]> var_2408 = const()[name = tensor<string, []>("op_2408"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_271_cast_fp16 = reshape(shape = var_2408, x = x_269_cast_fp16)[name = tensor<string, []>("x_271_cast_fp16")];
            tensor<int32, [4]> var_2412_begin_0 = const()[name = tensor<string, []>("op_2412_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_2412_end_0 = const()[name = tensor<string, []>("op_2412_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_2412_end_mask_0 = const()[name = tensor<string, []>("op_2412_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_2412_cast_fp16 = slice_by_index(begin = var_2412_begin_0, end = var_2412_end_0, end_mask = var_2412_end_mask_0, x = x_271_cast_fp16)[name = tensor<string, []>("op_2412_cast_fp16")];
            tensor<int32, [4]> var_2413 = const()[name = tensor<string, []>("op_2413"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_41_cast_fp16 = reshape(shape = var_2413, x = var_2412_cast_fp16)[name = tensor<string, []>("matrix_bd_41_cast_fp16")];
            tensor<bool, []> matrix_ac_21_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_21_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_21_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_21_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_71_perm_0 = const()[name = tensor<string, []>("transpose_71_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_72_perm_0 = const()[name = tensor<string, []>("transpose_72_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_72 = transpose(perm = transpose_72_perm_0, x = k_41_cast_fp16)[name = tensor<string, []>("transpose_145")];
            tensor<fp16, [1, 8, 17, 64]> transpose_71 = transpose(perm = transpose_71_perm_0, x = var_2396_cast_fp16)[name = tensor<string, []>("transpose_146")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_21_cast_fp16 = matmul(transpose_x = matrix_ac_21_transpose_x_0, transpose_y = matrix_ac_21_transpose_y_0, x = transpose_71, y = transpose_72)[name = tensor<string, []>("matrix_ac_21_cast_fp16")];
            tensor<int32, [4]> matrix_bd_43_begin_0 = const()[name = tensor<string, []>("matrix_bd_43_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_43_end_0 = const()[name = tensor<string, []>("matrix_bd_43_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_43_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_43_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_43_cast_fp16 = slice_by_index(begin = matrix_bd_43_begin_0, end = matrix_bd_43_end_0, end_mask = matrix_bd_43_end_mask_0, x = matrix_bd_41_cast_fp16)[name = tensor<string, []>("matrix_bd_43_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2422_cast_fp16 = add(x = matrix_ac_21_cast_fp16, y = matrix_bd_43_cast_fp16)[name = tensor<string, []>("op_2422_cast_fp16")];
            tensor<fp16, []> _inversed_scores_41_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_41_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_41_cast_fp16 = mul(x = var_2422_cast_fp16, y = _inversed_scores_41_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_41_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_43_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_41_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_43_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2428_cast_fp16 = softmax(axis = var_62, x = scores_43_cast_fp16)[name = tensor<string, []>("op_2428_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_561_cast_fp16 = select(a = var_40_to_fp16, b = var_2428_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_561_cast_fp16")];
            tensor<bool, []> x_273_transpose_x_0 = const()[name = tensor<string, []>("x_273_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_273_transpose_y_0 = const()[name = tensor<string, []>("x_273_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_23_cast_fp16 = transpose(perm = value_23_perm_0, x = v_21_cast_fp16)[name = tensor<string, []>("transpose_148")];
            tensor<fp16, [1, 8, 17, 64]> x_273_cast_fp16 = matmul(transpose_x = x_273_transpose_x_0, transpose_y = x_273_transpose_y_0, x = input_561_cast_fp16, y = value_23_cast_fp16)[name = tensor<string, []>("x_273_cast_fp16")];
            tensor<int32, [4]> var_2432_perm_0 = const()[name = tensor<string, []>("op_2432_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_2433 = const()[name = tensor<string, []>("op_2433"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_2432_cast_fp16 = transpose(perm = var_2432_perm_0, x = x_273_cast_fp16)[name = tensor<string, []>("transpose_144")];
            tensor<fp16, [1, 17, 512]> input_563_cast_fp16 = reshape(shape = var_2433, x = var_2432_cast_fp16)[name = tensor<string, []>("input_563_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_10_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133303488)))];
            tensor<fp16, [1, 17, 512]> linear_97_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_10_self_attn_linear_out_weight_to_fp16, x = input_563_cast_fp16)[name = tensor<string, []>("linear_97_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_567_cast_fp16 = add(x = input_557_cast_fp16, y = linear_97_cast_fp16)[name = tensor<string, []>("input_567_cast_fp16")];
            tensor<int32, [1]> x_277_axes_0 = const()[name = tensor<string, []>("x_277_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_10_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133827840)))];
            tensor<fp16, [512]> encoder_layers_10_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133828928)))];
            tensor<fp16, [1, 17, 512]> x_277_cast_fp16 = layer_norm(axes = x_277_axes_0, beta = encoder_layers_10_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_10_norm_conv_weight_to_fp16, x = input_567_cast_fp16)[name = tensor<string, []>("x_277_cast_fp16")];
            tensor<int32, [3]> input_569_perm_0 = const()[name = tensor<string, []>("input_569_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_571_pad_type_0 = const()[name = tensor<string, []>("input_571_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_571_strides_0 = const()[name = tensor<string, []>("input_571_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_571_pad_0 = const()[name = tensor<string, []>("input_571_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_571_dilations_0 = const()[name = tensor<string, []>("input_571_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_571_groups_0 = const()[name = tensor<string, []>("input_571_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_10_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133830016)))];
            tensor<fp16, [1, 512, 17]> input_569_cast_fp16 = transpose(perm = input_569_perm_0, x = x_277_cast_fp16)[name = tensor<string, []>("transpose_143")];
            tensor<fp16, [1, 1024, 17]> input_571_cast_fp16 = conv(dilations = input_571_dilations_0, groups = input_571_groups_0, pad = input_571_pad_0, pad_type = input_571_pad_type_0, strides = input_571_strides_0, weight = encoder_layers_10_conv_pointwise_conv1_weight_to_fp16, x = input_569_cast_fp16)[name = tensor<string, []>("input_571_cast_fp16")];
            tensor<int32, []> x_279_split_num_splits_0 = const()[name = tensor<string, []>("x_279_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_279_split_axis_0 = const()[name = tensor<string, []>("x_279_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_279_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_279_split_cast_fp16_1 = split(axis = x_279_split_axis_0, num_splits = x_279_split_num_splits_0, x = input_571_cast_fp16)[name = tensor<string, []>("x_279_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_279_split_1_sigmoid_cast_fp16 = sigmoid(x = x_279_split_cast_fp16_1)[name = tensor<string, []>("x_279_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_279_cast_fp16 = mul(x = x_279_split_cast_fp16_0, y = x_279_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_279_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_573_cast_fp16 = select(a = var_40_to_fp16, b = x_279_cast_fp16, cond = var_418)[name = tensor<string, []>("input_573_cast_fp16")];
            tensor<bool, []> new_x_43_interleave_0 = const()[name = tensor<string, []>("new_x_43_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_43_cast_fp16 = concat(axis = var_62, interleave = new_x_43_interleave_0, values = (cache_43_cast_fp16, input_573_cast_fp16))[name = tensor<string, []>("new_x_43_cast_fp16")];
            tensor<int32, [3]> var_2471_begin_0 = const()[name = tensor<string, []>("op_2471_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_2471_end_0 = const()[name = tensor<string, []>("op_2471_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_2471_end_mask_0 = const()[name = tensor<string, []>("op_2471_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_2471_cast_fp16 = slice_by_index(begin = var_2471_begin_0, end = var_2471_end_0, end_mask = var_2471_end_mask_0, x = new_x_43_cast_fp16)[name = tensor<string, []>("op_2471_cast_fp16")];
            tensor<string, []> x_281_pad_type_0 = const()[name = tensor<string, []>("x_281_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_281_groups_0 = const()[name = tensor<string, []>("x_281_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_281_strides_0 = const()[name = tensor<string, []>("x_281_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_281_pad_0 = const()[name = tensor<string, []>("x_281_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_281_dilations_0 = const()[name = tensor<string, []>("x_281_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_10_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134878656)))];
            tensor<fp16, [1, 512, 17]> x_281_cast_fp16 = conv(dilations = x_281_dilations_0, groups = x_281_groups_0, pad = x_281_pad_0, pad_type = x_281_pad_type_0, strides = x_281_strides_0, weight = encoder_layers_10_conv_depthwise_conv_weight_to_fp16, x = new_x_43_cast_fp16)[name = tensor<string, []>("x_281_cast_fp16")];
            tensor<int32, [3]> input_575_perm_0 = const()[name = tensor<string, []>("input_575_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_283_axes_0 = const()[name = tensor<string, []>("x_283_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_10_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134887936)))];
            tensor<fp16, [512]> encoder_layers_10_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134889024)))];
            tensor<fp16, [1, 17, 512]> input_575_cast_fp16 = transpose(perm = input_575_perm_0, x = x_281_cast_fp16)[name = tensor<string, []>("transpose_142")];
            tensor<fp16, [1, 17, 512]> x_283_cast_fp16 = layer_norm(axes = x_283_axes_0, beta = encoder_layers_10_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_10_conv_batch_norm_weight_to_fp16, x = input_575_cast_fp16)[name = tensor<string, []>("x_283_cast_fp16")];
            tensor<int32, [3]> input_577_perm_0 = const()[name = tensor<string, []>("input_577_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_577_cast_fp16 = transpose(perm = input_577_perm_0, x = x_283_cast_fp16)[name = tensor<string, []>("transpose_141")];
            tensor<fp16, [1, 512, 17]> input_579_cast_fp16 = silu(x = input_577_cast_fp16)[name = tensor<string, []>("input_579_cast_fp16")];
            tensor<string, []> x_285_pad_type_0 = const()[name = tensor<string, []>("x_285_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_285_strides_0 = const()[name = tensor<string, []>("x_285_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_285_pad_0 = const()[name = tensor<string, []>("x_285_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_285_dilations_0 = const()[name = tensor<string, []>("x_285_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_285_groups_0 = const()[name = tensor<string, []>("x_285_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_10_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134890112)))];
            tensor<fp16, [1, 512, 17]> x_285_cast_fp16 = conv(dilations = x_285_dilations_0, groups = x_285_groups_0, pad = x_285_pad_0, pad_type = x_285_pad_type_0, strides = x_285_strides_0, weight = encoder_layers_10_conv_pointwise_conv2_weight_to_fp16, x = input_579_cast_fp16)[name = tensor<string, []>("x_285_cast_fp16")];
            tensor<int32, [3]> input_581_perm_0 = const()[name = tensor<string, []>("input_581_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_581_cast_fp16 = transpose(perm = input_581_perm_0, x = x_285_cast_fp16)[name = tensor<string, []>("transpose_140")];
            tensor<fp16, [1, 17, 512]> input_583_cast_fp16 = add(x = input_567_cast_fp16, y = input_581_cast_fp16)[name = tensor<string, []>("input_583_cast_fp16")];
            tensor<int32, [1]> input_585_axes_0 = const()[name = tensor<string, []>("input_585_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_10_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(135414464)))];
            tensor<fp16, [512]> encoder_layers_10_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(135415552)))];
            tensor<fp16, [1, 17, 512]> input_585_cast_fp16 = layer_norm(axes = input_585_axes_0, beta = encoder_layers_10_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_10_norm_feed_forward2_weight_to_fp16, x = input_583_cast_fp16)[name = tensor<string, []>("input_585_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_10_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(135416640)))];
            tensor<fp16, [1, 17, 2048]> linear_98_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_10_feed_forward2_linear1_weight_to_fp16, x = input_585_cast_fp16)[name = tensor<string, []>("linear_98_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_589_cast_fp16 = silu(x = linear_98_cast_fp16)[name = tensor<string, []>("input_589_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_10_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(137513856)))];
            tensor<fp16, [1, 17, 512]> linear_99_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_10_feed_forward2_linear2_weight_to_fp16, x = input_589_cast_fp16)[name = tensor<string, []>("linear_99_cast_fp16")];
            tensor<fp16, []> var_2512_to_fp16 = const()[name = tensor<string, []>("op_2512_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2513_cast_fp16 = mul(x = linear_99_cast_fp16, y = var_2512_to_fp16)[name = tensor<string, []>("op_2513_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_595_cast_fp16 = add(x = input_583_cast_fp16, y = var_2513_cast_fp16)[name = tensor<string, []>("input_595_cast_fp16")];
            tensor<int32, [1]> input_597_axes_0 = const()[name = tensor<string, []>("input_597_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_10_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(139611072)))];
            tensor<fp16, [512]> encoder_layers_10_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_10_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(139612160)))];
            tensor<fp16, [1, 17, 512]> input_597_cast_fp16 = layer_norm(axes = input_597_axes_0, beta = encoder_layers_10_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_10_norm_out_weight_to_fp16, x = input_595_cast_fp16)[name = tensor<string, []>("input_597_cast_fp16")];
            tensor<int32, [4]> cache_45_begin_0 = const()[name = tensor<string, []>("cache_45_begin_0"), val = tensor<int32, [4]>([11, 0, 0, 0])];
            tensor<int32, [4]> cache_45_end_0 = const()[name = tensor<string, []>("cache_45_end_0"), val = tensor<int32, [4]>([12, 1, 70, 512])];
            tensor<bool, [4]> cache_45_end_mask_0 = const()[name = tensor<string, []>("cache_45_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_45_squeeze_mask_0 = const()[name = tensor<string, []>("cache_45_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_45_cast_fp16 = slice_by_index(begin = cache_45_begin_0, end = cache_45_end_0, end_mask = cache_45_end_mask_0, squeeze_mask = cache_45_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_45_cast_fp16")];
            tensor<int32, [4]> cache_47_begin_0 = const()[name = tensor<string, []>("cache_47_begin_0"), val = tensor<int32, [4]>([11, 0, 0, 0])];
            tensor<int32, [4]> cache_47_end_0 = const()[name = tensor<string, []>("cache_47_end_0"), val = tensor<int32, [4]>([12, 1, 512, 8])];
            tensor<bool, [4]> cache_47_end_mask_0 = const()[name = tensor<string, []>("cache_47_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_47_squeeze_mask_0 = const()[name = tensor<string, []>("cache_47_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_47_cast_fp16 = slice_by_index(begin = cache_47_begin_0, end = cache_47_end_0, end_mask = cache_47_end_mask_0, squeeze_mask = cache_47_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_47_cast_fp16")];
            tensor<int32, [1]> input_599_axes_0 = const()[name = tensor<string, []>("input_599_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_11_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(139613248)))];
            tensor<fp16, [512]> encoder_layers_11_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(139614336)))];
            tensor<fp16, [1, 17, 512]> input_599_cast_fp16 = layer_norm(axes = input_599_axes_0, beta = encoder_layers_11_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_11_norm_feed_forward1_weight_to_fp16, x = input_597_cast_fp16)[name = tensor<string, []>("input_599_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_11_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(139615424)))];
            tensor<fp16, [1, 17, 2048]> linear_100_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_11_feed_forward1_linear1_weight_to_fp16, x = input_599_cast_fp16)[name = tensor<string, []>("linear_100_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_603_cast_fp16 = silu(x = linear_100_cast_fp16)[name = tensor<string, []>("input_603_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_11_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(141712640)))];
            tensor<fp16, [1, 17, 512]> linear_101_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_11_feed_forward1_linear2_weight_to_fp16, x = input_603_cast_fp16)[name = tensor<string, []>("linear_101_cast_fp16")];
            tensor<fp16, []> var_2547_to_fp16 = const()[name = tensor<string, []>("op_2547_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2548_cast_fp16 = mul(x = linear_101_cast_fp16, y = var_2547_to_fp16)[name = tensor<string, []>("op_2548_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_609_cast_fp16 = add(x = input_597_cast_fp16, y = var_2548_cast_fp16)[name = tensor<string, []>("input_609_cast_fp16")];
            tensor<int32, [1]> key_23_axes_0 = const()[name = tensor<string, []>("key_23_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_11_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(143809856)))];
            tensor<fp16, [512]> encoder_layers_11_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(143810944)))];
            tensor<fp16, [1, 17, 512]> key_23_cast_fp16 = layer_norm(axes = key_23_axes_0, beta = encoder_layers_11_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_11_norm_self_att_weight_to_fp16, x = input_609_cast_fp16)[name = tensor<string, []>("key_23_cast_fp16")];
            tensor<bool, []> input_611_interleave_0 = const()[name = tensor<string, []>("input_611_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_611_cast_fp16 = concat(axis = var_64, interleave = input_611_interleave_0, values = (cache_45_cast_fp16, key_23_cast_fp16))[name = tensor<string, []>("input_611_cast_fp16")];
            tensor<int32, [3]> var_2570_begin_0 = const()[name = tensor<string, []>("op_2570_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_2570_end_0 = const()[name = tensor<string, []>("op_2570_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_2570_end_mask_0 = const()[name = tensor<string, []>("op_2570_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_2570_cast_fp16 = slice_by_index(begin = var_2570_begin_0, end = var_2570_end_0, end_mask = var_2570_end_mask_0, x = cache_45_cast_fp16)[name = tensor<string, []>("op_2570_cast_fp16")];
            tensor<bool, []> var_2576_interleave_0 = const()[name = tensor<string, []>("op_2576_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_2576_cast_fp16 = concat(axis = var_64, interleave = var_2576_interleave_0, values = (var_2570_cast_fp16, key_23_cast_fp16))[name = tensor<string, []>("op_2576_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_11_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(143812032)))];
            tensor<fp16, [1, 17, 512]> linear_102_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_11_self_attn_linear_q_weight_to_fp16, x = key_23_cast_fp16)[name = tensor<string, []>("linear_102_cast_fp16")];
            tensor<int32, [4]> var_2580 = const()[name = tensor<string, []>("op_2580"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_67_cast_fp16 = reshape(shape = var_2580, x = linear_102_cast_fp16)[name = tensor<string, []>("q_67_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_11_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144336384)))];
            tensor<fp16, [1, 87, 512]> linear_103_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_11_self_attn_linear_k_weight_to_fp16, x = input_611_cast_fp16)[name = tensor<string, []>("linear_103_cast_fp16")];
            tensor<int32, [4]> var_2584 = const()[name = tensor<string, []>("op_2584"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_45_cast_fp16 = reshape(shape = var_2584, x = linear_103_cast_fp16)[name = tensor<string, []>("k_45_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_11_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144860736)))];
            tensor<fp16, [1, 87, 512]> linear_104_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_11_self_attn_linear_v_weight_to_fp16, x = input_611_cast_fp16)[name = tensor<string, []>("linear_104_cast_fp16")];
            tensor<int32, [4]> var_2588 = const()[name = tensor<string, []>("op_2588"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_23_cast_fp16 = reshape(shape = var_2588, x = linear_104_cast_fp16)[name = tensor<string, []>("v_23_cast_fp16")];
            tensor<int32, [4]> value_25_perm_0 = const()[name = tensor<string, []>("value_25_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_11_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(145385088)))];
            tensor<fp16, [1, 17, 8, 64]> var_2600_cast_fp16 = add(x = q_67_cast_fp16, y = encoder_layers_11_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_2600_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_11_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(145386176)))];
            tensor<fp16, [1, 17, 8, 64]> var_2602_cast_fp16 = add(x = q_67_cast_fp16, y = encoder_layers_11_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_2602_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_23_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_23_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_293_transpose_x_0 = const()[name = tensor<string, []>("x_293_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_293_transpose_y_0 = const()[name = tensor<string, []>("x_293_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_2604_to_fp16 = const()[name = tensor<string, []>("op_2604_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(145387264)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_23_cast_fp16 = transpose(perm = q_with_bias_v_23_perm_0, x = var_2602_cast_fp16)[name = tensor<string, []>("transpose_138")];
            tensor<fp16, [1, 8, 17, 173]> x_293_cast_fp16 = matmul(transpose_x = x_293_transpose_x_0, transpose_y = x_293_transpose_y_0, x = q_with_bias_v_23_cast_fp16, y = var_2604_to_fp16)[name = tensor<string, []>("x_293_cast_fp16")];
            tensor<int32, [8]> x_295_pad_0 = const()[name = tensor<string, []>("x_295_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_295_mode_0 = const()[name = tensor<string, []>("x_295_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_166_to_fp16 = const()[name = tensor<string, []>("const_166_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_295_cast_fp16 = pad(constant_val = const_166_to_fp16, mode = x_295_mode_0, pad = x_295_pad_0, x = x_293_cast_fp16)[name = tensor<string, []>("x_295_cast_fp16")];
            tensor<int32, [4]> var_2612 = const()[name = tensor<string, []>("op_2612"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_297_cast_fp16 = reshape(shape = var_2612, x = x_295_cast_fp16)[name = tensor<string, []>("x_297_cast_fp16")];
            tensor<int32, [4]> var_2616_begin_0 = const()[name = tensor<string, []>("op_2616_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_2616_end_0 = const()[name = tensor<string, []>("op_2616_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_2616_end_mask_0 = const()[name = tensor<string, []>("op_2616_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_2616_cast_fp16 = slice_by_index(begin = var_2616_begin_0, end = var_2616_end_0, end_mask = var_2616_end_mask_0, x = x_297_cast_fp16)[name = tensor<string, []>("op_2616_cast_fp16")];
            tensor<int32, [4]> var_2617 = const()[name = tensor<string, []>("op_2617"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_45_cast_fp16 = reshape(shape = var_2617, x = var_2616_cast_fp16)[name = tensor<string, []>("matrix_bd_45_cast_fp16")];
            tensor<bool, []> matrix_ac_23_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_23_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_23_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_23_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_73_perm_0 = const()[name = tensor<string, []>("transpose_73_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_74_perm_0 = const()[name = tensor<string, []>("transpose_74_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_74 = transpose(perm = transpose_74_perm_0, x = k_45_cast_fp16)[name = tensor<string, []>("transpose_136")];
            tensor<fp16, [1, 8, 17, 64]> transpose_73 = transpose(perm = transpose_73_perm_0, x = var_2600_cast_fp16)[name = tensor<string, []>("transpose_137")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_23_cast_fp16 = matmul(transpose_x = matrix_ac_23_transpose_x_0, transpose_y = matrix_ac_23_transpose_y_0, x = transpose_73, y = transpose_74)[name = tensor<string, []>("matrix_ac_23_cast_fp16")];
            tensor<int32, [4]> matrix_bd_47_begin_0 = const()[name = tensor<string, []>("matrix_bd_47_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_47_end_0 = const()[name = tensor<string, []>("matrix_bd_47_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_47_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_47_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_47_cast_fp16 = slice_by_index(begin = matrix_bd_47_begin_0, end = matrix_bd_47_end_0, end_mask = matrix_bd_47_end_mask_0, x = matrix_bd_45_cast_fp16)[name = tensor<string, []>("matrix_bd_47_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2626_cast_fp16 = add(x = matrix_ac_23_cast_fp16, y = matrix_bd_47_cast_fp16)[name = tensor<string, []>("op_2626_cast_fp16")];
            tensor<fp16, []> _inversed_scores_45_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_45_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_45_cast_fp16 = mul(x = var_2626_cast_fp16, y = _inversed_scores_45_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_45_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_47_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_45_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_47_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2632_cast_fp16 = softmax(axis = var_62, x = scores_47_cast_fp16)[name = tensor<string, []>("op_2632_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_613_cast_fp16 = select(a = var_40_to_fp16, b = var_2632_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_613_cast_fp16")];
            tensor<bool, []> x_299_transpose_x_0 = const()[name = tensor<string, []>("x_299_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_299_transpose_y_0 = const()[name = tensor<string, []>("x_299_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_25_cast_fp16 = transpose(perm = value_25_perm_0, x = v_23_cast_fp16)[name = tensor<string, []>("transpose_139")];
            tensor<fp16, [1, 8, 17, 64]> x_299_cast_fp16 = matmul(transpose_x = x_299_transpose_x_0, transpose_y = x_299_transpose_y_0, x = input_613_cast_fp16, y = value_25_cast_fp16)[name = tensor<string, []>("x_299_cast_fp16")];
            tensor<int32, [4]> var_2636_perm_0 = const()[name = tensor<string, []>("op_2636_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_2637 = const()[name = tensor<string, []>("op_2637"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_2636_cast_fp16 = transpose(perm = var_2636_perm_0, x = x_299_cast_fp16)[name = tensor<string, []>("transpose_135")];
            tensor<fp16, [1, 17, 512]> input_615_cast_fp16 = reshape(shape = var_2637, x = var_2636_cast_fp16)[name = tensor<string, []>("input_615_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_11_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(145564480)))];
            tensor<fp16, [1, 17, 512]> linear_106_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_11_self_attn_linear_out_weight_to_fp16, x = input_615_cast_fp16)[name = tensor<string, []>("linear_106_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_619_cast_fp16 = add(x = input_609_cast_fp16, y = linear_106_cast_fp16)[name = tensor<string, []>("input_619_cast_fp16")];
            tensor<int32, [1]> x_303_axes_0 = const()[name = tensor<string, []>("x_303_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_11_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(146088832)))];
            tensor<fp16, [512]> encoder_layers_11_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(146089920)))];
            tensor<fp16, [1, 17, 512]> x_303_cast_fp16 = layer_norm(axes = x_303_axes_0, beta = encoder_layers_11_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_11_norm_conv_weight_to_fp16, x = input_619_cast_fp16)[name = tensor<string, []>("x_303_cast_fp16")];
            tensor<int32, [3]> input_621_perm_0 = const()[name = tensor<string, []>("input_621_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_623_pad_type_0 = const()[name = tensor<string, []>("input_623_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_623_strides_0 = const()[name = tensor<string, []>("input_623_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_623_pad_0 = const()[name = tensor<string, []>("input_623_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_623_dilations_0 = const()[name = tensor<string, []>("input_623_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_623_groups_0 = const()[name = tensor<string, []>("input_623_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_11_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(146091008)))];
            tensor<fp16, [1, 512, 17]> input_621_cast_fp16 = transpose(perm = input_621_perm_0, x = x_303_cast_fp16)[name = tensor<string, []>("transpose_134")];
            tensor<fp16, [1, 1024, 17]> input_623_cast_fp16 = conv(dilations = input_623_dilations_0, groups = input_623_groups_0, pad = input_623_pad_0, pad_type = input_623_pad_type_0, strides = input_623_strides_0, weight = encoder_layers_11_conv_pointwise_conv1_weight_to_fp16, x = input_621_cast_fp16)[name = tensor<string, []>("input_623_cast_fp16")];
            tensor<int32, []> x_305_split_num_splits_0 = const()[name = tensor<string, []>("x_305_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_305_split_axis_0 = const()[name = tensor<string, []>("x_305_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_305_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_305_split_cast_fp16_1 = split(axis = x_305_split_axis_0, num_splits = x_305_split_num_splits_0, x = input_623_cast_fp16)[name = tensor<string, []>("x_305_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_305_split_1_sigmoid_cast_fp16 = sigmoid(x = x_305_split_cast_fp16_1)[name = tensor<string, []>("x_305_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_305_cast_fp16 = mul(x = x_305_split_cast_fp16_0, y = x_305_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_305_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_625_cast_fp16 = select(a = var_40_to_fp16, b = x_305_cast_fp16, cond = var_418)[name = tensor<string, []>("input_625_cast_fp16")];
            tensor<bool, []> new_x_47_interleave_0 = const()[name = tensor<string, []>("new_x_47_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_47_cast_fp16 = concat(axis = var_62, interleave = new_x_47_interleave_0, values = (cache_47_cast_fp16, input_625_cast_fp16))[name = tensor<string, []>("new_x_47_cast_fp16")];
            tensor<int32, [3]> var_2675_begin_0 = const()[name = tensor<string, []>("op_2675_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_2675_end_0 = const()[name = tensor<string, []>("op_2675_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_2675_end_mask_0 = const()[name = tensor<string, []>("op_2675_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_2675_cast_fp16 = slice_by_index(begin = var_2675_begin_0, end = var_2675_end_0, end_mask = var_2675_end_mask_0, x = new_x_47_cast_fp16)[name = tensor<string, []>("op_2675_cast_fp16")];
            tensor<string, []> x_307_pad_type_0 = const()[name = tensor<string, []>("x_307_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_307_groups_0 = const()[name = tensor<string, []>("x_307_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_307_strides_0 = const()[name = tensor<string, []>("x_307_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_307_pad_0 = const()[name = tensor<string, []>("x_307_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_307_dilations_0 = const()[name = tensor<string, []>("x_307_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_11_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147139648)))];
            tensor<fp16, [1, 512, 17]> x_307_cast_fp16 = conv(dilations = x_307_dilations_0, groups = x_307_groups_0, pad = x_307_pad_0, pad_type = x_307_pad_type_0, strides = x_307_strides_0, weight = encoder_layers_11_conv_depthwise_conv_weight_to_fp16, x = new_x_47_cast_fp16)[name = tensor<string, []>("x_307_cast_fp16")];
            tensor<int32, [3]> input_627_perm_0 = const()[name = tensor<string, []>("input_627_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_309_axes_0 = const()[name = tensor<string, []>("x_309_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_11_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147148928)))];
            tensor<fp16, [512]> encoder_layers_11_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147150016)))];
            tensor<fp16, [1, 17, 512]> input_627_cast_fp16 = transpose(perm = input_627_perm_0, x = x_307_cast_fp16)[name = tensor<string, []>("transpose_133")];
            tensor<fp16, [1, 17, 512]> x_309_cast_fp16 = layer_norm(axes = x_309_axes_0, beta = encoder_layers_11_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_11_conv_batch_norm_weight_to_fp16, x = input_627_cast_fp16)[name = tensor<string, []>("x_309_cast_fp16")];
            tensor<int32, [3]> input_629_perm_0 = const()[name = tensor<string, []>("input_629_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_629_cast_fp16 = transpose(perm = input_629_perm_0, x = x_309_cast_fp16)[name = tensor<string, []>("transpose_132")];
            tensor<fp16, [1, 512, 17]> input_631_cast_fp16 = silu(x = input_629_cast_fp16)[name = tensor<string, []>("input_631_cast_fp16")];
            tensor<string, []> x_311_pad_type_0 = const()[name = tensor<string, []>("x_311_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_311_strides_0 = const()[name = tensor<string, []>("x_311_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_311_pad_0 = const()[name = tensor<string, []>("x_311_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_311_dilations_0 = const()[name = tensor<string, []>("x_311_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_311_groups_0 = const()[name = tensor<string, []>("x_311_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_11_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147151104)))];
            tensor<fp16, [1, 512, 17]> x_311_cast_fp16 = conv(dilations = x_311_dilations_0, groups = x_311_groups_0, pad = x_311_pad_0, pad_type = x_311_pad_type_0, strides = x_311_strides_0, weight = encoder_layers_11_conv_pointwise_conv2_weight_to_fp16, x = input_631_cast_fp16)[name = tensor<string, []>("x_311_cast_fp16")];
            tensor<int32, [3]> input_633_perm_0 = const()[name = tensor<string, []>("input_633_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_633_cast_fp16 = transpose(perm = input_633_perm_0, x = x_311_cast_fp16)[name = tensor<string, []>("transpose_131")];
            tensor<fp16, [1, 17, 512]> input_635_cast_fp16 = add(x = input_619_cast_fp16, y = input_633_cast_fp16)[name = tensor<string, []>("input_635_cast_fp16")];
            tensor<int32, [1]> input_637_axes_0 = const()[name = tensor<string, []>("input_637_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_11_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147675456)))];
            tensor<fp16, [512]> encoder_layers_11_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147676544)))];
            tensor<fp16, [1, 17, 512]> input_637_cast_fp16 = layer_norm(axes = input_637_axes_0, beta = encoder_layers_11_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_11_norm_feed_forward2_weight_to_fp16, x = input_635_cast_fp16)[name = tensor<string, []>("input_637_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_11_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147677632)))];
            tensor<fp16, [1, 17, 2048]> linear_107_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_11_feed_forward2_linear1_weight_to_fp16, x = input_637_cast_fp16)[name = tensor<string, []>("linear_107_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_641_cast_fp16 = silu(x = linear_107_cast_fp16)[name = tensor<string, []>("input_641_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_11_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(149774848)))];
            tensor<fp16, [1, 17, 512]> linear_108_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_11_feed_forward2_linear2_weight_to_fp16, x = input_641_cast_fp16)[name = tensor<string, []>("linear_108_cast_fp16")];
            tensor<fp16, []> var_2716_to_fp16 = const()[name = tensor<string, []>("op_2716_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2717_cast_fp16 = mul(x = linear_108_cast_fp16, y = var_2716_to_fp16)[name = tensor<string, []>("op_2717_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_647_cast_fp16 = add(x = input_635_cast_fp16, y = var_2717_cast_fp16)[name = tensor<string, []>("input_647_cast_fp16")];
            tensor<int32, [1]> input_649_axes_0 = const()[name = tensor<string, []>("input_649_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_11_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151872064)))];
            tensor<fp16, [512]> encoder_layers_11_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_11_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151873152)))];
            tensor<fp16, [1, 17, 512]> input_649_cast_fp16 = layer_norm(axes = input_649_axes_0, beta = encoder_layers_11_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_11_norm_out_weight_to_fp16, x = input_647_cast_fp16)[name = tensor<string, []>("input_649_cast_fp16")];
            tensor<int32, [4]> cache_49_begin_0 = const()[name = tensor<string, []>("cache_49_begin_0"), val = tensor<int32, [4]>([12, 0, 0, 0])];
            tensor<int32, [4]> cache_49_end_0 = const()[name = tensor<string, []>("cache_49_end_0"), val = tensor<int32, [4]>([13, 1, 70, 512])];
            tensor<bool, [4]> cache_49_end_mask_0 = const()[name = tensor<string, []>("cache_49_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_49_squeeze_mask_0 = const()[name = tensor<string, []>("cache_49_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_49_cast_fp16 = slice_by_index(begin = cache_49_begin_0, end = cache_49_end_0, end_mask = cache_49_end_mask_0, squeeze_mask = cache_49_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_49_cast_fp16")];
            tensor<int32, [4]> cache_51_begin_0 = const()[name = tensor<string, []>("cache_51_begin_0"), val = tensor<int32, [4]>([12, 0, 0, 0])];
            tensor<int32, [4]> cache_51_end_0 = const()[name = tensor<string, []>("cache_51_end_0"), val = tensor<int32, [4]>([13, 1, 512, 8])];
            tensor<bool, [4]> cache_51_end_mask_0 = const()[name = tensor<string, []>("cache_51_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_51_squeeze_mask_0 = const()[name = tensor<string, []>("cache_51_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_51_cast_fp16 = slice_by_index(begin = cache_51_begin_0, end = cache_51_end_0, end_mask = cache_51_end_mask_0, squeeze_mask = cache_51_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_51_cast_fp16")];
            tensor<int32, [1]> input_651_axes_0 = const()[name = tensor<string, []>("input_651_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_12_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151874240)))];
            tensor<fp16, [512]> encoder_layers_12_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151875328)))];
            tensor<fp16, [1, 17, 512]> input_651_cast_fp16 = layer_norm(axes = input_651_axes_0, beta = encoder_layers_12_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_12_norm_feed_forward1_weight_to_fp16, x = input_649_cast_fp16)[name = tensor<string, []>("input_651_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_12_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151876416)))];
            tensor<fp16, [1, 17, 2048]> linear_109_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_12_feed_forward1_linear1_weight_to_fp16, x = input_651_cast_fp16)[name = tensor<string, []>("linear_109_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_655_cast_fp16 = silu(x = linear_109_cast_fp16)[name = tensor<string, []>("input_655_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_12_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(153973632)))];
            tensor<fp16, [1, 17, 512]> linear_110_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_12_feed_forward1_linear2_weight_to_fp16, x = input_655_cast_fp16)[name = tensor<string, []>("linear_110_cast_fp16")];
            tensor<fp16, []> var_2751_to_fp16 = const()[name = tensor<string, []>("op_2751_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2752_cast_fp16 = mul(x = linear_110_cast_fp16, y = var_2751_to_fp16)[name = tensor<string, []>("op_2752_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_661_cast_fp16 = add(x = input_649_cast_fp16, y = var_2752_cast_fp16)[name = tensor<string, []>("input_661_cast_fp16")];
            tensor<int32, [1]> key_25_axes_0 = const()[name = tensor<string, []>("key_25_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_12_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(156070848)))];
            tensor<fp16, [512]> encoder_layers_12_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(156071936)))];
            tensor<fp16, [1, 17, 512]> key_25_cast_fp16 = layer_norm(axes = key_25_axes_0, beta = encoder_layers_12_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_12_norm_self_att_weight_to_fp16, x = input_661_cast_fp16)[name = tensor<string, []>("key_25_cast_fp16")];
            tensor<bool, []> input_663_interleave_0 = const()[name = tensor<string, []>("input_663_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_663_cast_fp16 = concat(axis = var_64, interleave = input_663_interleave_0, values = (cache_49_cast_fp16, key_25_cast_fp16))[name = tensor<string, []>("input_663_cast_fp16")];
            tensor<int32, [3]> var_2774_begin_0 = const()[name = tensor<string, []>("op_2774_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_2774_end_0 = const()[name = tensor<string, []>("op_2774_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_2774_end_mask_0 = const()[name = tensor<string, []>("op_2774_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_2774_cast_fp16 = slice_by_index(begin = var_2774_begin_0, end = var_2774_end_0, end_mask = var_2774_end_mask_0, x = cache_49_cast_fp16)[name = tensor<string, []>("op_2774_cast_fp16")];
            tensor<bool, []> var_2780_interleave_0 = const()[name = tensor<string, []>("op_2780_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_2780_cast_fp16 = concat(axis = var_64, interleave = var_2780_interleave_0, values = (var_2774_cast_fp16, key_25_cast_fp16))[name = tensor<string, []>("op_2780_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_12_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(156073024)))];
            tensor<fp16, [1, 17, 512]> linear_111_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_12_self_attn_linear_q_weight_to_fp16, x = key_25_cast_fp16)[name = tensor<string, []>("linear_111_cast_fp16")];
            tensor<int32, [4]> var_2784 = const()[name = tensor<string, []>("op_2784"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_73_cast_fp16 = reshape(shape = var_2784, x = linear_111_cast_fp16)[name = tensor<string, []>("q_73_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_12_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(156597376)))];
            tensor<fp16, [1, 87, 512]> linear_112_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_12_self_attn_linear_k_weight_to_fp16, x = input_663_cast_fp16)[name = tensor<string, []>("linear_112_cast_fp16")];
            tensor<int32, [4]> var_2788 = const()[name = tensor<string, []>("op_2788"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_49_cast_fp16 = reshape(shape = var_2788, x = linear_112_cast_fp16)[name = tensor<string, []>("k_49_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_12_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157121728)))];
            tensor<fp16, [1, 87, 512]> linear_113_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_12_self_attn_linear_v_weight_to_fp16, x = input_663_cast_fp16)[name = tensor<string, []>("linear_113_cast_fp16")];
            tensor<int32, [4]> var_2792 = const()[name = tensor<string, []>("op_2792"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_25_cast_fp16 = reshape(shape = var_2792, x = linear_113_cast_fp16)[name = tensor<string, []>("v_25_cast_fp16")];
            tensor<int32, [4]> value_27_perm_0 = const()[name = tensor<string, []>("value_27_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_12_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157646080)))];
            tensor<fp16, [1, 17, 8, 64]> var_2804_cast_fp16 = add(x = q_73_cast_fp16, y = encoder_layers_12_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_2804_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_12_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157647168)))];
            tensor<fp16, [1, 17, 8, 64]> var_2806_cast_fp16 = add(x = q_73_cast_fp16, y = encoder_layers_12_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_2806_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_25_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_25_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_319_transpose_x_0 = const()[name = tensor<string, []>("x_319_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_319_transpose_y_0 = const()[name = tensor<string, []>("x_319_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_2808_to_fp16 = const()[name = tensor<string, []>("op_2808_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157648256)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_25_cast_fp16 = transpose(perm = q_with_bias_v_25_perm_0, x = var_2806_cast_fp16)[name = tensor<string, []>("transpose_129")];
            tensor<fp16, [1, 8, 17, 173]> x_319_cast_fp16 = matmul(transpose_x = x_319_transpose_x_0, transpose_y = x_319_transpose_y_0, x = q_with_bias_v_25_cast_fp16, y = var_2808_to_fp16)[name = tensor<string, []>("x_319_cast_fp16")];
            tensor<int32, [8]> x_321_pad_0 = const()[name = tensor<string, []>("x_321_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_321_mode_0 = const()[name = tensor<string, []>("x_321_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_179_to_fp16 = const()[name = tensor<string, []>("const_179_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_321_cast_fp16 = pad(constant_val = const_179_to_fp16, mode = x_321_mode_0, pad = x_321_pad_0, x = x_319_cast_fp16)[name = tensor<string, []>("x_321_cast_fp16")];
            tensor<int32, [4]> var_2816 = const()[name = tensor<string, []>("op_2816"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_323_cast_fp16 = reshape(shape = var_2816, x = x_321_cast_fp16)[name = tensor<string, []>("x_323_cast_fp16")];
            tensor<int32, [4]> var_2820_begin_0 = const()[name = tensor<string, []>("op_2820_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_2820_end_0 = const()[name = tensor<string, []>("op_2820_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_2820_end_mask_0 = const()[name = tensor<string, []>("op_2820_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_2820_cast_fp16 = slice_by_index(begin = var_2820_begin_0, end = var_2820_end_0, end_mask = var_2820_end_mask_0, x = x_323_cast_fp16)[name = tensor<string, []>("op_2820_cast_fp16")];
            tensor<int32, [4]> var_2821 = const()[name = tensor<string, []>("op_2821"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_49_cast_fp16 = reshape(shape = var_2821, x = var_2820_cast_fp16)[name = tensor<string, []>("matrix_bd_49_cast_fp16")];
            tensor<bool, []> matrix_ac_25_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_25_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_25_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_25_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_75_perm_0 = const()[name = tensor<string, []>("transpose_75_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_76_perm_0 = const()[name = tensor<string, []>("transpose_76_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_76 = transpose(perm = transpose_76_perm_0, x = k_49_cast_fp16)[name = tensor<string, []>("transpose_127")];
            tensor<fp16, [1, 8, 17, 64]> transpose_75 = transpose(perm = transpose_75_perm_0, x = var_2804_cast_fp16)[name = tensor<string, []>("transpose_128")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_25_cast_fp16 = matmul(transpose_x = matrix_ac_25_transpose_x_0, transpose_y = matrix_ac_25_transpose_y_0, x = transpose_75, y = transpose_76)[name = tensor<string, []>("matrix_ac_25_cast_fp16")];
            tensor<int32, [4]> matrix_bd_51_begin_0 = const()[name = tensor<string, []>("matrix_bd_51_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_51_end_0 = const()[name = tensor<string, []>("matrix_bd_51_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_51_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_51_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_51_cast_fp16 = slice_by_index(begin = matrix_bd_51_begin_0, end = matrix_bd_51_end_0, end_mask = matrix_bd_51_end_mask_0, x = matrix_bd_49_cast_fp16)[name = tensor<string, []>("matrix_bd_51_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2830_cast_fp16 = add(x = matrix_ac_25_cast_fp16, y = matrix_bd_51_cast_fp16)[name = tensor<string, []>("op_2830_cast_fp16")];
            tensor<fp16, []> _inversed_scores_49_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_49_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_49_cast_fp16 = mul(x = var_2830_cast_fp16, y = _inversed_scores_49_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_49_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_51_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_49_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_51_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_2836_cast_fp16 = softmax(axis = var_62, x = scores_51_cast_fp16)[name = tensor<string, []>("op_2836_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_665_cast_fp16 = select(a = var_40_to_fp16, b = var_2836_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_665_cast_fp16")];
            tensor<bool, []> x_325_transpose_x_0 = const()[name = tensor<string, []>("x_325_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_325_transpose_y_0 = const()[name = tensor<string, []>("x_325_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_27_cast_fp16 = transpose(perm = value_27_perm_0, x = v_25_cast_fp16)[name = tensor<string, []>("transpose_130")];
            tensor<fp16, [1, 8, 17, 64]> x_325_cast_fp16 = matmul(transpose_x = x_325_transpose_x_0, transpose_y = x_325_transpose_y_0, x = input_665_cast_fp16, y = value_27_cast_fp16)[name = tensor<string, []>("x_325_cast_fp16")];
            tensor<int32, [4]> var_2840_perm_0 = const()[name = tensor<string, []>("op_2840_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_2841 = const()[name = tensor<string, []>("op_2841"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_2840_cast_fp16 = transpose(perm = var_2840_perm_0, x = x_325_cast_fp16)[name = tensor<string, []>("transpose_126")];
            tensor<fp16, [1, 17, 512]> input_667_cast_fp16 = reshape(shape = var_2841, x = var_2840_cast_fp16)[name = tensor<string, []>("input_667_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_12_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157825472)))];
            tensor<fp16, [1, 17, 512]> linear_115_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_12_self_attn_linear_out_weight_to_fp16, x = input_667_cast_fp16)[name = tensor<string, []>("linear_115_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_671_cast_fp16 = add(x = input_661_cast_fp16, y = linear_115_cast_fp16)[name = tensor<string, []>("input_671_cast_fp16")];
            tensor<int32, [1]> x_329_axes_0 = const()[name = tensor<string, []>("x_329_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_12_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158349824)))];
            tensor<fp16, [512]> encoder_layers_12_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158350912)))];
            tensor<fp16, [1, 17, 512]> x_329_cast_fp16 = layer_norm(axes = x_329_axes_0, beta = encoder_layers_12_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_12_norm_conv_weight_to_fp16, x = input_671_cast_fp16)[name = tensor<string, []>("x_329_cast_fp16")];
            tensor<int32, [3]> input_673_perm_0 = const()[name = tensor<string, []>("input_673_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_675_pad_type_0 = const()[name = tensor<string, []>("input_675_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_675_strides_0 = const()[name = tensor<string, []>("input_675_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_675_pad_0 = const()[name = tensor<string, []>("input_675_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_675_dilations_0 = const()[name = tensor<string, []>("input_675_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_675_groups_0 = const()[name = tensor<string, []>("input_675_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_12_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158352000)))];
            tensor<fp16, [1, 512, 17]> input_673_cast_fp16 = transpose(perm = input_673_perm_0, x = x_329_cast_fp16)[name = tensor<string, []>("transpose_125")];
            tensor<fp16, [1, 1024, 17]> input_675_cast_fp16 = conv(dilations = input_675_dilations_0, groups = input_675_groups_0, pad = input_675_pad_0, pad_type = input_675_pad_type_0, strides = input_675_strides_0, weight = encoder_layers_12_conv_pointwise_conv1_weight_to_fp16, x = input_673_cast_fp16)[name = tensor<string, []>("input_675_cast_fp16")];
            tensor<int32, []> x_331_split_num_splits_0 = const()[name = tensor<string, []>("x_331_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_331_split_axis_0 = const()[name = tensor<string, []>("x_331_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_331_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_331_split_cast_fp16_1 = split(axis = x_331_split_axis_0, num_splits = x_331_split_num_splits_0, x = input_675_cast_fp16)[name = tensor<string, []>("x_331_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_331_split_1_sigmoid_cast_fp16 = sigmoid(x = x_331_split_cast_fp16_1)[name = tensor<string, []>("x_331_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_331_cast_fp16 = mul(x = x_331_split_cast_fp16_0, y = x_331_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_331_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_677_cast_fp16 = select(a = var_40_to_fp16, b = x_331_cast_fp16, cond = var_418)[name = tensor<string, []>("input_677_cast_fp16")];
            tensor<bool, []> new_x_51_interleave_0 = const()[name = tensor<string, []>("new_x_51_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_51_cast_fp16 = concat(axis = var_62, interleave = new_x_51_interleave_0, values = (cache_51_cast_fp16, input_677_cast_fp16))[name = tensor<string, []>("new_x_51_cast_fp16")];
            tensor<int32, [3]> var_2879_begin_0 = const()[name = tensor<string, []>("op_2879_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_2879_end_0 = const()[name = tensor<string, []>("op_2879_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_2879_end_mask_0 = const()[name = tensor<string, []>("op_2879_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_2879_cast_fp16 = slice_by_index(begin = var_2879_begin_0, end = var_2879_end_0, end_mask = var_2879_end_mask_0, x = new_x_51_cast_fp16)[name = tensor<string, []>("op_2879_cast_fp16")];
            tensor<string, []> x_333_pad_type_0 = const()[name = tensor<string, []>("x_333_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_333_groups_0 = const()[name = tensor<string, []>("x_333_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_333_strides_0 = const()[name = tensor<string, []>("x_333_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_333_pad_0 = const()[name = tensor<string, []>("x_333_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_333_dilations_0 = const()[name = tensor<string, []>("x_333_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_12_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(159400640)))];
            tensor<fp16, [1, 512, 17]> x_333_cast_fp16 = conv(dilations = x_333_dilations_0, groups = x_333_groups_0, pad = x_333_pad_0, pad_type = x_333_pad_type_0, strides = x_333_strides_0, weight = encoder_layers_12_conv_depthwise_conv_weight_to_fp16, x = new_x_51_cast_fp16)[name = tensor<string, []>("x_333_cast_fp16")];
            tensor<int32, [3]> input_679_perm_0 = const()[name = tensor<string, []>("input_679_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_335_axes_0 = const()[name = tensor<string, []>("x_335_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_12_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(159409920)))];
            tensor<fp16, [512]> encoder_layers_12_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(159411008)))];
            tensor<fp16, [1, 17, 512]> input_679_cast_fp16 = transpose(perm = input_679_perm_0, x = x_333_cast_fp16)[name = tensor<string, []>("transpose_124")];
            tensor<fp16, [1, 17, 512]> x_335_cast_fp16 = layer_norm(axes = x_335_axes_0, beta = encoder_layers_12_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_12_conv_batch_norm_weight_to_fp16, x = input_679_cast_fp16)[name = tensor<string, []>("x_335_cast_fp16")];
            tensor<int32, [3]> input_681_perm_0 = const()[name = tensor<string, []>("input_681_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_681_cast_fp16 = transpose(perm = input_681_perm_0, x = x_335_cast_fp16)[name = tensor<string, []>("transpose_123")];
            tensor<fp16, [1, 512, 17]> input_683_cast_fp16 = silu(x = input_681_cast_fp16)[name = tensor<string, []>("input_683_cast_fp16")];
            tensor<string, []> x_337_pad_type_0 = const()[name = tensor<string, []>("x_337_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_337_strides_0 = const()[name = tensor<string, []>("x_337_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_337_pad_0 = const()[name = tensor<string, []>("x_337_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_337_dilations_0 = const()[name = tensor<string, []>("x_337_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_337_groups_0 = const()[name = tensor<string, []>("x_337_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_12_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(159412096)))];
            tensor<fp16, [1, 512, 17]> x_337_cast_fp16 = conv(dilations = x_337_dilations_0, groups = x_337_groups_0, pad = x_337_pad_0, pad_type = x_337_pad_type_0, strides = x_337_strides_0, weight = encoder_layers_12_conv_pointwise_conv2_weight_to_fp16, x = input_683_cast_fp16)[name = tensor<string, []>("x_337_cast_fp16")];
            tensor<int32, [3]> input_685_perm_0 = const()[name = tensor<string, []>("input_685_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_685_cast_fp16 = transpose(perm = input_685_perm_0, x = x_337_cast_fp16)[name = tensor<string, []>("transpose_122")];
            tensor<fp16, [1, 17, 512]> input_687_cast_fp16 = add(x = input_671_cast_fp16, y = input_685_cast_fp16)[name = tensor<string, []>("input_687_cast_fp16")];
            tensor<int32, [1]> input_689_axes_0 = const()[name = tensor<string, []>("input_689_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_12_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(159936448)))];
            tensor<fp16, [512]> encoder_layers_12_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(159937536)))];
            tensor<fp16, [1, 17, 512]> input_689_cast_fp16 = layer_norm(axes = input_689_axes_0, beta = encoder_layers_12_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_12_norm_feed_forward2_weight_to_fp16, x = input_687_cast_fp16)[name = tensor<string, []>("input_689_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_12_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(159938624)))];
            tensor<fp16, [1, 17, 2048]> linear_116_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_12_feed_forward2_linear1_weight_to_fp16, x = input_689_cast_fp16)[name = tensor<string, []>("linear_116_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_693_cast_fp16 = silu(x = linear_116_cast_fp16)[name = tensor<string, []>("input_693_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_12_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162035840)))];
            tensor<fp16, [1, 17, 512]> linear_117_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_12_feed_forward2_linear2_weight_to_fp16, x = input_693_cast_fp16)[name = tensor<string, []>("linear_117_cast_fp16")];
            tensor<fp16, []> var_2920_to_fp16 = const()[name = tensor<string, []>("op_2920_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2921_cast_fp16 = mul(x = linear_117_cast_fp16, y = var_2920_to_fp16)[name = tensor<string, []>("op_2921_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_699_cast_fp16 = add(x = input_687_cast_fp16, y = var_2921_cast_fp16)[name = tensor<string, []>("input_699_cast_fp16")];
            tensor<int32, [1]> input_701_axes_0 = const()[name = tensor<string, []>("input_701_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_12_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(164133056)))];
            tensor<fp16, [512]> encoder_layers_12_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_12_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(164134144)))];
            tensor<fp16, [1, 17, 512]> input_701_cast_fp16 = layer_norm(axes = input_701_axes_0, beta = encoder_layers_12_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_12_norm_out_weight_to_fp16, x = input_699_cast_fp16)[name = tensor<string, []>("input_701_cast_fp16")];
            tensor<int32, [4]> cache_53_begin_0 = const()[name = tensor<string, []>("cache_53_begin_0"), val = tensor<int32, [4]>([13, 0, 0, 0])];
            tensor<int32, [4]> cache_53_end_0 = const()[name = tensor<string, []>("cache_53_end_0"), val = tensor<int32, [4]>([14, 1, 70, 512])];
            tensor<bool, [4]> cache_53_end_mask_0 = const()[name = tensor<string, []>("cache_53_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_53_squeeze_mask_0 = const()[name = tensor<string, []>("cache_53_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_53_cast_fp16 = slice_by_index(begin = cache_53_begin_0, end = cache_53_end_0, end_mask = cache_53_end_mask_0, squeeze_mask = cache_53_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_53_cast_fp16")];
            tensor<int32, [4]> cache_55_begin_0 = const()[name = tensor<string, []>("cache_55_begin_0"), val = tensor<int32, [4]>([13, 0, 0, 0])];
            tensor<int32, [4]> cache_55_end_0 = const()[name = tensor<string, []>("cache_55_end_0"), val = tensor<int32, [4]>([14, 1, 512, 8])];
            tensor<bool, [4]> cache_55_end_mask_0 = const()[name = tensor<string, []>("cache_55_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_55_squeeze_mask_0 = const()[name = tensor<string, []>("cache_55_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_55_cast_fp16 = slice_by_index(begin = cache_55_begin_0, end = cache_55_end_0, end_mask = cache_55_end_mask_0, squeeze_mask = cache_55_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_55_cast_fp16")];
            tensor<int32, [1]> input_703_axes_0 = const()[name = tensor<string, []>("input_703_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_13_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(164135232)))];
            tensor<fp16, [512]> encoder_layers_13_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(164136320)))];
            tensor<fp16, [1, 17, 512]> input_703_cast_fp16 = layer_norm(axes = input_703_axes_0, beta = encoder_layers_13_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_13_norm_feed_forward1_weight_to_fp16, x = input_701_cast_fp16)[name = tensor<string, []>("input_703_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_13_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(164137408)))];
            tensor<fp16, [1, 17, 2048]> linear_118_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_13_feed_forward1_linear1_weight_to_fp16, x = input_703_cast_fp16)[name = tensor<string, []>("linear_118_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_707_cast_fp16 = silu(x = linear_118_cast_fp16)[name = tensor<string, []>("input_707_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_13_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166234624)))];
            tensor<fp16, [1, 17, 512]> linear_119_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_13_feed_forward1_linear2_weight_to_fp16, x = input_707_cast_fp16)[name = tensor<string, []>("linear_119_cast_fp16")];
            tensor<fp16, []> var_2955_to_fp16 = const()[name = tensor<string, []>("op_2955_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_2956_cast_fp16 = mul(x = linear_119_cast_fp16, y = var_2955_to_fp16)[name = tensor<string, []>("op_2956_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_713_cast_fp16 = add(x = input_701_cast_fp16, y = var_2956_cast_fp16)[name = tensor<string, []>("input_713_cast_fp16")];
            tensor<int32, [1]> key_27_axes_0 = const()[name = tensor<string, []>("key_27_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_13_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168331840)))];
            tensor<fp16, [512]> encoder_layers_13_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168332928)))];
            tensor<fp16, [1, 17, 512]> key_27_cast_fp16 = layer_norm(axes = key_27_axes_0, beta = encoder_layers_13_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_13_norm_self_att_weight_to_fp16, x = input_713_cast_fp16)[name = tensor<string, []>("key_27_cast_fp16")];
            tensor<bool, []> input_715_interleave_0 = const()[name = tensor<string, []>("input_715_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_715_cast_fp16 = concat(axis = var_64, interleave = input_715_interleave_0, values = (cache_53_cast_fp16, key_27_cast_fp16))[name = tensor<string, []>("input_715_cast_fp16")];
            tensor<int32, [3]> var_2978_begin_0 = const()[name = tensor<string, []>("op_2978_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_2978_end_0 = const()[name = tensor<string, []>("op_2978_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_2978_end_mask_0 = const()[name = tensor<string, []>("op_2978_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_2978_cast_fp16 = slice_by_index(begin = var_2978_begin_0, end = var_2978_end_0, end_mask = var_2978_end_mask_0, x = cache_53_cast_fp16)[name = tensor<string, []>("op_2978_cast_fp16")];
            tensor<bool, []> var_2984_interleave_0 = const()[name = tensor<string, []>("op_2984_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_2984_cast_fp16 = concat(axis = var_64, interleave = var_2984_interleave_0, values = (var_2978_cast_fp16, key_27_cast_fp16))[name = tensor<string, []>("op_2984_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_13_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168334016)))];
            tensor<fp16, [1, 17, 512]> linear_120_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_13_self_attn_linear_q_weight_to_fp16, x = key_27_cast_fp16)[name = tensor<string, []>("linear_120_cast_fp16")];
            tensor<int32, [4]> var_2988 = const()[name = tensor<string, []>("op_2988"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_79_cast_fp16 = reshape(shape = var_2988, x = linear_120_cast_fp16)[name = tensor<string, []>("q_79_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_13_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168858368)))];
            tensor<fp16, [1, 87, 512]> linear_121_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_13_self_attn_linear_k_weight_to_fp16, x = input_715_cast_fp16)[name = tensor<string, []>("linear_121_cast_fp16")];
            tensor<int32, [4]> var_2992 = const()[name = tensor<string, []>("op_2992"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_53_cast_fp16 = reshape(shape = var_2992, x = linear_121_cast_fp16)[name = tensor<string, []>("k_53_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_13_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169382720)))];
            tensor<fp16, [1, 87, 512]> linear_122_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_13_self_attn_linear_v_weight_to_fp16, x = input_715_cast_fp16)[name = tensor<string, []>("linear_122_cast_fp16")];
            tensor<int32, [4]> var_2996 = const()[name = tensor<string, []>("op_2996"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_27_cast_fp16 = reshape(shape = var_2996, x = linear_122_cast_fp16)[name = tensor<string, []>("v_27_cast_fp16")];
            tensor<int32, [4]> value_29_perm_0 = const()[name = tensor<string, []>("value_29_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_13_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169907072)))];
            tensor<fp16, [1, 17, 8, 64]> var_3008_cast_fp16 = add(x = q_79_cast_fp16, y = encoder_layers_13_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_3008_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_13_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169908160)))];
            tensor<fp16, [1, 17, 8, 64]> var_3010_cast_fp16 = add(x = q_79_cast_fp16, y = encoder_layers_13_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_3010_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_27_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_27_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_345_transpose_x_0 = const()[name = tensor<string, []>("x_345_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_345_transpose_y_0 = const()[name = tensor<string, []>("x_345_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_3012_to_fp16 = const()[name = tensor<string, []>("op_3012_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169909248)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_27_cast_fp16 = transpose(perm = q_with_bias_v_27_perm_0, x = var_3010_cast_fp16)[name = tensor<string, []>("transpose_120")];
            tensor<fp16, [1, 8, 17, 173]> x_345_cast_fp16 = matmul(transpose_x = x_345_transpose_x_0, transpose_y = x_345_transpose_y_0, x = q_with_bias_v_27_cast_fp16, y = var_3012_to_fp16)[name = tensor<string, []>("x_345_cast_fp16")];
            tensor<int32, [8]> x_347_pad_0 = const()[name = tensor<string, []>("x_347_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_347_mode_0 = const()[name = tensor<string, []>("x_347_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_192_to_fp16 = const()[name = tensor<string, []>("const_192_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_347_cast_fp16 = pad(constant_val = const_192_to_fp16, mode = x_347_mode_0, pad = x_347_pad_0, x = x_345_cast_fp16)[name = tensor<string, []>("x_347_cast_fp16")];
            tensor<int32, [4]> var_3020 = const()[name = tensor<string, []>("op_3020"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_349_cast_fp16 = reshape(shape = var_3020, x = x_347_cast_fp16)[name = tensor<string, []>("x_349_cast_fp16")];
            tensor<int32, [4]> var_3024_begin_0 = const()[name = tensor<string, []>("op_3024_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_3024_end_0 = const()[name = tensor<string, []>("op_3024_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_3024_end_mask_0 = const()[name = tensor<string, []>("op_3024_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_3024_cast_fp16 = slice_by_index(begin = var_3024_begin_0, end = var_3024_end_0, end_mask = var_3024_end_mask_0, x = x_349_cast_fp16)[name = tensor<string, []>("op_3024_cast_fp16")];
            tensor<int32, [4]> var_3025 = const()[name = tensor<string, []>("op_3025"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_53_cast_fp16 = reshape(shape = var_3025, x = var_3024_cast_fp16)[name = tensor<string, []>("matrix_bd_53_cast_fp16")];
            tensor<bool, []> matrix_ac_27_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_27_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_27_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_27_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_77_perm_0 = const()[name = tensor<string, []>("transpose_77_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_78_perm_0 = const()[name = tensor<string, []>("transpose_78_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_78 = transpose(perm = transpose_78_perm_0, x = k_53_cast_fp16)[name = tensor<string, []>("transpose_118")];
            tensor<fp16, [1, 8, 17, 64]> transpose_77 = transpose(perm = transpose_77_perm_0, x = var_3008_cast_fp16)[name = tensor<string, []>("transpose_119")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_27_cast_fp16 = matmul(transpose_x = matrix_ac_27_transpose_x_0, transpose_y = matrix_ac_27_transpose_y_0, x = transpose_77, y = transpose_78)[name = tensor<string, []>("matrix_ac_27_cast_fp16")];
            tensor<int32, [4]> matrix_bd_55_begin_0 = const()[name = tensor<string, []>("matrix_bd_55_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_55_end_0 = const()[name = tensor<string, []>("matrix_bd_55_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_55_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_55_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_55_cast_fp16 = slice_by_index(begin = matrix_bd_55_begin_0, end = matrix_bd_55_end_0, end_mask = matrix_bd_55_end_mask_0, x = matrix_bd_53_cast_fp16)[name = tensor<string, []>("matrix_bd_55_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_3034_cast_fp16 = add(x = matrix_ac_27_cast_fp16, y = matrix_bd_55_cast_fp16)[name = tensor<string, []>("op_3034_cast_fp16")];
            tensor<fp16, []> _inversed_scores_53_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_53_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_53_cast_fp16 = mul(x = var_3034_cast_fp16, y = _inversed_scores_53_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_53_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_55_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_53_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_55_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_3040_cast_fp16 = softmax(axis = var_62, x = scores_55_cast_fp16)[name = tensor<string, []>("op_3040_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_717_cast_fp16 = select(a = var_40_to_fp16, b = var_3040_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_717_cast_fp16")];
            tensor<bool, []> x_351_transpose_x_0 = const()[name = tensor<string, []>("x_351_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_351_transpose_y_0 = const()[name = tensor<string, []>("x_351_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_29_cast_fp16 = transpose(perm = value_29_perm_0, x = v_27_cast_fp16)[name = tensor<string, []>("transpose_121")];
            tensor<fp16, [1, 8, 17, 64]> x_351_cast_fp16 = matmul(transpose_x = x_351_transpose_x_0, transpose_y = x_351_transpose_y_0, x = input_717_cast_fp16, y = value_29_cast_fp16)[name = tensor<string, []>("x_351_cast_fp16")];
            tensor<int32, [4]> var_3044_perm_0 = const()[name = tensor<string, []>("op_3044_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_3045 = const()[name = tensor<string, []>("op_3045"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_3044_cast_fp16 = transpose(perm = var_3044_perm_0, x = x_351_cast_fp16)[name = tensor<string, []>("transpose_117")];
            tensor<fp16, [1, 17, 512]> input_719_cast_fp16 = reshape(shape = var_3045, x = var_3044_cast_fp16)[name = tensor<string, []>("input_719_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_13_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(170086464)))];
            tensor<fp16, [1, 17, 512]> linear_124_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_13_self_attn_linear_out_weight_to_fp16, x = input_719_cast_fp16)[name = tensor<string, []>("linear_124_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_723_cast_fp16 = add(x = input_713_cast_fp16, y = linear_124_cast_fp16)[name = tensor<string, []>("input_723_cast_fp16")];
            tensor<int32, [1]> x_355_axes_0 = const()[name = tensor<string, []>("x_355_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_13_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(170610816)))];
            tensor<fp16, [512]> encoder_layers_13_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(170611904)))];
            tensor<fp16, [1, 17, 512]> x_355_cast_fp16 = layer_norm(axes = x_355_axes_0, beta = encoder_layers_13_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_13_norm_conv_weight_to_fp16, x = input_723_cast_fp16)[name = tensor<string, []>("x_355_cast_fp16")];
            tensor<int32, [3]> input_725_perm_0 = const()[name = tensor<string, []>("input_725_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_727_pad_type_0 = const()[name = tensor<string, []>("input_727_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_727_strides_0 = const()[name = tensor<string, []>("input_727_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_727_pad_0 = const()[name = tensor<string, []>("input_727_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_727_dilations_0 = const()[name = tensor<string, []>("input_727_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_727_groups_0 = const()[name = tensor<string, []>("input_727_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_13_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(170612992)))];
            tensor<fp16, [1, 512, 17]> input_725_cast_fp16 = transpose(perm = input_725_perm_0, x = x_355_cast_fp16)[name = tensor<string, []>("transpose_116")];
            tensor<fp16, [1, 1024, 17]> input_727_cast_fp16 = conv(dilations = input_727_dilations_0, groups = input_727_groups_0, pad = input_727_pad_0, pad_type = input_727_pad_type_0, strides = input_727_strides_0, weight = encoder_layers_13_conv_pointwise_conv1_weight_to_fp16, x = input_725_cast_fp16)[name = tensor<string, []>("input_727_cast_fp16")];
            tensor<int32, []> x_357_split_num_splits_0 = const()[name = tensor<string, []>("x_357_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_357_split_axis_0 = const()[name = tensor<string, []>("x_357_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_357_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_357_split_cast_fp16_1 = split(axis = x_357_split_axis_0, num_splits = x_357_split_num_splits_0, x = input_727_cast_fp16)[name = tensor<string, []>("x_357_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_357_split_1_sigmoid_cast_fp16 = sigmoid(x = x_357_split_cast_fp16_1)[name = tensor<string, []>("x_357_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_357_cast_fp16 = mul(x = x_357_split_cast_fp16_0, y = x_357_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_357_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_729_cast_fp16 = select(a = var_40_to_fp16, b = x_357_cast_fp16, cond = var_418)[name = tensor<string, []>("input_729_cast_fp16")];
            tensor<bool, []> new_x_55_interleave_0 = const()[name = tensor<string, []>("new_x_55_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_55_cast_fp16 = concat(axis = var_62, interleave = new_x_55_interleave_0, values = (cache_55_cast_fp16, input_729_cast_fp16))[name = tensor<string, []>("new_x_55_cast_fp16")];
            tensor<int32, [3]> var_3083_begin_0 = const()[name = tensor<string, []>("op_3083_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_3083_end_0 = const()[name = tensor<string, []>("op_3083_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_3083_end_mask_0 = const()[name = tensor<string, []>("op_3083_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_3083_cast_fp16 = slice_by_index(begin = var_3083_begin_0, end = var_3083_end_0, end_mask = var_3083_end_mask_0, x = new_x_55_cast_fp16)[name = tensor<string, []>("op_3083_cast_fp16")];
            tensor<string, []> x_359_pad_type_0 = const()[name = tensor<string, []>("x_359_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_359_groups_0 = const()[name = tensor<string, []>("x_359_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_359_strides_0 = const()[name = tensor<string, []>("x_359_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_359_pad_0 = const()[name = tensor<string, []>("x_359_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_359_dilations_0 = const()[name = tensor<string, []>("x_359_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_13_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(171661632)))];
            tensor<fp16, [1, 512, 17]> x_359_cast_fp16 = conv(dilations = x_359_dilations_0, groups = x_359_groups_0, pad = x_359_pad_0, pad_type = x_359_pad_type_0, strides = x_359_strides_0, weight = encoder_layers_13_conv_depthwise_conv_weight_to_fp16, x = new_x_55_cast_fp16)[name = tensor<string, []>("x_359_cast_fp16")];
            tensor<int32, [3]> input_731_perm_0 = const()[name = tensor<string, []>("input_731_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_361_axes_0 = const()[name = tensor<string, []>("x_361_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_13_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(171670912)))];
            tensor<fp16, [512]> encoder_layers_13_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(171672000)))];
            tensor<fp16, [1, 17, 512]> input_731_cast_fp16 = transpose(perm = input_731_perm_0, x = x_359_cast_fp16)[name = tensor<string, []>("transpose_115")];
            tensor<fp16, [1, 17, 512]> x_361_cast_fp16 = layer_norm(axes = x_361_axes_0, beta = encoder_layers_13_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_13_conv_batch_norm_weight_to_fp16, x = input_731_cast_fp16)[name = tensor<string, []>("x_361_cast_fp16")];
            tensor<int32, [3]> input_733_perm_0 = const()[name = tensor<string, []>("input_733_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_733_cast_fp16 = transpose(perm = input_733_perm_0, x = x_361_cast_fp16)[name = tensor<string, []>("transpose_114")];
            tensor<fp16, [1, 512, 17]> input_735_cast_fp16 = silu(x = input_733_cast_fp16)[name = tensor<string, []>("input_735_cast_fp16")];
            tensor<string, []> x_363_pad_type_0 = const()[name = tensor<string, []>("x_363_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_363_strides_0 = const()[name = tensor<string, []>("x_363_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_363_pad_0 = const()[name = tensor<string, []>("x_363_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_363_dilations_0 = const()[name = tensor<string, []>("x_363_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_363_groups_0 = const()[name = tensor<string, []>("x_363_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_13_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(171673088)))];
            tensor<fp16, [1, 512, 17]> x_363_cast_fp16 = conv(dilations = x_363_dilations_0, groups = x_363_groups_0, pad = x_363_pad_0, pad_type = x_363_pad_type_0, strides = x_363_strides_0, weight = encoder_layers_13_conv_pointwise_conv2_weight_to_fp16, x = input_735_cast_fp16)[name = tensor<string, []>("x_363_cast_fp16")];
            tensor<int32, [3]> input_737_perm_0 = const()[name = tensor<string, []>("input_737_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_737_cast_fp16 = transpose(perm = input_737_perm_0, x = x_363_cast_fp16)[name = tensor<string, []>("transpose_113")];
            tensor<fp16, [1, 17, 512]> input_739_cast_fp16 = add(x = input_723_cast_fp16, y = input_737_cast_fp16)[name = tensor<string, []>("input_739_cast_fp16")];
            tensor<int32, [1]> input_741_axes_0 = const()[name = tensor<string, []>("input_741_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_13_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172197440)))];
            tensor<fp16, [512]> encoder_layers_13_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172198528)))];
            tensor<fp16, [1, 17, 512]> input_741_cast_fp16 = layer_norm(axes = input_741_axes_0, beta = encoder_layers_13_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_13_norm_feed_forward2_weight_to_fp16, x = input_739_cast_fp16)[name = tensor<string, []>("input_741_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_13_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172199616)))];
            tensor<fp16, [1, 17, 2048]> linear_125_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_13_feed_forward2_linear1_weight_to_fp16, x = input_741_cast_fp16)[name = tensor<string, []>("linear_125_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_745_cast_fp16 = silu(x = linear_125_cast_fp16)[name = tensor<string, []>("input_745_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_13_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(174296832)))];
            tensor<fp16, [1, 17, 512]> linear_126_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_13_feed_forward2_linear2_weight_to_fp16, x = input_745_cast_fp16)[name = tensor<string, []>("linear_126_cast_fp16")];
            tensor<fp16, []> var_3124_to_fp16 = const()[name = tensor<string, []>("op_3124_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_3125_cast_fp16 = mul(x = linear_126_cast_fp16, y = var_3124_to_fp16)[name = tensor<string, []>("op_3125_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_751_cast_fp16 = add(x = input_739_cast_fp16, y = var_3125_cast_fp16)[name = tensor<string, []>("input_751_cast_fp16")];
            tensor<int32, [1]> input_753_axes_0 = const()[name = tensor<string, []>("input_753_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_13_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176394048)))];
            tensor<fp16, [512]> encoder_layers_13_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_13_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176395136)))];
            tensor<fp16, [1, 17, 512]> input_753_cast_fp16 = layer_norm(axes = input_753_axes_0, beta = encoder_layers_13_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_13_norm_out_weight_to_fp16, x = input_751_cast_fp16)[name = tensor<string, []>("input_753_cast_fp16")];
            tensor<int32, [4]> cache_57_begin_0 = const()[name = tensor<string, []>("cache_57_begin_0"), val = tensor<int32, [4]>([14, 0, 0, 0])];
            tensor<int32, [4]> cache_57_end_0 = const()[name = tensor<string, []>("cache_57_end_0"), val = tensor<int32, [4]>([15, 1, 70, 512])];
            tensor<bool, [4]> cache_57_end_mask_0 = const()[name = tensor<string, []>("cache_57_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_57_squeeze_mask_0 = const()[name = tensor<string, []>("cache_57_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_57_cast_fp16 = slice_by_index(begin = cache_57_begin_0, end = cache_57_end_0, end_mask = cache_57_end_mask_0, squeeze_mask = cache_57_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_57_cast_fp16")];
            tensor<int32, [4]> cache_59_begin_0 = const()[name = tensor<string, []>("cache_59_begin_0"), val = tensor<int32, [4]>([14, 0, 0, 0])];
            tensor<int32, [4]> cache_59_end_0 = const()[name = tensor<string, []>("cache_59_end_0"), val = tensor<int32, [4]>([15, 1, 512, 8])];
            tensor<bool, [4]> cache_59_end_mask_0 = const()[name = tensor<string, []>("cache_59_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_59_squeeze_mask_0 = const()[name = tensor<string, []>("cache_59_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_59_cast_fp16 = slice_by_index(begin = cache_59_begin_0, end = cache_59_end_0, end_mask = cache_59_end_mask_0, squeeze_mask = cache_59_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_59_cast_fp16")];
            tensor<int32, [1]> input_755_axes_0 = const()[name = tensor<string, []>("input_755_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_14_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176396224)))];
            tensor<fp16, [512]> encoder_layers_14_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176397312)))];
            tensor<fp16, [1, 17, 512]> input_755_cast_fp16 = layer_norm(axes = input_755_axes_0, beta = encoder_layers_14_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_14_norm_feed_forward1_weight_to_fp16, x = input_753_cast_fp16)[name = tensor<string, []>("input_755_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_14_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176398400)))];
            tensor<fp16, [1, 17, 2048]> linear_127_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_14_feed_forward1_linear1_weight_to_fp16, x = input_755_cast_fp16)[name = tensor<string, []>("linear_127_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_759_cast_fp16 = silu(x = linear_127_cast_fp16)[name = tensor<string, []>("input_759_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_14_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(178495616)))];
            tensor<fp16, [1, 17, 512]> linear_128_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_14_feed_forward1_linear2_weight_to_fp16, x = input_759_cast_fp16)[name = tensor<string, []>("linear_128_cast_fp16")];
            tensor<fp16, []> var_3159_to_fp16 = const()[name = tensor<string, []>("op_3159_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_3160_cast_fp16 = mul(x = linear_128_cast_fp16, y = var_3159_to_fp16)[name = tensor<string, []>("op_3160_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_765_cast_fp16 = add(x = input_753_cast_fp16, y = var_3160_cast_fp16)[name = tensor<string, []>("input_765_cast_fp16")];
            tensor<int32, [1]> key_29_axes_0 = const()[name = tensor<string, []>("key_29_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_14_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180592832)))];
            tensor<fp16, [512]> encoder_layers_14_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180593920)))];
            tensor<fp16, [1, 17, 512]> key_29_cast_fp16 = layer_norm(axes = key_29_axes_0, beta = encoder_layers_14_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_14_norm_self_att_weight_to_fp16, x = input_765_cast_fp16)[name = tensor<string, []>("key_29_cast_fp16")];
            tensor<bool, []> input_767_interleave_0 = const()[name = tensor<string, []>("input_767_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_767_cast_fp16 = concat(axis = var_64, interleave = input_767_interleave_0, values = (cache_57_cast_fp16, key_29_cast_fp16))[name = tensor<string, []>("input_767_cast_fp16")];
            tensor<int32, [3]> var_3182_begin_0 = const()[name = tensor<string, []>("op_3182_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_3182_end_0 = const()[name = tensor<string, []>("op_3182_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_3182_end_mask_0 = const()[name = tensor<string, []>("op_3182_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_3182_cast_fp16 = slice_by_index(begin = var_3182_begin_0, end = var_3182_end_0, end_mask = var_3182_end_mask_0, x = cache_57_cast_fp16)[name = tensor<string, []>("op_3182_cast_fp16")];
            tensor<bool, []> var_3188_interleave_0 = const()[name = tensor<string, []>("op_3188_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_3188_cast_fp16 = concat(axis = var_64, interleave = var_3188_interleave_0, values = (var_3182_cast_fp16, key_29_cast_fp16))[name = tensor<string, []>("op_3188_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_14_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180595008)))];
            tensor<fp16, [1, 17, 512]> linear_129_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_14_self_attn_linear_q_weight_to_fp16, x = key_29_cast_fp16)[name = tensor<string, []>("linear_129_cast_fp16")];
            tensor<int32, [4]> var_3192 = const()[name = tensor<string, []>("op_3192"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_85_cast_fp16 = reshape(shape = var_3192, x = linear_129_cast_fp16)[name = tensor<string, []>("q_85_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_14_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181119360)))];
            tensor<fp16, [1, 87, 512]> linear_130_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_14_self_attn_linear_k_weight_to_fp16, x = input_767_cast_fp16)[name = tensor<string, []>("linear_130_cast_fp16")];
            tensor<int32, [4]> var_3196 = const()[name = tensor<string, []>("op_3196"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_57_cast_fp16 = reshape(shape = var_3196, x = linear_130_cast_fp16)[name = tensor<string, []>("k_57_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_14_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181643712)))];
            tensor<fp16, [1, 87, 512]> linear_131_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_14_self_attn_linear_v_weight_to_fp16, x = input_767_cast_fp16)[name = tensor<string, []>("linear_131_cast_fp16")];
            tensor<int32, [4]> var_3200 = const()[name = tensor<string, []>("op_3200"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_29_cast_fp16 = reshape(shape = var_3200, x = linear_131_cast_fp16)[name = tensor<string, []>("v_29_cast_fp16")];
            tensor<int32, [4]> value_31_perm_0 = const()[name = tensor<string, []>("value_31_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_14_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182168064)))];
            tensor<fp16, [1, 17, 8, 64]> var_3212_cast_fp16 = add(x = q_85_cast_fp16, y = encoder_layers_14_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_3212_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_14_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182169152)))];
            tensor<fp16, [1, 17, 8, 64]> var_3214_cast_fp16 = add(x = q_85_cast_fp16, y = encoder_layers_14_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_3214_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_29_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_29_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_371_transpose_x_0 = const()[name = tensor<string, []>("x_371_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_371_transpose_y_0 = const()[name = tensor<string, []>("x_371_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_3216_to_fp16 = const()[name = tensor<string, []>("op_3216_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182170240)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_29_cast_fp16 = transpose(perm = q_with_bias_v_29_perm_0, x = var_3214_cast_fp16)[name = tensor<string, []>("transpose_111")];
            tensor<fp16, [1, 8, 17, 173]> x_371_cast_fp16 = matmul(transpose_x = x_371_transpose_x_0, transpose_y = x_371_transpose_y_0, x = q_with_bias_v_29_cast_fp16, y = var_3216_to_fp16)[name = tensor<string, []>("x_371_cast_fp16")];
            tensor<int32, [8]> x_373_pad_0 = const()[name = tensor<string, []>("x_373_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_373_mode_0 = const()[name = tensor<string, []>("x_373_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_205_to_fp16 = const()[name = tensor<string, []>("const_205_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_373_cast_fp16 = pad(constant_val = const_205_to_fp16, mode = x_373_mode_0, pad = x_373_pad_0, x = x_371_cast_fp16)[name = tensor<string, []>("x_373_cast_fp16")];
            tensor<int32, [4]> var_3224 = const()[name = tensor<string, []>("op_3224"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_375_cast_fp16 = reshape(shape = var_3224, x = x_373_cast_fp16)[name = tensor<string, []>("x_375_cast_fp16")];
            tensor<int32, [4]> var_3228_begin_0 = const()[name = tensor<string, []>("op_3228_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_3228_end_0 = const()[name = tensor<string, []>("op_3228_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_3228_end_mask_0 = const()[name = tensor<string, []>("op_3228_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_3228_cast_fp16 = slice_by_index(begin = var_3228_begin_0, end = var_3228_end_0, end_mask = var_3228_end_mask_0, x = x_375_cast_fp16)[name = tensor<string, []>("op_3228_cast_fp16")];
            tensor<int32, [4]> var_3229 = const()[name = tensor<string, []>("op_3229"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_57_cast_fp16 = reshape(shape = var_3229, x = var_3228_cast_fp16)[name = tensor<string, []>("matrix_bd_57_cast_fp16")];
            tensor<bool, []> matrix_ac_29_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_29_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_29_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_29_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_79_perm_0 = const()[name = tensor<string, []>("transpose_79_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_80_perm_0 = const()[name = tensor<string, []>("transpose_80_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_80 = transpose(perm = transpose_80_perm_0, x = k_57_cast_fp16)[name = tensor<string, []>("transpose_109")];
            tensor<fp16, [1, 8, 17, 64]> transpose_79 = transpose(perm = transpose_79_perm_0, x = var_3212_cast_fp16)[name = tensor<string, []>("transpose_110")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_29_cast_fp16 = matmul(transpose_x = matrix_ac_29_transpose_x_0, transpose_y = matrix_ac_29_transpose_y_0, x = transpose_79, y = transpose_80)[name = tensor<string, []>("matrix_ac_29_cast_fp16")];
            tensor<int32, [4]> matrix_bd_59_begin_0 = const()[name = tensor<string, []>("matrix_bd_59_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_59_end_0 = const()[name = tensor<string, []>("matrix_bd_59_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_59_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_59_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_59_cast_fp16 = slice_by_index(begin = matrix_bd_59_begin_0, end = matrix_bd_59_end_0, end_mask = matrix_bd_59_end_mask_0, x = matrix_bd_57_cast_fp16)[name = tensor<string, []>("matrix_bd_59_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_3238_cast_fp16 = add(x = matrix_ac_29_cast_fp16, y = matrix_bd_59_cast_fp16)[name = tensor<string, []>("op_3238_cast_fp16")];
            tensor<fp16, []> _inversed_scores_57_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_57_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_57_cast_fp16 = mul(x = var_3238_cast_fp16, y = _inversed_scores_57_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_57_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_59_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_57_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_59_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_3244_cast_fp16 = softmax(axis = var_62, x = scores_59_cast_fp16)[name = tensor<string, []>("op_3244_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_769_cast_fp16 = select(a = var_40_to_fp16, b = var_3244_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_769_cast_fp16")];
            tensor<bool, []> x_377_transpose_x_0 = const()[name = tensor<string, []>("x_377_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_377_transpose_y_0 = const()[name = tensor<string, []>("x_377_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_31_cast_fp16 = transpose(perm = value_31_perm_0, x = v_29_cast_fp16)[name = tensor<string, []>("transpose_112")];
            tensor<fp16, [1, 8, 17, 64]> x_377_cast_fp16 = matmul(transpose_x = x_377_transpose_x_0, transpose_y = x_377_transpose_y_0, x = input_769_cast_fp16, y = value_31_cast_fp16)[name = tensor<string, []>("x_377_cast_fp16")];
            tensor<int32, [4]> var_3248_perm_0 = const()[name = tensor<string, []>("op_3248_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_3249 = const()[name = tensor<string, []>("op_3249"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_3248_cast_fp16 = transpose(perm = var_3248_perm_0, x = x_377_cast_fp16)[name = tensor<string, []>("transpose_108")];
            tensor<fp16, [1, 17, 512]> input_771_cast_fp16 = reshape(shape = var_3249, x = var_3248_cast_fp16)[name = tensor<string, []>("input_771_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_14_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182347456)))];
            tensor<fp16, [1, 17, 512]> linear_133_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_14_self_attn_linear_out_weight_to_fp16, x = input_771_cast_fp16)[name = tensor<string, []>("linear_133_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_775_cast_fp16 = add(x = input_765_cast_fp16, y = linear_133_cast_fp16)[name = tensor<string, []>("input_775_cast_fp16")];
            tensor<int32, [1]> x_381_axes_0 = const()[name = tensor<string, []>("x_381_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_14_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182871808)))];
            tensor<fp16, [512]> encoder_layers_14_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182872896)))];
            tensor<fp16, [1, 17, 512]> x_381_cast_fp16 = layer_norm(axes = x_381_axes_0, beta = encoder_layers_14_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_14_norm_conv_weight_to_fp16, x = input_775_cast_fp16)[name = tensor<string, []>("x_381_cast_fp16")];
            tensor<int32, [3]> input_777_perm_0 = const()[name = tensor<string, []>("input_777_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_779_pad_type_0 = const()[name = tensor<string, []>("input_779_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_779_strides_0 = const()[name = tensor<string, []>("input_779_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_779_pad_0 = const()[name = tensor<string, []>("input_779_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_779_dilations_0 = const()[name = tensor<string, []>("input_779_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_779_groups_0 = const()[name = tensor<string, []>("input_779_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_14_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182873984)))];
            tensor<fp16, [1, 512, 17]> input_777_cast_fp16 = transpose(perm = input_777_perm_0, x = x_381_cast_fp16)[name = tensor<string, []>("transpose_107")];
            tensor<fp16, [1, 1024, 17]> input_779_cast_fp16 = conv(dilations = input_779_dilations_0, groups = input_779_groups_0, pad = input_779_pad_0, pad_type = input_779_pad_type_0, strides = input_779_strides_0, weight = encoder_layers_14_conv_pointwise_conv1_weight_to_fp16, x = input_777_cast_fp16)[name = tensor<string, []>("input_779_cast_fp16")];
            tensor<int32, []> x_383_split_num_splits_0 = const()[name = tensor<string, []>("x_383_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_383_split_axis_0 = const()[name = tensor<string, []>("x_383_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_383_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_383_split_cast_fp16_1 = split(axis = x_383_split_axis_0, num_splits = x_383_split_num_splits_0, x = input_779_cast_fp16)[name = tensor<string, []>("x_383_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_383_split_1_sigmoid_cast_fp16 = sigmoid(x = x_383_split_cast_fp16_1)[name = tensor<string, []>("x_383_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_383_cast_fp16 = mul(x = x_383_split_cast_fp16_0, y = x_383_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_383_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_781_cast_fp16 = select(a = var_40_to_fp16, b = x_383_cast_fp16, cond = var_418)[name = tensor<string, []>("input_781_cast_fp16")];
            tensor<bool, []> new_x_59_interleave_0 = const()[name = tensor<string, []>("new_x_59_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_59_cast_fp16 = concat(axis = var_62, interleave = new_x_59_interleave_0, values = (cache_59_cast_fp16, input_781_cast_fp16))[name = tensor<string, []>("new_x_59_cast_fp16")];
            tensor<int32, [3]> var_3287_begin_0 = const()[name = tensor<string, []>("op_3287_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_3287_end_0 = const()[name = tensor<string, []>("op_3287_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_3287_end_mask_0 = const()[name = tensor<string, []>("op_3287_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_3287_cast_fp16 = slice_by_index(begin = var_3287_begin_0, end = var_3287_end_0, end_mask = var_3287_end_mask_0, x = new_x_59_cast_fp16)[name = tensor<string, []>("op_3287_cast_fp16")];
            tensor<string, []> x_385_pad_type_0 = const()[name = tensor<string, []>("x_385_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_385_groups_0 = const()[name = tensor<string, []>("x_385_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_385_strides_0 = const()[name = tensor<string, []>("x_385_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_385_pad_0 = const()[name = tensor<string, []>("x_385_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_385_dilations_0 = const()[name = tensor<string, []>("x_385_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_14_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183922624)))];
            tensor<fp16, [1, 512, 17]> x_385_cast_fp16 = conv(dilations = x_385_dilations_0, groups = x_385_groups_0, pad = x_385_pad_0, pad_type = x_385_pad_type_0, strides = x_385_strides_0, weight = encoder_layers_14_conv_depthwise_conv_weight_to_fp16, x = new_x_59_cast_fp16)[name = tensor<string, []>("x_385_cast_fp16")];
            tensor<int32, [3]> input_783_perm_0 = const()[name = tensor<string, []>("input_783_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_387_axes_0 = const()[name = tensor<string, []>("x_387_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_14_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183931904)))];
            tensor<fp16, [512]> encoder_layers_14_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183932992)))];
            tensor<fp16, [1, 17, 512]> input_783_cast_fp16 = transpose(perm = input_783_perm_0, x = x_385_cast_fp16)[name = tensor<string, []>("transpose_106")];
            tensor<fp16, [1, 17, 512]> x_387_cast_fp16 = layer_norm(axes = x_387_axes_0, beta = encoder_layers_14_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_14_conv_batch_norm_weight_to_fp16, x = input_783_cast_fp16)[name = tensor<string, []>("x_387_cast_fp16")];
            tensor<int32, [3]> input_785_perm_0 = const()[name = tensor<string, []>("input_785_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_785_cast_fp16 = transpose(perm = input_785_perm_0, x = x_387_cast_fp16)[name = tensor<string, []>("transpose_105")];
            tensor<fp16, [1, 512, 17]> input_787_cast_fp16 = silu(x = input_785_cast_fp16)[name = tensor<string, []>("input_787_cast_fp16")];
            tensor<string, []> x_389_pad_type_0 = const()[name = tensor<string, []>("x_389_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_389_strides_0 = const()[name = tensor<string, []>("x_389_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_389_pad_0 = const()[name = tensor<string, []>("x_389_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_389_dilations_0 = const()[name = tensor<string, []>("x_389_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_389_groups_0 = const()[name = tensor<string, []>("x_389_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_14_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183934080)))];
            tensor<fp16, [1, 512, 17]> x_389_cast_fp16 = conv(dilations = x_389_dilations_0, groups = x_389_groups_0, pad = x_389_pad_0, pad_type = x_389_pad_type_0, strides = x_389_strides_0, weight = encoder_layers_14_conv_pointwise_conv2_weight_to_fp16, x = input_787_cast_fp16)[name = tensor<string, []>("x_389_cast_fp16")];
            tensor<int32, [3]> input_789_perm_0 = const()[name = tensor<string, []>("input_789_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_789_cast_fp16 = transpose(perm = input_789_perm_0, x = x_389_cast_fp16)[name = tensor<string, []>("transpose_104")];
            tensor<fp16, [1, 17, 512]> input_791_cast_fp16 = add(x = input_775_cast_fp16, y = input_789_cast_fp16)[name = tensor<string, []>("input_791_cast_fp16")];
            tensor<int32, [1]> input_793_axes_0 = const()[name = tensor<string, []>("input_793_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_14_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(184458432)))];
            tensor<fp16, [512]> encoder_layers_14_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(184459520)))];
            tensor<fp16, [1, 17, 512]> input_793_cast_fp16 = layer_norm(axes = input_793_axes_0, beta = encoder_layers_14_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_14_norm_feed_forward2_weight_to_fp16, x = input_791_cast_fp16)[name = tensor<string, []>("input_793_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_14_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(184460608)))];
            tensor<fp16, [1, 17, 2048]> linear_134_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_14_feed_forward2_linear1_weight_to_fp16, x = input_793_cast_fp16)[name = tensor<string, []>("linear_134_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_797_cast_fp16 = silu(x = linear_134_cast_fp16)[name = tensor<string, []>("input_797_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_14_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(186557824)))];
            tensor<fp16, [1, 17, 512]> linear_135_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_14_feed_forward2_linear2_weight_to_fp16, x = input_797_cast_fp16)[name = tensor<string, []>("linear_135_cast_fp16")];
            tensor<fp16, []> var_3328_to_fp16 = const()[name = tensor<string, []>("op_3328_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_3329_cast_fp16 = mul(x = linear_135_cast_fp16, y = var_3328_to_fp16)[name = tensor<string, []>("op_3329_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_803_cast_fp16 = add(x = input_791_cast_fp16, y = var_3329_cast_fp16)[name = tensor<string, []>("input_803_cast_fp16")];
            tensor<int32, [1]> input_805_axes_0 = const()[name = tensor<string, []>("input_805_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_14_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(188655040)))];
            tensor<fp16, [512]> encoder_layers_14_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_14_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(188656128)))];
            tensor<fp16, [1, 17, 512]> input_805_cast_fp16 = layer_norm(axes = input_805_axes_0, beta = encoder_layers_14_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_14_norm_out_weight_to_fp16, x = input_803_cast_fp16)[name = tensor<string, []>("input_805_cast_fp16")];
            tensor<int32, [4]> cache_61_begin_0 = const()[name = tensor<string, []>("cache_61_begin_0"), val = tensor<int32, [4]>([15, 0, 0, 0])];
            tensor<int32, [4]> cache_61_end_0 = const()[name = tensor<string, []>("cache_61_end_0"), val = tensor<int32, [4]>([16, 1, 70, 512])];
            tensor<bool, [4]> cache_61_end_mask_0 = const()[name = tensor<string, []>("cache_61_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_61_squeeze_mask_0 = const()[name = tensor<string, []>("cache_61_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_61_cast_fp16 = slice_by_index(begin = cache_61_begin_0, end = cache_61_end_0, end_mask = cache_61_end_mask_0, squeeze_mask = cache_61_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_61_cast_fp16")];
            tensor<int32, [4]> cache_63_begin_0 = const()[name = tensor<string, []>("cache_63_begin_0"), val = tensor<int32, [4]>([15, 0, 0, 0])];
            tensor<int32, [4]> cache_63_end_0 = const()[name = tensor<string, []>("cache_63_end_0"), val = tensor<int32, [4]>([16, 1, 512, 8])];
            tensor<bool, [4]> cache_63_end_mask_0 = const()[name = tensor<string, []>("cache_63_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_63_squeeze_mask_0 = const()[name = tensor<string, []>("cache_63_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_63_cast_fp16 = slice_by_index(begin = cache_63_begin_0, end = cache_63_end_0, end_mask = cache_63_end_mask_0, squeeze_mask = cache_63_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_63_cast_fp16")];
            tensor<int32, [1]> input_807_axes_0 = const()[name = tensor<string, []>("input_807_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_15_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(188657216)))];
            tensor<fp16, [512]> encoder_layers_15_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(188658304)))];
            tensor<fp16, [1, 17, 512]> input_807_cast_fp16 = layer_norm(axes = input_807_axes_0, beta = encoder_layers_15_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_15_norm_feed_forward1_weight_to_fp16, x = input_805_cast_fp16)[name = tensor<string, []>("input_807_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_15_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(188659392)))];
            tensor<fp16, [1, 17, 2048]> linear_136_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_15_feed_forward1_linear1_weight_to_fp16, x = input_807_cast_fp16)[name = tensor<string, []>("linear_136_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_811_cast_fp16 = silu(x = linear_136_cast_fp16)[name = tensor<string, []>("input_811_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_15_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(190756608)))];
            tensor<fp16, [1, 17, 512]> linear_137_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_15_feed_forward1_linear2_weight_to_fp16, x = input_811_cast_fp16)[name = tensor<string, []>("linear_137_cast_fp16")];
            tensor<fp16, []> var_3363_to_fp16 = const()[name = tensor<string, []>("op_3363_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_3364_cast_fp16 = mul(x = linear_137_cast_fp16, y = var_3363_to_fp16)[name = tensor<string, []>("op_3364_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_817_cast_fp16 = add(x = input_805_cast_fp16, y = var_3364_cast_fp16)[name = tensor<string, []>("input_817_cast_fp16")];
            tensor<int32, [1]> key_31_axes_0 = const()[name = tensor<string, []>("key_31_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_15_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(192853824)))];
            tensor<fp16, [512]> encoder_layers_15_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(192854912)))];
            tensor<fp16, [1, 17, 512]> key_31_cast_fp16 = layer_norm(axes = key_31_axes_0, beta = encoder_layers_15_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_15_norm_self_att_weight_to_fp16, x = input_817_cast_fp16)[name = tensor<string, []>("key_31_cast_fp16")];
            tensor<bool, []> input_819_interleave_0 = const()[name = tensor<string, []>("input_819_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_819_cast_fp16 = concat(axis = var_64, interleave = input_819_interleave_0, values = (cache_61_cast_fp16, key_31_cast_fp16))[name = tensor<string, []>("input_819_cast_fp16")];
            tensor<int32, [3]> var_3386_begin_0 = const()[name = tensor<string, []>("op_3386_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_3386_end_0 = const()[name = tensor<string, []>("op_3386_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_3386_end_mask_0 = const()[name = tensor<string, []>("op_3386_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_3386_cast_fp16 = slice_by_index(begin = var_3386_begin_0, end = var_3386_end_0, end_mask = var_3386_end_mask_0, x = cache_61_cast_fp16)[name = tensor<string, []>("op_3386_cast_fp16")];
            tensor<bool, []> var_3392_interleave_0 = const()[name = tensor<string, []>("op_3392_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> var_3392_cast_fp16 = concat(axis = var_64, interleave = var_3392_interleave_0, values = (var_3386_cast_fp16, key_31_cast_fp16))[name = tensor<string, []>("op_3392_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_15_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(192856000)))];
            tensor<fp16, [1, 17, 512]> linear_138_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_15_self_attn_linear_q_weight_to_fp16, x = key_31_cast_fp16)[name = tensor<string, []>("linear_138_cast_fp16")];
            tensor<int32, [4]> var_3396 = const()[name = tensor<string, []>("op_3396"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_91_cast_fp16 = reshape(shape = var_3396, x = linear_138_cast_fp16)[name = tensor<string, []>("q_91_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_15_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(193380352)))];
            tensor<fp16, [1, 87, 512]> linear_139_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_15_self_attn_linear_k_weight_to_fp16, x = input_819_cast_fp16)[name = tensor<string, []>("linear_139_cast_fp16")];
            tensor<int32, [4]> var_3400 = const()[name = tensor<string, []>("op_3400"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_61_cast_fp16 = reshape(shape = var_3400, x = linear_139_cast_fp16)[name = tensor<string, []>("k_61_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_15_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(193904704)))];
            tensor<fp16, [1, 87, 512]> linear_140_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_15_self_attn_linear_v_weight_to_fp16, x = input_819_cast_fp16)[name = tensor<string, []>("linear_140_cast_fp16")];
            tensor<int32, [4]> var_3404 = const()[name = tensor<string, []>("op_3404"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_31_cast_fp16 = reshape(shape = var_3404, x = linear_140_cast_fp16)[name = tensor<string, []>("v_31_cast_fp16")];
            tensor<int32, [4]> value_33_perm_0 = const()[name = tensor<string, []>("value_33_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_15_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194429056)))];
            tensor<fp16, [1, 17, 8, 64]> var_3416_cast_fp16 = add(x = q_91_cast_fp16, y = encoder_layers_15_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_3416_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_15_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194430144)))];
            tensor<fp16, [1, 17, 8, 64]> var_3418_cast_fp16 = add(x = q_91_cast_fp16, y = encoder_layers_15_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_3418_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_31_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_31_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_397_transpose_x_0 = const()[name = tensor<string, []>("x_397_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_397_transpose_y_0 = const()[name = tensor<string, []>("x_397_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_3420_to_fp16 = const()[name = tensor<string, []>("op_3420_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194431232)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_31_cast_fp16 = transpose(perm = q_with_bias_v_31_perm_0, x = var_3418_cast_fp16)[name = tensor<string, []>("transpose_102")];
            tensor<fp16, [1, 8, 17, 173]> x_397_cast_fp16 = matmul(transpose_x = x_397_transpose_x_0, transpose_y = x_397_transpose_y_0, x = q_with_bias_v_31_cast_fp16, y = var_3420_to_fp16)[name = tensor<string, []>("x_397_cast_fp16")];
            tensor<int32, [8]> x_399_pad_0 = const()[name = tensor<string, []>("x_399_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_399_mode_0 = const()[name = tensor<string, []>("x_399_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_218_to_fp16 = const()[name = tensor<string, []>("const_218_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_399_cast_fp16 = pad(constant_val = const_218_to_fp16, mode = x_399_mode_0, pad = x_399_pad_0, x = x_397_cast_fp16)[name = tensor<string, []>("x_399_cast_fp16")];
            tensor<int32, [4]> var_3428 = const()[name = tensor<string, []>("op_3428"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_401_cast_fp16 = reshape(shape = var_3428, x = x_399_cast_fp16)[name = tensor<string, []>("x_401_cast_fp16")];
            tensor<int32, [4]> var_3432_begin_0 = const()[name = tensor<string, []>("op_3432_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_3432_end_0 = const()[name = tensor<string, []>("op_3432_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_3432_end_mask_0 = const()[name = tensor<string, []>("op_3432_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_3432_cast_fp16 = slice_by_index(begin = var_3432_begin_0, end = var_3432_end_0, end_mask = var_3432_end_mask_0, x = x_401_cast_fp16)[name = tensor<string, []>("op_3432_cast_fp16")];
            tensor<int32, [4]> var_3433 = const()[name = tensor<string, []>("op_3433"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_61_cast_fp16 = reshape(shape = var_3433, x = var_3432_cast_fp16)[name = tensor<string, []>("matrix_bd_61_cast_fp16")];
            tensor<bool, []> matrix_ac_31_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_31_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_31_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_31_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_81_perm_0 = const()[name = tensor<string, []>("transpose_81_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_82_perm_0 = const()[name = tensor<string, []>("transpose_82_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_82 = transpose(perm = transpose_82_perm_0, x = k_61_cast_fp16)[name = tensor<string, []>("transpose_100")];
            tensor<fp16, [1, 8, 17, 64]> transpose_81 = transpose(perm = transpose_81_perm_0, x = var_3416_cast_fp16)[name = tensor<string, []>("transpose_101")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_31_cast_fp16 = matmul(transpose_x = matrix_ac_31_transpose_x_0, transpose_y = matrix_ac_31_transpose_y_0, x = transpose_81, y = transpose_82)[name = tensor<string, []>("matrix_ac_31_cast_fp16")];
            tensor<int32, [4]> matrix_bd_63_begin_0 = const()[name = tensor<string, []>("matrix_bd_63_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_63_end_0 = const()[name = tensor<string, []>("matrix_bd_63_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_63_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_63_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_63_cast_fp16 = slice_by_index(begin = matrix_bd_63_begin_0, end = matrix_bd_63_end_0, end_mask = matrix_bd_63_end_mask_0, x = matrix_bd_61_cast_fp16)[name = tensor<string, []>("matrix_bd_63_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_3442_cast_fp16 = add(x = matrix_ac_31_cast_fp16, y = matrix_bd_63_cast_fp16)[name = tensor<string, []>("op_3442_cast_fp16")];
            tensor<fp16, []> _inversed_scores_61_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_61_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_61_cast_fp16 = mul(x = var_3442_cast_fp16, y = _inversed_scores_61_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_61_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_63_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_61_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_63_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_3448_cast_fp16 = softmax(axis = var_62, x = scores_63_cast_fp16)[name = tensor<string, []>("op_3448_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_821_cast_fp16 = select(a = var_40_to_fp16, b = var_3448_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_821_cast_fp16")];
            tensor<bool, []> x_403_transpose_x_0 = const()[name = tensor<string, []>("x_403_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_403_transpose_y_0 = const()[name = tensor<string, []>("x_403_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_33_cast_fp16 = transpose(perm = value_33_perm_0, x = v_31_cast_fp16)[name = tensor<string, []>("transpose_103")];
            tensor<fp16, [1, 8, 17, 64]> x_403_cast_fp16 = matmul(transpose_x = x_403_transpose_x_0, transpose_y = x_403_transpose_y_0, x = input_821_cast_fp16, y = value_33_cast_fp16)[name = tensor<string, []>("x_403_cast_fp16")];
            tensor<int32, [4]> var_3452_perm_0 = const()[name = tensor<string, []>("op_3452_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_3453 = const()[name = tensor<string, []>("op_3453"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_3452_cast_fp16 = transpose(perm = var_3452_perm_0, x = x_403_cast_fp16)[name = tensor<string, []>("transpose_99")];
            tensor<fp16, [1, 17, 512]> input_823_cast_fp16 = reshape(shape = var_3453, x = var_3452_cast_fp16)[name = tensor<string, []>("input_823_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_15_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194608448)))];
            tensor<fp16, [1, 17, 512]> linear_142_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_15_self_attn_linear_out_weight_to_fp16, x = input_823_cast_fp16)[name = tensor<string, []>("linear_142_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_827_cast_fp16 = add(x = input_817_cast_fp16, y = linear_142_cast_fp16)[name = tensor<string, []>("input_827_cast_fp16")];
            tensor<int32, [1]> x_407_axes_0 = const()[name = tensor<string, []>("x_407_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_15_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(195132800)))];
            tensor<fp16, [512]> encoder_layers_15_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(195133888)))];
            tensor<fp16, [1, 17, 512]> x_407_cast_fp16 = layer_norm(axes = x_407_axes_0, beta = encoder_layers_15_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_15_norm_conv_weight_to_fp16, x = input_827_cast_fp16)[name = tensor<string, []>("x_407_cast_fp16")];
            tensor<int32, [3]> input_829_perm_0 = const()[name = tensor<string, []>("input_829_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_831_pad_type_0 = const()[name = tensor<string, []>("input_831_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_831_strides_0 = const()[name = tensor<string, []>("input_831_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_831_pad_0 = const()[name = tensor<string, []>("input_831_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_831_dilations_0 = const()[name = tensor<string, []>("input_831_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_831_groups_0 = const()[name = tensor<string, []>("input_831_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_15_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(195134976)))];
            tensor<fp16, [1, 512, 17]> input_829_cast_fp16 = transpose(perm = input_829_perm_0, x = x_407_cast_fp16)[name = tensor<string, []>("transpose_98")];
            tensor<fp16, [1, 1024, 17]> input_831_cast_fp16 = conv(dilations = input_831_dilations_0, groups = input_831_groups_0, pad = input_831_pad_0, pad_type = input_831_pad_type_0, strides = input_831_strides_0, weight = encoder_layers_15_conv_pointwise_conv1_weight_to_fp16, x = input_829_cast_fp16)[name = tensor<string, []>("input_831_cast_fp16")];
            tensor<int32, []> x_409_split_num_splits_0 = const()[name = tensor<string, []>("x_409_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_409_split_axis_0 = const()[name = tensor<string, []>("x_409_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_409_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_409_split_cast_fp16_1 = split(axis = x_409_split_axis_0, num_splits = x_409_split_num_splits_0, x = input_831_cast_fp16)[name = tensor<string, []>("x_409_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_409_split_1_sigmoid_cast_fp16 = sigmoid(x = x_409_split_cast_fp16_1)[name = tensor<string, []>("x_409_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_409_cast_fp16 = mul(x = x_409_split_cast_fp16_0, y = x_409_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_409_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_833_cast_fp16 = select(a = var_40_to_fp16, b = x_409_cast_fp16, cond = var_418)[name = tensor<string, []>("input_833_cast_fp16")];
            tensor<bool, []> new_x_63_interleave_0 = const()[name = tensor<string, []>("new_x_63_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_63_cast_fp16 = concat(axis = var_62, interleave = new_x_63_interleave_0, values = (cache_63_cast_fp16, input_833_cast_fp16))[name = tensor<string, []>("new_x_63_cast_fp16")];
            tensor<int32, [3]> var_3491_begin_0 = const()[name = tensor<string, []>("op_3491_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> var_3491_end_0 = const()[name = tensor<string, []>("op_3491_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> var_3491_end_mask_0 = const()[name = tensor<string, []>("op_3491_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> var_3491_cast_fp16 = slice_by_index(begin = var_3491_begin_0, end = var_3491_end_0, end_mask = var_3491_end_mask_0, x = new_x_63_cast_fp16)[name = tensor<string, []>("op_3491_cast_fp16")];
            tensor<string, []> x_411_pad_type_0 = const()[name = tensor<string, []>("x_411_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_411_groups_0 = const()[name = tensor<string, []>("x_411_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_411_strides_0 = const()[name = tensor<string, []>("x_411_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_411_pad_0 = const()[name = tensor<string, []>("x_411_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_411_dilations_0 = const()[name = tensor<string, []>("x_411_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_15_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196183616)))];
            tensor<fp16, [1, 512, 17]> x_411_cast_fp16 = conv(dilations = x_411_dilations_0, groups = x_411_groups_0, pad = x_411_pad_0, pad_type = x_411_pad_type_0, strides = x_411_strides_0, weight = encoder_layers_15_conv_depthwise_conv_weight_to_fp16, x = new_x_63_cast_fp16)[name = tensor<string, []>("x_411_cast_fp16")];
            tensor<int32, [3]> input_835_perm_0 = const()[name = tensor<string, []>("input_835_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_413_axes_0 = const()[name = tensor<string, []>("x_413_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_15_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196192896)))];
            tensor<fp16, [512]> encoder_layers_15_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196193984)))];
            tensor<fp16, [1, 17, 512]> input_835_cast_fp16 = transpose(perm = input_835_perm_0, x = x_411_cast_fp16)[name = tensor<string, []>("transpose_97")];
            tensor<fp16, [1, 17, 512]> x_413_cast_fp16 = layer_norm(axes = x_413_axes_0, beta = encoder_layers_15_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_15_conv_batch_norm_weight_to_fp16, x = input_835_cast_fp16)[name = tensor<string, []>("x_413_cast_fp16")];
            tensor<int32, [3]> input_837_perm_0 = const()[name = tensor<string, []>("input_837_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_837_cast_fp16 = transpose(perm = input_837_perm_0, x = x_413_cast_fp16)[name = tensor<string, []>("transpose_96")];
            tensor<fp16, [1, 512, 17]> input_839_cast_fp16 = silu(x = input_837_cast_fp16)[name = tensor<string, []>("input_839_cast_fp16")];
            tensor<string, []> x_415_pad_type_0 = const()[name = tensor<string, []>("x_415_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_415_strides_0 = const()[name = tensor<string, []>("x_415_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_415_pad_0 = const()[name = tensor<string, []>("x_415_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_415_dilations_0 = const()[name = tensor<string, []>("x_415_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_415_groups_0 = const()[name = tensor<string, []>("x_415_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_15_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196195072)))];
            tensor<fp16, [1, 512, 17]> x_415_cast_fp16 = conv(dilations = x_415_dilations_0, groups = x_415_groups_0, pad = x_415_pad_0, pad_type = x_415_pad_type_0, strides = x_415_strides_0, weight = encoder_layers_15_conv_pointwise_conv2_weight_to_fp16, x = input_839_cast_fp16)[name = tensor<string, []>("x_415_cast_fp16")];
            tensor<int32, [3]> input_841_perm_0 = const()[name = tensor<string, []>("input_841_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_841_cast_fp16 = transpose(perm = input_841_perm_0, x = x_415_cast_fp16)[name = tensor<string, []>("transpose_95")];
            tensor<fp16, [1, 17, 512]> input_843_cast_fp16 = add(x = input_827_cast_fp16, y = input_841_cast_fp16)[name = tensor<string, []>("input_843_cast_fp16")];
            tensor<int32, [1]> input_845_axes_0 = const()[name = tensor<string, []>("input_845_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_15_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196719424)))];
            tensor<fp16, [512]> encoder_layers_15_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196720512)))];
            tensor<fp16, [1, 17, 512]> input_845_cast_fp16 = layer_norm(axes = input_845_axes_0, beta = encoder_layers_15_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_15_norm_feed_forward2_weight_to_fp16, x = input_843_cast_fp16)[name = tensor<string, []>("input_845_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_15_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196721600)))];
            tensor<fp16, [1, 17, 2048]> linear_143_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_15_feed_forward2_linear1_weight_to_fp16, x = input_845_cast_fp16)[name = tensor<string, []>("linear_143_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_849_cast_fp16 = silu(x = linear_143_cast_fp16)[name = tensor<string, []>("input_849_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_15_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(198818816)))];
            tensor<fp16, [1, 17, 512]> linear_144_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_15_feed_forward2_linear2_weight_to_fp16, x = input_849_cast_fp16)[name = tensor<string, []>("linear_144_cast_fp16")];
            tensor<fp16, []> var_3532_to_fp16 = const()[name = tensor<string, []>("op_3532_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_3533_cast_fp16 = mul(x = linear_144_cast_fp16, y = var_3532_to_fp16)[name = tensor<string, []>("op_3533_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_855_cast_fp16 = add(x = input_843_cast_fp16, y = var_3533_cast_fp16)[name = tensor<string, []>("input_855_cast_fp16")];
            tensor<int32, [1]> input_857_axes_0 = const()[name = tensor<string, []>("input_857_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_15_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(200916032)))];
            tensor<fp16, [512]> encoder_layers_15_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_15_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(200917120)))];
            tensor<fp16, [1, 17, 512]> input_857_cast_fp16 = layer_norm(axes = input_857_axes_0, beta = encoder_layers_15_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_15_norm_out_weight_to_fp16, x = input_855_cast_fp16)[name = tensor<string, []>("input_857_cast_fp16")];
            tensor<int32, [4]> cache_65_begin_0 = const()[name = tensor<string, []>("cache_65_begin_0"), val = tensor<int32, [4]>([16, 0, 0, 0])];
            tensor<int32, [4]> cache_65_end_0 = const()[name = tensor<string, []>("cache_65_end_0"), val = tensor<int32, [4]>([17, 1, 70, 512])];
            tensor<bool, [4]> cache_65_end_mask_0 = const()[name = tensor<string, []>("cache_65_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_65_squeeze_mask_0 = const()[name = tensor<string, []>("cache_65_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 70, 512]> cache_65_cast_fp16 = slice_by_index(begin = cache_65_begin_0, end = cache_65_end_0, end_mask = cache_65_end_mask_0, squeeze_mask = cache_65_squeeze_mask_0, x = cache_last_channel_to_fp16)[name = tensor<string, []>("cache_65_cast_fp16")];
            tensor<int32, [4]> cache_begin_0 = const()[name = tensor<string, []>("cache_begin_0"), val = tensor<int32, [4]>([16, 0, 0, 0])];
            tensor<int32, [4]> cache_end_0 = const()[name = tensor<string, []>("cache_end_0"), val = tensor<int32, [4]>([17, 1, 512, 8])];
            tensor<bool, [4]> cache_end_mask_0 = const()[name = tensor<string, []>("cache_end_mask_0"), val = tensor<bool, [4]>([false, true, true, true])];
            tensor<bool, [4]> cache_squeeze_mask_0 = const()[name = tensor<string, []>("cache_squeeze_mask_0"), val = tensor<bool, [4]>([true, false, false, false])];
            tensor<fp16, [1, 512, 8]> cache_cast_fp16 = slice_by_index(begin = cache_begin_0, end = cache_end_0, end_mask = cache_end_mask_0, squeeze_mask = cache_squeeze_mask_0, x = cache_last_time_to_fp16)[name = tensor<string, []>("cache_cast_fp16")];
            tensor<int32, [1]> input_859_axes_0 = const()[name = tensor<string, []>("input_859_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_16_norm_feed_forward1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_feed_forward1_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(200918208)))];
            tensor<fp16, [512]> encoder_layers_16_norm_feed_forward1_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_feed_forward1_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(200919296)))];
            tensor<fp16, [1, 17, 512]> input_859_cast_fp16 = layer_norm(axes = input_859_axes_0, beta = encoder_layers_16_norm_feed_forward1_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_16_norm_feed_forward1_weight_to_fp16, x = input_857_cast_fp16)[name = tensor<string, []>("input_859_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_16_feed_forward1_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_feed_forward1_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(200920384)))];
            tensor<fp16, [1, 17, 2048]> linear_145_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_16_feed_forward1_linear1_weight_to_fp16, x = input_859_cast_fp16)[name = tensor<string, []>("linear_145_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_863_cast_fp16 = silu(x = linear_145_cast_fp16)[name = tensor<string, []>("input_863_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_16_feed_forward1_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_feed_forward1_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(203017600)))];
            tensor<fp16, [1, 17, 512]> linear_146_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_16_feed_forward1_linear2_weight_to_fp16, x = input_863_cast_fp16)[name = tensor<string, []>("linear_146_cast_fp16")];
            tensor<fp16, []> var_3567_to_fp16 = const()[name = tensor<string, []>("op_3567_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_3568_cast_fp16 = mul(x = linear_146_cast_fp16, y = var_3567_to_fp16)[name = tensor<string, []>("op_3568_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_869_cast_fp16 = add(x = input_857_cast_fp16, y = var_3568_cast_fp16)[name = tensor<string, []>("input_869_cast_fp16")];
            tensor<int32, [1]> key_axes_0 = const()[name = tensor<string, []>("key_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_16_norm_self_att_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_self_att_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205114816)))];
            tensor<fp16, [512]> encoder_layers_16_norm_self_att_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_self_att_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205115904)))];
            tensor<fp16, [1, 17, 512]> key_cast_fp16 = layer_norm(axes = key_axes_0, beta = encoder_layers_16_norm_self_att_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_16_norm_self_att_weight_to_fp16, x = input_869_cast_fp16)[name = tensor<string, []>("key_cast_fp16")];
            tensor<bool, []> input_871_interleave_0 = const()[name = tensor<string, []>("input_871_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 87, 512]> input_871_cast_fp16 = concat(axis = var_64, interleave = input_871_interleave_0, values = (cache_65_cast_fp16, key_cast_fp16))[name = tensor<string, []>("input_871_cast_fp16")];
            tensor<int32, [3]> var_3590_begin_0 = const()[name = tensor<string, []>("op_3590_begin_0"), val = tensor<int32, [3]>([0, 17, 0])];
            tensor<int32, [3]> var_3590_end_0 = const()[name = tensor<string, []>("op_3590_end_0"), val = tensor<int32, [3]>([1, 70, 512])];
            tensor<bool, [3]> var_3590_end_mask_0 = const()[name = tensor<string, []>("op_3590_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 53, 512]> var_3590_cast_fp16 = slice_by_index(begin = var_3590_begin_0, end = var_3590_end_0, end_mask = var_3590_end_mask_0, x = cache_65_cast_fp16)[name = tensor<string, []>("op_3590_cast_fp16")];
            tensor<bool, []> cache_last_channel_cur_interleave_0 = const()[name = tensor<string, []>("cache_last_channel_cur_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 70, 512]> cache_last_channel_cur_cast_fp16 = concat(axis = var_64, interleave = cache_last_channel_cur_interleave_0, values = (var_3590_cast_fp16, key_cast_fp16))[name = tensor<string, []>("cache_last_channel_cur_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_16_self_attn_linear_q_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_self_attn_linear_q_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205116992)))];
            tensor<fp16, [1, 17, 512]> linear_147_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_16_self_attn_linear_q_weight_to_fp16, x = key_cast_fp16)[name = tensor<string, []>("linear_147_cast_fp16")];
            tensor<int32, [4]> var_3600 = const()[name = tensor<string, []>("op_3600"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 17, 8, 64]> q_97_cast_fp16 = reshape(shape = var_3600, x = linear_147_cast_fp16)[name = tensor<string, []>("q_97_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_16_self_attn_linear_k_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_self_attn_linear_k_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205641344)))];
            tensor<fp16, [1, 87, 512]> linear_148_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_16_self_attn_linear_k_weight_to_fp16, x = input_871_cast_fp16)[name = tensor<string, []>("linear_148_cast_fp16")];
            tensor<int32, [4]> var_3604 = const()[name = tensor<string, []>("op_3604"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> k_65_cast_fp16 = reshape(shape = var_3604, x = linear_148_cast_fp16)[name = tensor<string, []>("k_65_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_16_self_attn_linear_v_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_self_attn_linear_v_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206165696)))];
            tensor<fp16, [1, 87, 512]> linear_149_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_16_self_attn_linear_v_weight_to_fp16, x = input_871_cast_fp16)[name = tensor<string, []>("linear_149_cast_fp16")];
            tensor<int32, [4]> var_3608 = const()[name = tensor<string, []>("op_3608"), val = tensor<int32, [4]>([1, -1, 8, 64])];
            tensor<fp16, [1, 87, 8, 64]> v_cast_fp16 = reshape(shape = var_3608, x = linear_149_cast_fp16)[name = tensor<string, []>("v_cast_fp16")];
            tensor<int32, [4]> value_perm_0 = const()[name = tensor<string, []>("value_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [8, 64]> encoder_layers_16_self_attn_pos_bias_u_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_self_attn_pos_bias_u_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206690048)))];
            tensor<fp16, [1, 17, 8, 64]> var_3620_cast_fp16 = add(x = q_97_cast_fp16, y = encoder_layers_16_self_attn_pos_bias_u_to_fp16)[name = tensor<string, []>("op_3620_cast_fp16")];
            tensor<fp16, [8, 64]> encoder_layers_16_self_attn_pos_bias_v_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_self_attn_pos_bias_v_to_fp16"), val = tensor<fp16, [8, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206691136)))];
            tensor<fp16, [1, 17, 8, 64]> var_3622_cast_fp16 = add(x = q_97_cast_fp16, y = encoder_layers_16_self_attn_pos_bias_v_to_fp16)[name = tensor<string, []>("op_3622_cast_fp16")];
            tensor<int32, [4]> q_with_bias_v_perm_0 = const()[name = tensor<string, []>("q_with_bias_v_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<bool, []> x_423_transpose_x_0 = const()[name = tensor<string, []>("x_423_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_423_transpose_y_0 = const()[name = tensor<string, []>("x_423_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 64, 173]> var_3624_to_fp16 = const()[name = tensor<string, []>("op_3624_to_fp16"), val = tensor<fp16, [1, 8, 64, 173]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206692224)))];
            tensor<fp16, [1, 8, 17, 64]> q_with_bias_v_cast_fp16 = transpose(perm = q_with_bias_v_perm_0, x = var_3622_cast_fp16)[name = tensor<string, []>("transpose_93")];
            tensor<fp16, [1, 8, 17, 173]> x_423_cast_fp16 = matmul(transpose_x = x_423_transpose_x_0, transpose_y = x_423_transpose_y_0, x = q_with_bias_v_cast_fp16, y = var_3624_to_fp16)[name = tensor<string, []>("x_423_cast_fp16")];
            tensor<int32, [8]> x_425_pad_0 = const()[name = tensor<string, []>("x_425_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 0, 1, 0])];
            tensor<string, []> x_425_mode_0 = const()[name = tensor<string, []>("x_425_mode_0"), val = tensor<string, []>("constant")];
            tensor<fp16, []> const_231_to_fp16 = const()[name = tensor<string, []>("const_231_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [1, 8, 17, 174]> x_425_cast_fp16 = pad(constant_val = const_231_to_fp16, mode = x_425_mode_0, pad = x_425_pad_0, x = x_423_cast_fp16)[name = tensor<string, []>("x_425_cast_fp16")];
            tensor<int32, [4]> var_3632 = const()[name = tensor<string, []>("op_3632"), val = tensor<int32, [4]>([1, 8, -1, 17])];
            tensor<fp16, [1, 8, 174, 17]> x_427_cast_fp16 = reshape(shape = var_3632, x = x_425_cast_fp16)[name = tensor<string, []>("x_427_cast_fp16")];
            tensor<int32, [4]> var_3636_begin_0 = const()[name = tensor<string, []>("op_3636_begin_0"), val = tensor<int32, [4]>([0, 0, 1, 0])];
            tensor<int32, [4]> var_3636_end_0 = const()[name = tensor<string, []>("op_3636_end_0"), val = tensor<int32, [4]>([1, 8, 174, 17])];
            tensor<bool, [4]> var_3636_end_mask_0 = const()[name = tensor<string, []>("op_3636_end_mask_0"), val = tensor<bool, [4]>([true, true, true, true])];
            tensor<fp16, [1, 8, 173, 17]> var_3636_cast_fp16 = slice_by_index(begin = var_3636_begin_0, end = var_3636_end_0, end_mask = var_3636_end_mask_0, x = x_427_cast_fp16)[name = tensor<string, []>("op_3636_cast_fp16")];
            tensor<int32, [4]> var_3637 = const()[name = tensor<string, []>("op_3637"), val = tensor<int32, [4]>([1, 8, 17, 173])];
            tensor<fp16, [1, 8, 17, 173]> matrix_bd_65_cast_fp16 = reshape(shape = var_3637, x = var_3636_cast_fp16)[name = tensor<string, []>("matrix_bd_65_cast_fp16")];
            tensor<bool, []> matrix_ac_transpose_x_0 = const()[name = tensor<string, []>("matrix_ac_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matrix_ac_transpose_y_0 = const()[name = tensor<string, []>("matrix_ac_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_83_perm_0 = const()[name = tensor<string, []>("transpose_83_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_84_perm_0 = const()[name = tensor<string, []>("transpose_84_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp16, [1, 8, 64, 87]> transpose_84 = transpose(perm = transpose_84_perm_0, x = k_65_cast_fp16)[name = tensor<string, []>("transpose_91")];
            tensor<fp16, [1, 8, 17, 64]> transpose_83 = transpose(perm = transpose_83_perm_0, x = var_3620_cast_fp16)[name = tensor<string, []>("transpose_92")];
            tensor<fp16, [1, 8, 17, 87]> matrix_ac_cast_fp16 = matmul(transpose_x = matrix_ac_transpose_x_0, transpose_y = matrix_ac_transpose_y_0, x = transpose_83, y = transpose_84)[name = tensor<string, []>("matrix_ac_cast_fp16")];
            tensor<int32, [4]> matrix_bd_begin_0 = const()[name = tensor<string, []>("matrix_bd_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> matrix_bd_end_0 = const()[name = tensor<string, []>("matrix_bd_end_0"), val = tensor<int32, [4]>([1, 8, 17, 87])];
            tensor<bool, [4]> matrix_bd_end_mask_0 = const()[name = tensor<string, []>("matrix_bd_end_mask_0"), val = tensor<bool, [4]>([true, true, true, false])];
            tensor<fp16, [1, 8, 17, 87]> matrix_bd_cast_fp16 = slice_by_index(begin = matrix_bd_begin_0, end = matrix_bd_end_0, end_mask = matrix_bd_end_mask_0, x = matrix_bd_65_cast_fp16)[name = tensor<string, []>("matrix_bd_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_3646_cast_fp16 = add(x = matrix_ac_cast_fp16, y = matrix_bd_cast_fp16)[name = tensor<string, []>("op_3646_cast_fp16")];
            tensor<fp16, []> _inversed_scores_65_y_0_to_fp16 = const()[name = tensor<string, []>("_inversed_scores_65_y_0_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 8, 17, 87]> _inversed_scores_65_cast_fp16 = mul(x = var_3646_cast_fp16, y = _inversed_scores_65_y_0_to_fp16)[name = tensor<string, []>("_inversed_scores_65_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> scores_cast_fp16 = select(a = var_41_to_fp16, b = _inversed_scores_65_cast_fp16, cond = mask_3)[name = tensor<string, []>("scores_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> var_3652_cast_fp16 = softmax(axis = var_62, x = scores_cast_fp16)[name = tensor<string, []>("op_3652_cast_fp16")];
            tensor<fp16, [1, 8, 17, 87]> input_873_cast_fp16 = select(a = var_40_to_fp16, b = var_3652_cast_fp16, cond = mask_3)[name = tensor<string, []>("input_873_cast_fp16")];
            tensor<bool, []> x_429_transpose_x_0 = const()[name = tensor<string, []>("x_429_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> x_429_transpose_y_0 = const()[name = tensor<string, []>("x_429_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 8, 87, 64]> value_cast_fp16 = transpose(perm = value_perm_0, x = v_cast_fp16)[name = tensor<string, []>("transpose_94")];
            tensor<fp16, [1, 8, 17, 64]> x_429_cast_fp16 = matmul(transpose_x = x_429_transpose_x_0, transpose_y = x_429_transpose_y_0, x = input_873_cast_fp16, y = value_cast_fp16)[name = tensor<string, []>("x_429_cast_fp16")];
            tensor<int32, [4]> var_3656_perm_0 = const()[name = tensor<string, []>("op_3656_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_3657 = const()[name = tensor<string, []>("op_3657"), val = tensor<int32, [3]>([1, -1, 512])];
            tensor<fp16, [1, 17, 8, 64]> var_3656_cast_fp16 = transpose(perm = var_3656_perm_0, x = x_429_cast_fp16)[name = tensor<string, []>("transpose_90")];
            tensor<fp16, [1, 17, 512]> input_875_cast_fp16 = reshape(shape = var_3657, x = var_3656_cast_fp16)[name = tensor<string, []>("input_875_cast_fp16")];
            tensor<fp16, [512, 512]> encoder_layers_16_self_attn_linear_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_self_attn_linear_out_weight_to_fp16"), val = tensor<fp16, [512, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206869440)))];
            tensor<fp16, [1, 17, 512]> linear_151_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_16_self_attn_linear_out_weight_to_fp16, x = input_875_cast_fp16)[name = tensor<string, []>("linear_151_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_879_cast_fp16 = add(x = input_869_cast_fp16, y = linear_151_cast_fp16)[name = tensor<string, []>("input_879_cast_fp16")];
            tensor<int32, [1]> x_433_axes_0 = const()[name = tensor<string, []>("x_433_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_16_norm_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_conv_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(207393792)))];
            tensor<fp16, [512]> encoder_layers_16_norm_conv_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_conv_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(207394880)))];
            tensor<fp16, [1, 17, 512]> x_433_cast_fp16 = layer_norm(axes = x_433_axes_0, beta = encoder_layers_16_norm_conv_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_16_norm_conv_weight_to_fp16, x = input_879_cast_fp16)[name = tensor<string, []>("x_433_cast_fp16")];
            tensor<int32, [3]> input_881_perm_0 = const()[name = tensor<string, []>("input_881_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> input_883_pad_type_0 = const()[name = tensor<string, []>("input_883_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> input_883_strides_0 = const()[name = tensor<string, []>("input_883_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> input_883_pad_0 = const()[name = tensor<string, []>("input_883_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> input_883_dilations_0 = const()[name = tensor<string, []>("input_883_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> input_883_groups_0 = const()[name = tensor<string, []>("input_883_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1024, 512, 1]> encoder_layers_16_conv_pointwise_conv1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_conv_pointwise_conv1_weight_to_fp16"), val = tensor<fp16, [1024, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(207395968)))];
            tensor<fp16, [1, 512, 17]> input_881_cast_fp16 = transpose(perm = input_881_perm_0, x = x_433_cast_fp16)[name = tensor<string, []>("transpose_89")];
            tensor<fp16, [1, 1024, 17]> input_883_cast_fp16 = conv(dilations = input_883_dilations_0, groups = input_883_groups_0, pad = input_883_pad_0, pad_type = input_883_pad_type_0, strides = input_883_strides_0, weight = encoder_layers_16_conv_pointwise_conv1_weight_to_fp16, x = input_881_cast_fp16)[name = tensor<string, []>("input_883_cast_fp16")];
            tensor<int32, []> x_435_split_num_splits_0 = const()[name = tensor<string, []>("x_435_split_num_splits_0"), val = tensor<int32, []>(2)];
            tensor<int32, []> x_435_split_axis_0 = const()[name = tensor<string, []>("x_435_split_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 512, 17]> x_435_split_cast_fp16_0, tensor<fp16, [1, 512, 17]> x_435_split_cast_fp16_1 = split(axis = x_435_split_axis_0, num_splits = x_435_split_num_splits_0, x = input_883_cast_fp16)[name = tensor<string, []>("x_435_split_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_435_split_1_sigmoid_cast_fp16 = sigmoid(x = x_435_split_cast_fp16_1)[name = tensor<string, []>("x_435_split_1_sigmoid_cast_fp16")];
            tensor<fp16, [1, 512, 17]> x_435_cast_fp16 = mul(x = x_435_split_cast_fp16_0, y = x_435_split_1_sigmoid_cast_fp16)[name = tensor<string, []>("x_435_cast_fp16")];
            tensor<fp16, [1, 512, 17]> input_885_cast_fp16 = select(a = var_40_to_fp16, b = x_435_cast_fp16, cond = var_418)[name = tensor<string, []>("input_885_cast_fp16")];
            tensor<bool, []> new_x_interleave_0 = const()[name = tensor<string, []>("new_x_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 512, 25]> new_x_cast_fp16 = concat(axis = var_62, interleave = new_x_interleave_0, values = (cache_cast_fp16, input_885_cast_fp16))[name = tensor<string, []>("new_x_cast_fp16")];
            tensor<int32, [3]> cache_last_time_cur_begin_0 = const()[name = tensor<string, []>("cache_last_time_cur_begin_0"), val = tensor<int32, [3]>([0, 0, 17])];
            tensor<int32, [3]> cache_last_time_cur_end_0 = const()[name = tensor<string, []>("cache_last_time_cur_end_0"), val = tensor<int32, [3]>([1, 512, 25])];
            tensor<bool, [3]> cache_last_time_cur_end_mask_0 = const()[name = tensor<string, []>("cache_last_time_cur_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp16, [1, 512, 8]> cache_last_time_cur_cast_fp16 = slice_by_index(begin = cache_last_time_cur_begin_0, end = cache_last_time_cur_end_0, end_mask = cache_last_time_cur_end_mask_0, x = new_x_cast_fp16)[name = tensor<string, []>("cache_last_time_cur_cast_fp16")];
            tensor<string, []> x_437_pad_type_0 = const()[name = tensor<string, []>("x_437_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, []> x_437_groups_0 = const()[name = tensor<string, []>("x_437_groups_0"), val = tensor<int32, []>(512)];
            tensor<int32, [1]> x_437_strides_0 = const()[name = tensor<string, []>("x_437_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_437_pad_0 = const()[name = tensor<string, []>("x_437_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_437_dilations_0 = const()[name = tensor<string, []>("x_437_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [512, 1, 9]> encoder_layers_16_conv_depthwise_conv_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_conv_depthwise_conv_weight_to_fp16"), val = tensor<fp16, [512, 1, 9]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208444608)))];
            tensor<fp16, [1, 512, 17]> x_437_cast_fp16 = conv(dilations = x_437_dilations_0, groups = x_437_groups_0, pad = x_437_pad_0, pad_type = x_437_pad_type_0, strides = x_437_strides_0, weight = encoder_layers_16_conv_depthwise_conv_weight_to_fp16, x = new_x_cast_fp16)[name = tensor<string, []>("x_437_cast_fp16")];
            tensor<int32, [3]> input_887_perm_0 = const()[name = tensor<string, []>("input_887_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<int32, [1]> x_439_axes_0 = const()[name = tensor<string, []>("x_439_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_16_conv_batch_norm_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_conv_batch_norm_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208453888)))];
            tensor<fp16, [512]> encoder_layers_16_conv_batch_norm_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_conv_batch_norm_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208454976)))];
            tensor<fp16, [1, 17, 512]> input_887_cast_fp16 = transpose(perm = input_887_perm_0, x = x_437_cast_fp16)[name = tensor<string, []>("transpose_88")];
            tensor<fp16, [1, 17, 512]> x_439_cast_fp16 = layer_norm(axes = x_439_axes_0, beta = encoder_layers_16_conv_batch_norm_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_16_conv_batch_norm_weight_to_fp16, x = input_887_cast_fp16)[name = tensor<string, []>("x_439_cast_fp16")];
            tensor<int32, [3]> input_889_perm_0 = const()[name = tensor<string, []>("input_889_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 512, 17]> input_889_cast_fp16 = transpose(perm = input_889_perm_0, x = x_439_cast_fp16)[name = tensor<string, []>("transpose_87")];
            tensor<fp16, [1, 512, 17]> input_891_cast_fp16 = silu(x = input_889_cast_fp16)[name = tensor<string, []>("input_891_cast_fp16")];
            tensor<string, []> x_441_pad_type_0 = const()[name = tensor<string, []>("x_441_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [1]> x_441_strides_0 = const()[name = tensor<string, []>("x_441_strides_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [2]> x_441_pad_0 = const()[name = tensor<string, []>("x_441_pad_0"), val = tensor<int32, [2]>([0, 0])];
            tensor<int32, [1]> x_441_dilations_0 = const()[name = tensor<string, []>("x_441_dilations_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, []> x_441_groups_0 = const()[name = tensor<string, []>("x_441_groups_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [512, 512, 1]> encoder_layers_16_conv_pointwise_conv2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_conv_pointwise_conv2_weight_to_fp16"), val = tensor<fp16, [512, 512, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208456064)))];
            tensor<fp16, [1, 512, 17]> x_441_cast_fp16 = conv(dilations = x_441_dilations_0, groups = x_441_groups_0, pad = x_441_pad_0, pad_type = x_441_pad_type_0, strides = x_441_strides_0, weight = encoder_layers_16_conv_pointwise_conv2_weight_to_fp16, x = input_891_cast_fp16)[name = tensor<string, []>("x_441_cast_fp16")];
            tensor<int32, [3]> input_893_perm_0 = const()[name = tensor<string, []>("input_893_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [1, 17, 512]> input_893_cast_fp16 = transpose(perm = input_893_perm_0, x = x_441_cast_fp16)[name = tensor<string, []>("transpose_86")];
            tensor<fp16, [1, 17, 512]> input_895_cast_fp16 = add(x = input_879_cast_fp16, y = input_893_cast_fp16)[name = tensor<string, []>("input_895_cast_fp16")];
            tensor<int32, [1]> input_897_axes_0 = const()[name = tensor<string, []>("input_897_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_16_norm_feed_forward2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_feed_forward2_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208980416)))];
            tensor<fp16, [512]> encoder_layers_16_norm_feed_forward2_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_feed_forward2_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208981504)))];
            tensor<fp16, [1, 17, 512]> input_897_cast_fp16 = layer_norm(axes = input_897_axes_0, beta = encoder_layers_16_norm_feed_forward2_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_16_norm_feed_forward2_weight_to_fp16, x = input_895_cast_fp16)[name = tensor<string, []>("input_897_cast_fp16")];
            tensor<fp16, [2048, 512]> encoder_layers_16_feed_forward2_linear1_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_feed_forward2_linear1_weight_to_fp16"), val = tensor<fp16, [2048, 512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208982592)))];
            tensor<fp16, [1, 17, 2048]> linear_152_cast_fp16 = linear(bias = linear_1_bias_0_to_fp16, weight = encoder_layers_16_feed_forward2_linear1_weight_to_fp16, x = input_897_cast_fp16)[name = tensor<string, []>("linear_152_cast_fp16")];
            tensor<fp16, [1, 17, 2048]> input_901_cast_fp16 = silu(x = linear_152_cast_fp16)[name = tensor<string, []>("input_901_cast_fp16")];
            tensor<fp16, [512, 2048]> encoder_layers_16_feed_forward2_linear2_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_feed_forward2_linear2_weight_to_fp16"), val = tensor<fp16, [512, 2048]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(211079808)))];
            tensor<fp16, [1, 17, 512]> linear_153_cast_fp16 = linear(bias = linear_2_bias_0_to_fp16, weight = encoder_layers_16_feed_forward2_linear2_weight_to_fp16, x = input_901_cast_fp16)[name = tensor<string, []>("linear_153_cast_fp16")];
            tensor<fp16, []> var_3736_to_fp16 = const()[name = tensor<string, []>("op_3736_to_fp16"), val = tensor<fp16, []>(0x1p-1)];
            tensor<fp16, [1, 17, 512]> var_3737_cast_fp16 = mul(x = linear_153_cast_fp16, y = var_3736_to_fp16)[name = tensor<string, []>("op_3737_cast_fp16")];
            tensor<fp16, [1, 17, 512]> input_cast_fp16 = add(x = input_895_cast_fp16, y = var_3737_cast_fp16)[name = tensor<string, []>("input_cast_fp16")];
            tensor<int32, [1]> audio_signal_axes_0 = const()[name = tensor<string, []>("audio_signal_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [512]> encoder_layers_16_norm_out_weight_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_out_weight_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(213177024)))];
            tensor<fp16, [512]> encoder_layers_16_norm_out_bias_to_fp16 = const()[name = tensor<string, []>("encoder_layers_16_norm_out_bias_to_fp16"), val = tensor<fp16, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(213178112)))];
            tensor<fp16, [1, 17, 512]> audio_signal_cast_fp16 = layer_norm(axes = audio_signal_axes_0, beta = encoder_layers_16_norm_out_bias_to_fp16, epsilon = var_38_to_fp16, gamma = encoder_layers_16_norm_out_weight_to_fp16, x = input_cast_fp16)[name = tensor<string, []>("audio_signal_cast_fp16")];
            tensor<int32, [3]> obj_1_perm_0 = const()[name = tensor<string, []>("obj_1_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<string, []> obj_1_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("obj_1_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<int32, []> obj_5_axis_0 = const()[name = tensor<string, []>("obj_5_axis_0"), val = tensor<int32, []>(0)];
            tensor<fp16, [17, 1, 70, 512]> obj_5_cast_fp16 = stack(axis = obj_5_axis_0, values = (var_332_cast_fp16, var_536_cast_fp16, var_740_cast_fp16, var_944_cast_fp16, var_1148_cast_fp16, var_1352_cast_fp16, var_1556_cast_fp16, var_1760_cast_fp16, var_1964_cast_fp16, var_2168_cast_fp16, var_2372_cast_fp16, var_2576_cast_fp16, var_2780_cast_fp16, var_2984_cast_fp16, var_3188_cast_fp16, var_3392_cast_fp16, cache_last_channel_cur_cast_fp16))[name = tensor<string, []>("obj_5_cast_fp16")];
            tensor<int32, []> obj_7_axis_0 = const()[name = tensor<string, []>("obj_7_axis_0"), val = tensor<int32, []>(0)];
            tensor<fp16, [17, 1, 512, 8]> obj_7_cast_fp16 = stack(axis = obj_7_axis_0, values = (var_431_cast_fp16, var_635_cast_fp16, var_839_cast_fp16, var_1043_cast_fp16, var_1247_cast_fp16, var_1451_cast_fp16, var_1655_cast_fp16, var_1859_cast_fp16, var_2063_cast_fp16, var_2267_cast_fp16, var_2471_cast_fp16, var_2675_cast_fp16, var_2879_cast_fp16, var_3083_cast_fp16, var_3287_cast_fp16, var_3491_cast_fp16, cache_last_time_cur_cast_fp16))[name = tensor<string, []>("obj_7_cast_fp16")];
            tensor<string, []> obj_7_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("obj_7_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<int32, [1]> var_3753 = add(x = cache_last_channel_len, y = max_audio_length_1)[name = tensor<string, []>("op_3753")];
            tensor<string, []> var_3753_promoted_to_fp16_dtype_0 = const()[name = tensor<string, []>("op_3753_promoted_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, []> const_237_to_fp16 = const()[name = tensor<string, []>("const_237_to_fp16"), val = tensor<fp16, []>(-inf)];
            tensor<fp16, []> var_45_promoted_to_fp16 = const()[name = tensor<string, []>("op_45_promoted_to_fp16"), val = tensor<fp16, []>(0x1.18p+6)];
            tensor<fp16, [1]> var_3753_to_fp16 = cast(dtype = var_3753_promoted_to_fp16_dtype_0, x = var_3753)[name = tensor<string, []>("cast_184")];
            tensor<fp16, [1]> clip_1_cast_fp16 = clip(alpha = const_237_to_fp16, beta = var_45_promoted_to_fp16, x = var_3753_to_fp16)[name = tensor<string, []>("clip_1_cast_fp16")];
            tensor<string, []> var_3780_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("op_3780_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<string, []> cast_179_dtype_0 = const()[name = tensor<string, []>("cast_179_dtype_0"), val = tensor<string, []>("int32")];
            tensor<string, []> cast_180_dtype_0 = const()[name = tensor<string, []>("cast_180_dtype_0"), val = tensor<string, []>("int32")];
            tensor<int32, [1]> new_cache_last_channel_len = cast(dtype = cast_180_dtype_0, x = clip_1_cast_fp16)[name = tensor<string, []>("cast_181")];
            tensor<int32, [1]> encoded_length = cast(dtype = cast_179_dtype_0, x = clip_0_cast_fp16)[name = tensor<string, []>("cast_182")];
            tensor<fp32, [17, 1, 70, 512]> new_cache_last_channel = cast(dtype = var_3780_cast_fp16_to_fp32_dtype_0, x = obj_5_cast_fp16)[name = tensor<string, []>("cast_183")];
            tensor<fp32, [17, 1, 512, 8]> new_cache_last_time = cast(dtype = obj_7_cast_fp16_to_fp32_dtype_0, x = obj_7_cast_fp16)[name = tensor<string, []>("cast_185")];
            tensor<fp16, [1, 512, 17]> obj_1_cast_fp16 = transpose(perm = obj_1_perm_0, x = audio_signal_cast_fp16)[name = tensor<string, []>("transpose_85")];
            tensor<fp32, [1, 512, 17]> encoded_output = cast(dtype = obj_1_cast_fp16_to_fp32_dtype_0, x = obj_1_cast_fp16)[name = tensor<string, []>("cast_186")];
            tensor<fp32, [1, 128, 16]> new_pre_cache = cast(dtype = var_28_cast_fp16_to_fp32_dtype_0, x = var_28_cast_fp16)[name = tensor<string, []>("cast_192")];
        } -> (encoded_output, encoded_length, new_pre_cache, new_cache_last_channel, new_cache_last_time, new_cache_last_channel_len);
}