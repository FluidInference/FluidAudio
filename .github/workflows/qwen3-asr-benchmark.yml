name: Qwen3-ASR Benchmark

on:
  workflow_dispatch:
    inputs:
      max_files:
        description: 'Max files per variant'
        default: '10'
        type: string

jobs:
  qwen3-asr-benchmark:
    name: Qwen3-ASR Benchmark
    runs-on: macos-15
    permissions:
      contents: read

    timeout-minutes: 60

    steps:
      - uses: actions/checkout@v5

      - uses: swift-actions/setup-swift@v2
        with:
          swift-version: "6.1"

      - name: Cache Dependencies
        uses: actions/cache@v4
        with:
          path: |
            .build
            ~/Library/Application Support/FluidAudio/Models/qwen3-asr-0.6b-coreml
            ~/Library/Application Support/FluidAudio/Datasets/LibriSpeech
            ~/Library/Caches/Homebrew
            /usr/local/Cellar/ffmpeg
            /opt/homebrew/Cellar/ffmpeg
          key: ${{ runner.os }}-qwen3-asr-${{ hashFiles('Package.resolved', 'Sources/FluidAudio/Frameworks/**', 'Sources/FluidAudio/ModelRegistry.swift', 'Sources/FluidAudio/ModelNames.swift') }}

      - name: Install ffmpeg
        run: |
          brew install ffmpeg || echo "ffmpeg may already be installed"
          ffmpeg -version || echo "ffmpeg not available"

      - name: Build
        run: swift build -c release

      - name: Run Benchmarks
        id: benchmark
        run: |
          MAX_FILES="${{ github.event.inputs.max_files || '10' }}"
          BENCHMARK_START=$(date +%s)

          set -o pipefail

          run_benchmark() {
            local VARIANT=$1
            local MAX=$2
            local OUTPUT=$3

            echo "========================================="
            echo "Running Qwen3-ASR benchmark: $VARIANT (max $MAX files)"
            echo "Output: $OUTPUT"
            echo "========================================="

            if swift run fluidaudiocli qwen3-benchmark \
              --variant "$VARIANT" --max-files "$MAX" \
              --output "$OUTPUT" > benchmark_log.txt 2>&1; then
              echo "Benchmark $VARIANT completed successfully"
              return 0
            else
              echo "Benchmark $VARIANT FAILED with exit code $?"
              echo "Full output:"
              cat benchmark_log.txt
              return 1
            fi
          }

          # Run both variants
          run_benchmark "f32" "$MAX_FILES" "qwen3_results_f32.json" || F32_FAILED=1
          run_benchmark "int8" "$MAX_FILES" "qwen3_results_int8.json" || INT8_FAILED=1

          # Extract f32 metrics
          if [ -f qwen3_results_f32.json ]; then
            F32_WER_AVG=$(jq -r '.summary.averageWER * 100' qwen3_results_f32.json 2>/dev/null)
            F32_WER_MED=$(jq -r '.summary.medianWER * 100' qwen3_results_f32.json 2>/dev/null)
            F32_CER_AVG=$(jq -r '.summary.averageCER * 100' qwen3_results_f32.json 2>/dev/null)
            F32_RTFx=$(jq -r '.summary.medianRTFx' qwen3_results_f32.json 2>/dev/null)
            F32_OVERALL_RTFx=$(jq -r '.summary.overallRTFx' qwen3_results_f32.json 2>/dev/null)

            [ "$F32_WER_AVG" != "null" ] && [ -n "$F32_WER_AVG" ] && F32_WER_AVG=$(printf "%.2f" "$F32_WER_AVG") || F32_WER_AVG="N/A"
            [ "$F32_WER_MED" != "null" ] && [ -n "$F32_WER_MED" ] && F32_WER_MED=$(printf "%.2f" "$F32_WER_MED") || F32_WER_MED="N/A"
            [ "$F32_CER_AVG" != "null" ] && [ -n "$F32_CER_AVG" ] && F32_CER_AVG=$(printf "%.2f" "$F32_CER_AVG") || F32_CER_AVG="N/A"
            [ "$F32_RTFx" != "null" ] && [ -n "$F32_RTFx" ] && F32_RTFx=$(printf "%.2f" "$F32_RTFx") || F32_RTFx="N/A"
            [ "$F32_OVERALL_RTFx" != "null" ] && [ -n "$F32_OVERALL_RTFx" ] && F32_OVERALL_RTFx=$(printf "%.2f" "$F32_OVERALL_RTFx") || F32_OVERALL_RTFx="N/A"
          fi

          # Extract int8 metrics
          if [ -f qwen3_results_int8.json ]; then
            INT8_WER_AVG=$(jq -r '.summary.averageWER * 100' qwen3_results_int8.json 2>/dev/null)
            INT8_WER_MED=$(jq -r '.summary.medianWER * 100' qwen3_results_int8.json 2>/dev/null)
            INT8_CER_AVG=$(jq -r '.summary.averageCER * 100' qwen3_results_int8.json 2>/dev/null)
            INT8_RTFx=$(jq -r '.summary.medianRTFx' qwen3_results_int8.json 2>/dev/null)
            INT8_OVERALL_RTFx=$(jq -r '.summary.overallRTFx' qwen3_results_int8.json 2>/dev/null)

            [ "$INT8_WER_AVG" != "null" ] && [ -n "$INT8_WER_AVG" ] && INT8_WER_AVG=$(printf "%.2f" "$INT8_WER_AVG") || INT8_WER_AVG="N/A"
            [ "$INT8_WER_MED" != "null" ] && [ -n "$INT8_WER_MED" ] && INT8_WER_MED=$(printf "%.2f" "$INT8_WER_MED") || INT8_WER_MED="N/A"
            [ "$INT8_CER_AVG" != "null" ] && [ -n "$INT8_CER_AVG" ] && INT8_CER_AVG=$(printf "%.2f" "$INT8_CER_AVG") || INT8_CER_AVG="N/A"
            [ "$INT8_RTFx" != "null" ] && [ -n "$INT8_RTFx" ] && INT8_RTFx=$(printf "%.2f" "$INT8_RTFx") || INT8_RTFx="N/A"
            [ "$INT8_OVERALL_RTFx" != "null" ] && [ -n "$INT8_OVERALL_RTFx" ] && INT8_OVERALL_RTFx=$(printf "%.2f" "$INT8_OVERALL_RTFx") || INT8_OVERALL_RTFx="N/A"
          fi

          # Output metrics
          echo "F32_WER_AVG=${F32_WER_AVG:-N/A}" >> $GITHUB_OUTPUT
          echo "F32_WER_MED=${F32_WER_MED:-N/A}" >> $GITHUB_OUTPUT
          echo "F32_CER_AVG=${F32_CER_AVG:-N/A}" >> $GITHUB_OUTPUT
          echo "F32_RTFx=${F32_RTFx:-N/A}" >> $GITHUB_OUTPUT
          echo "F32_OVERALL_RTFx=${F32_OVERALL_RTFx:-N/A}" >> $GITHUB_OUTPUT
          echo "INT8_WER_AVG=${INT8_WER_AVG:-N/A}" >> $GITHUB_OUTPUT
          echo "INT8_WER_MED=${INT8_WER_MED:-N/A}" >> $GITHUB_OUTPUT
          echo "INT8_CER_AVG=${INT8_CER_AVG:-N/A}" >> $GITHUB_OUTPUT
          echo "INT8_RTFx=${INT8_RTFx:-N/A}" >> $GITHUB_OUTPUT
          echo "INT8_OVERALL_RTFx=${INT8_OVERALL_RTFx:-N/A}" >> $GITHUB_OUTPUT

          EXECUTION_TIME=$(( ($(date +%s) - BENCHMARK_START) / 60 ))m$(( ($(date +%s) - BENCHMARK_START) % 60 ))s
          echo "EXECUTION_TIME=$EXECUTION_TIME" >> $GITHUB_OUTPUT
          echo "FILES_COUNT=$MAX_FILES" >> $GITHUB_OUTPUT

          if [ ! -z "$F32_FAILED" ] || [ ! -z "$INT8_FAILED" ]; then
            echo "BENCHMARK_STATUS=PARTIAL_FAILURE" >> $GITHUB_OUTPUT
            echo "Some benchmarks failed:"
            [ ! -z "$F32_FAILED" ] && echo "  - f32 benchmark failed"
            [ ! -z "$INT8_FAILED" ] && echo "  - int8 benchmark failed"
          else
            echo "BENCHMARK_STATUS=SUCCESS" >> $GITHUB_OUTPUT
            echo "All benchmarks completed successfully"
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Qwen3-ASR Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### LibriSpeech test-clean" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Variant | WER Avg | WER Med | CER Avg | Median RTFx | Overall RTFx |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|---------|---------|---------|-------------|--------------|" >> $GITHUB_STEP_SUMMARY
          echo "| f32 (FP16) | ${{ steps.benchmark.outputs.F32_WER_AVG }}% | ${{ steps.benchmark.outputs.F32_WER_MED }}% | ${{ steps.benchmark.outputs.F32_CER_AVG }}% | ${{ steps.benchmark.outputs.F32_RTFx }}x | ${{ steps.benchmark.outputs.F32_OVERALL_RTFx }}x |" >> $GITHUB_STEP_SUMMARY
          echo "| int8 | ${{ steps.benchmark.outputs.INT8_WER_AVG }}% | ${{ steps.benchmark.outputs.INT8_WER_MED }}% | ${{ steps.benchmark.outputs.INT8_CER_AVG }}% | ${{ steps.benchmark.outputs.INT8_RTFx }}x | ${{ steps.benchmark.outputs.INT8_OVERALL_RTFx }}x |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Variant | Decoder Size | Total (approx) |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-------------|----------------|" >> $GITHUB_STEP_SUMMARY
          echo "| f32 (FP16) | 1.1 GB | ~1.75 GB |" >> $GITHUB_STEP_SUMMARY
          echo "| int8 | 571 MB | ~900 MB |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "_${{ steps.benchmark.outputs.FILES_COUNT }} files per variant â€¢ Runtime: ${{ steps.benchmark.outputs.EXECUTION_TIME }}_" >> $GITHUB_STEP_SUMMARY

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: qwen3-asr-results
          path: qwen3_results_*.json
