name: ASR Benchmark

on:
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      max_files:
        description: 'Number of files to test per dataset'
        required: false
        default: '100'

jobs:
  asr-benchmark:
    name: ASR Benchmark
    runs-on: macos-14
    permissions:
      contents: read
      pull-requests: write

    steps:
    - uses: actions/checkout@v4

    - uses: swift-actions/setup-swift@v2
      with:
        swift-version: "6.0"

    - name: Cache Dependencies
      uses: actions/cache@v4
      with:
        path: |
          .build
          ~/Library/Application Support/FluidAudio/Models/Parakeet
          ~/Documents/Datasets/librispeech
        key: ${{ runner.os }}-asr-${{ hashFiles('Package.resolved') }}-v4

    - name: Build
      run: swift build -c release

    - name: Download Models if Needed
      run: |
        MODELS_DIR="$HOME/Library/Application Support/FluidAudio/Models/Parakeet"
        VOCAB_FILE="$HOME/Library/Application Support/FluidAudio/parakeet_vocab.json"
        
        # Check if all models exist
        if [ -d "$MODELS_DIR/Melspectogram.mlmodelc" ] && \
           [ -d "$MODELS_DIR/ParakeetEncoder.mlmodelc" ] && \
           [ -d "$MODELS_DIR/ParakeetDecoder.mlmodelc" ] && \
           [ -d "$MODELS_DIR/RNNTJoint.mlmodelc" ] && \
           [ -f "$VOCAB_FILE" ]; then
          echo "✅ Models already cached"
        else
          echo "📥 Downloading models..."
          rm -rf "$MODELS_DIR"
          mkdir -p "$MODELS_DIR"
          
          TEMP_DIR=$(mktemp -d)
          cd "$TEMP_DIR"
          GIT_LFS_SKIP_SMUDGE=1 git clone --depth 1 https://huggingface.co/FluidInference/parakeet-tdt-0.6b-v2-coreml.git
          cd parakeet-tdt-0.6b-v2-coreml
          git lfs pull --include="*.mlmodelc/**"
          
          mv *.mlmodelc "$MODELS_DIR/"
          mv parakeet_vocab.json "$HOME/Library/Application Support/FluidAudio/"
          
          cd /
          rm -rf "$TEMP_DIR"
          echo "✅ Models downloaded"
        fi

    - name: Run Benchmarks
      id: benchmark
      run: |
        MAX_FILES="${{ github.event.inputs.max_files || '100' }}"
        BENCHMARK_START=$(date +%s)
        
        # Run in parallel
        swift run -c release fluidaudio asr-benchmark \
          --subset test-clean --max-files "$MAX_FILES" \
          --auto-download --output asr_results_clean.json &
        CLEAN_PID=$!
        
        swift run -c release fluidaudio asr-benchmark \
          --subset test-other --max-files "$MAX_FILES" \
          --auto-download --output asr_results_other.json &
        OTHER_PID=$!
        
        wait $CLEAN_PID && wait $OTHER_PID
        
        # Extract metrics
        if [ -f asr_results_clean.json ]; then
          CLEAN_WER_AVG=$(jq -r '.averageWER' asr_results_clean.json)
          CLEAN_WER_MED=$(jq -r '.medianWER' asr_results_clean.json)
          CLEAN_AUDIO=$(jq -r '.totalAudioDuration' asr_results_clean.json)
          CLEAN_TIME=$(jq -r '.totalProcessingTime' asr_results_clean.json)
          CLEAN_RTFx=$(awk "BEGIN {printf \"%.1f\", $CLEAN_AUDIO / $CLEAN_TIME}")
        fi
        
        if [ -f asr_results_other.json ]; then
          OTHER_WER_AVG=$(jq -r '.averageWER' asr_results_other.json)
          OTHER_WER_MED=$(jq -r '.medianWER' asr_results_other.json)
          OTHER_AUDIO=$(jq -r '.totalAudioDuration' asr_results_other.json)
          OTHER_TIME=$(jq -r '.totalProcessingTime' asr_results_other.json)
          OTHER_RTFx=$(awk "BEGIN {printf \"%.1f\", $OTHER_AUDIO / $OTHER_TIME}")
        fi
        
        # Output metrics
        echo "CLEAN_WER_AVG=${CLEAN_WER_AVG:-N/A}" >> $GITHUB_OUTPUT
        echo "CLEAN_WER_MED=${CLEAN_WER_MED:-N/A}" >> $GITHUB_OUTPUT
        echo "CLEAN_RTFx=${CLEAN_RTFx:-N/A}" >> $GITHUB_OUTPUT
        echo "OTHER_WER_AVG=${OTHER_WER_AVG:-N/A}" >> $GITHUB_OUTPUT
        echo "OTHER_WER_MED=${OTHER_WER_MED:-N/A}" >> $GITHUB_OUTPUT
        echo "OTHER_RTFx=${OTHER_RTFx:-N/A}" >> $GITHUB_OUTPUT
        
        EXECUTION_TIME=$(( ($(date +%s) - BENCHMARK_START) / 60 ))m$(( ($(date +%s) - BENCHMARK_START) % 60 ))s
        echo "EXECUTION_TIME=$EXECUTION_TIME" >> $GITHUB_OUTPUT

    - name: Comment PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const body = `## ASR Benchmark Results

          | Dataset | WER Avg | WER Med | RTFx | Status |
          |---------|---------|---------|------|--------|
          | test-clean | ${{ steps.benchmark.outputs.CLEAN_WER_AVG }}% | ${{ steps.benchmark.outputs.CLEAN_WER_MED }}% | ${{ steps.benchmark.outputs.CLEAN_RTFx }}x | ${parseFloat('${{ steps.benchmark.outputs.CLEAN_WER_AVG }}') < 10 ? '✅' : '⚠️'} |
          | test-other | ${{ steps.benchmark.outputs.OTHER_WER_AVG }}% | ${{ steps.benchmark.outputs.OTHER_WER_MED }}% | ${{ steps.benchmark.outputs.OTHER_RTFx }}x | ${parseFloat('${{ steps.benchmark.outputs.OTHER_WER_AVG }}') < 20 ? '✅' : '⚠️'} |

          <sub>${{ github.event.inputs.max_files || '100' }} files per dataset • Test runtime: ${{ steps.benchmark.outputs.EXECUTION_TIME }} • ${new Date().toLocaleString('en-US', { timeZone: 'America/New_York', year: 'numeric', month: '2-digit', day: '2-digit', hour: '2-digit', minute: '2-digit', hour12: true })} EST</sub>

          <sub>**RTFx** = Real-Time Factor (higher is better) • Calculated as: Total audio duration ÷ Total processing time<br>
          Processing time includes: Model inference on Apple Neural Engine, audio preprocessing, state resets between files, token-to-text conversion, and file I/O<br>
          Example: RTFx of 2.0x means 10 seconds of audio processed in 5 seconds (2x faster than real-time)</sub>

          <!-- fluidaudio-benchmark-asr -->`;

          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });

          const existing = comments.find(c => 
            c.body.includes('<!-- fluidaudio-benchmark-asr -->')
          );

          if (existing) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: existing.id,
              body: body
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });
          }

    - name: Upload Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: asr-results
        path: asr_results_*.json